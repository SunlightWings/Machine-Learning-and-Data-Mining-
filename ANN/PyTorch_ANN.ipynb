{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Author: Prabin"
      ],
      "metadata": {
        "id": "5SL7G7GXRmGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we are going to learn how to build ANN with PyTorch. But you will also be introduced to PyTorch if you are new to it."
      ],
      "metadata": {
        "id": "PxDI_r_Gmv3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Basics:\n",
        "\n",
        "* PyTorch is a deep learning framework that's well maintained and designed for building and training models. Many scientists prefer PyTorch over Tensorflow to carry out researchs. PyTorch has so much in common with the Python library Numpy.\n",
        "\n",
        "* PyTorch Module can be imported using `import torch`. For various data, PyTorch supports:\n",
        "  1. torchvision for image data\n",
        "  2. torchaudio for audio data\n",
        "  3. torchtext for text data\n",
        "\n",
        "* Tensor is the fundamental data structure in PyTorch.\n",
        "\n",
        "Lets create a tensor from list and from a numpy array."
      ],
      "metadata": {
        "id": "i5jaXR7mhl4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "zObG7jpYrgh3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJZogAGmmrpL",
        "outputId": "62e393b6-7f61-4dd2-fded-ebe89d69abbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ],
      "source": [
        "# tensor from list\n",
        "lst = [[1,2,3],[4,5,6]]\n",
        "tensor1 = torch.tensor(lst)\n",
        "print(tensor1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor from a numpy array\n",
        "array1 = np.array(lst)\n",
        "tensor2 = torch.tensor(array1)\n",
        "tensor3 = torch.from_numpy(array1)\n",
        "print(tensor2)\n",
        "print(tensor3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuT-Hlx0tRDt",
        "outputId": "1e606940-b0c9-4fc1-eabc-3030c75ae23e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape of the tensor and the datatype can be checked as:\n"
      ],
      "metadata": {
        "id": "aOPxVxrKCdx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE32ZwYFreaG",
        "outputId": "5ce44f09-7eb5-4fce-d55f-2e57bc52b2e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIS5O49O0iQd",
        "outputId": "f13ffd19-b9d8-450b-8b75-27033da6fbce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The command `tensor.device` displays which devicee the tensor is loaded on such as CPU or GPU."
      ],
      "metadata": {
        "id": "y6YCe-Yc2bZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZykTykVx0oct",
        "outputId": "b81160cd-5123-4562-b059-84ce0a088d8a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uIbVQgkK9pBF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some SImple Operations: (Optional)\n",
        "We may neecd to perform various simple operations in tensors instead of Numpy arrays for the consistency of our code base. So lets be familiar with some operations. You may skip to the ANN implementation directly if you are already familiar with these operations."
      ],
      "metadata": {
        "id": "Z7Eoj4FK7SAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Absolute value and Negative values"
      ],
      "metadata": {
        "id": "uDNMnVre7sU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial = torch.tensor([-1,2,-9])\n",
        "print(initial)\n",
        "\n",
        "positive = torch.abs(initial)\n",
        "print(positive)\n",
        "negation = torch.neg(initial)\n",
        "print(negation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqEe-Itv63Nj",
        "outputId": "9747b4a7-03c3-4cda-edbd-356cd5d1c76f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1,  2, -9])\n",
            "tensor([1, 2, 9])\n",
            "tensor([ 1, -2,  9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Random number generation:\n",
        "\n",
        "`torch.randn` Returns a tensor filled with random numbers from a normal distribution"
      ],
      "metadata": {
        "id": "8baQoTg875HP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(3,2)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylRI88iS773m",
        "outputId": "1d3f9bda-e982-4c70-bea2-ec5f612cda8c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1491, -1.6488],\n",
              "        [ 0.1502,  0.1241],\n",
              "        [ 0.9275, -0.0455]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try running the above cell 3 times. What did you see?\n",
        "You must have noticed that the tensor changed 3 times.\n",
        "\n",
        "For reproducibility purpose, we may need to be able to produce same set of random numbers when the experiment is to be repeated in the future. So we use `manual_seed`.\n",
        "Now run the following cell 3 times and check if the same random numbers are produced each time."
      ],
      "metadata": {
        "id": "g45-oezzyuKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "random_fixed = torch.randn(3,2)\n",
        "random_fixed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbEK3MHjy4KA",
        "outputId": "b9ee8dd3-306d-4570-f1d8-c2b962b03de4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3367,  0.1288],\n",
              "        [ 0.2345,  0.2303],\n",
              "        [-1.1229, -0.1863]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Arithmetic Operation:\n",
        "\n",
        "`torch.add` adds the scalar other to each element of the input and returns a new resulting tensor.\n",
        "Similarly, `torch.sub` does the subtraction, `torch.mul` does the multiplication, and `torch.div` does the division."
      ],
      "metadata": {
        "id": "yH0r6XwA7z85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(a)\n",
        "add = torch.add(a,20)\n",
        "print(add)\n",
        "sub = torch.sub(a,20)\n",
        "print(sub)\n",
        "mul = torch.mul(a,2)\n",
        "print(mul)\n",
        "div = torch.div(a,10)\n",
        "print(div)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJJ2ZSfV7rFp",
        "outputId": "dc7529fc-78a2-457e-a04c-61c7f87ff888"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1491, -1.6488],\n",
            "        [ 0.1502,  0.1241],\n",
            "        [ 0.9275, -0.0455]])\n",
            "tensor([[20.1491, 18.3512],\n",
            "        [20.1502, 20.1241],\n",
            "        [20.9275, 19.9545]])\n",
            "tensor([[-19.8509, -21.6488],\n",
            "        [-19.8498, -19.8759],\n",
            "        [-19.0725, -20.0455]])\n",
            "tensor([[ 0.2983, -3.2976],\n",
            "        [ 0.3004,  0.2482],\n",
            "        [ 1.8550, -0.0909]])\n",
            "tensor([[ 0.0149, -0.1649],\n",
            "        [ 0.0150,  0.0124],\n",
            "        [ 0.0928, -0.0045]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Multiplication\n",
        " * Element-wise multiplication using `*`\n",
        " * Squaring is also element-wise\n",
        " * Matrix multiplication using `@`"
      ],
      "metadata": {
        "id": "pDXjASmF7B2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "element_multiplication = tensor1 * tensor2                                # element wise multiplication\n",
        "print(\"tensor1* tensor2 = \\n\",element_multiplication, sep='')\n",
        "\n",
        "print(\"\\n\", \"a =\", a, \"\\n\")\n",
        "square = torch.square(a)                                                  # squaring elements\n",
        "print(\"a squared= \",square)"
      ],
      "metadata": {
        "id": "4TDbAWVB02tO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567addea-2666-4330-d31e-a13e66709f20"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor1* tensor2 = \n",
            "tensor([[ 1,  4,  9],\n",
            "        [16, 25, 36]])\n",
            "\n",
            " a = tensor([[ 0.1491, -1.6488],\n",
            "        [ 0.1502,  0.1241],\n",
            "        [ 0.9275, -0.0455]]) \n",
            "\n",
            "a squared=  tensor([[2.2244e-02, 2.7185e+00],\n",
            "        [2.2557e-02, 1.5403e-02],\n",
            "        [8.6027e-01, 2.0658e-03]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([[1,2],[3,4]])\n",
        "y = torch.tensor([[1,1],[1,1]])\n",
        "print(x)\n",
        "print(y)\n",
        "matrix_multiplication = x @ y                        # Matrix multiplication\n",
        "print(matrix_multiplication)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMnRc9kzM1Tk",
        "outputId": "e845c980-d1f4-4a3c-9435-7ad4178a1617"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "tensor([[1, 1],\n",
            "        [1, 1]])\n",
            "tensor([[3, 3],\n",
            "        [7, 7]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Reciprocal"
      ],
      "metadata": {
        "id": "h0kHBd1v9FgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.tensor([1,2,5,10])\n",
        "print(torch.reciprocal(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAWe5KAY8HNo",
        "outputId": "fd729079-aeba-4bc7-e072-c2e4d127ccd9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.0000, 0.5000, 0.2000, 0.1000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Remainder"
      ],
      "metadata": {
        "id": "d_Duxt9ZF_sN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(b)\n",
        "remainder = torch.remainder(b,3)\n",
        "print(remainder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKQcfzgBEfjI",
        "outputId": "b33cb137-7ada-4c8f-8880-1fc76e4bd3d5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1,  2,  5, 10])\n",
            "tensor([1, 2, 2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autograd in PyTorch:\n",
        "\n",
        "Autograd is a feature in PyTorch that for rapid computation of multiple partial derivatives (also referred to as gradients) over a complex computation. The power of autograd comes from the fact that it traces your computation graph dynamically at runtime meaning that if your model has decision branches, or loops whose lengths are not known until runtime, the computation will still be traced correctly, and you'll get correct gradients to drive learning.\n",
        "\n",
        "A machine learninig model can be defined as:\n",
        "\n",
        "$\\vec{y} = \\vec{M}(\\vec{x})$\n",
        "\n",
        "where,\n",
        "\n",
        "$\\vec{x}$ = *i*-dimensional vector $\\vec{x}$\n",
        "\n",
        "$\\vec{M}$ = Vector-valued function (function that outputs a vector $\\vec{y}$, and not a scalar)\n",
        "\n",
        "\\\n",
        "\n",
        "Meanwhile, The Loss function L($\\vec{y}$) = L($\\vec{M}$($\\vec{x}$)) is a single-valued scalar function of the model's output because it produces a single scalar value.\n",
        "\n",
        "Now, we want to minimize the loss function-perhaps make it go towards zero. That is we need to make its first derivative with respect to the input equal to 0:\n",
        "\n",
        "$\\frac{\\partial L}{\\partial x} = 0$.\n",
        "\n",
        "By the chain rule of differential calculus, we have:\n",
        "\n",
        "$\\frac{\\partial {L({\\vec y})}}{\\partial x}$ =\n",
        "$\\frac{\\partial L}{\\partial y} . \\frac{\\partial y}{\\partial x}$ =\n",
        "$\\frac{\\partial L}{\\partial y} . \\frac{\\partial M(x)}{\\partial x}$\n",
        "\n",
        "Now $\\frac{\\partial L}{\\partial y} . \\frac{\\partial M(x)}{\\partial x}$ contains many local partial derivatives over every multiplied learning\n",
        "weight, every activation function, and every other mathematical\n",
        "transformation in the model. Every computed tensor in your PyTorch\n",
        "model carries a history of its input tensors and the function used to\n",
        "create it. Combined with the fact that PyTorch functions meant to act on\n",
        "tensors each have a built-in implementation for computing their own\n",
        "derivatives, this greatly speeds the computation of the local\n",
        "derivatives.\n",
        "\n",
        "\\\n",
        "\n",
        "For a function $\\vec{y}=f(\\vec{x})$, with n-dimensional input and m-dimensional output, the complete gradient is a matrix of the derivative of every output with respect to every input, called the **Jacobian:**\n",
        "\n",
        "$$\\begin{aligned}\n",
        "J\n",
        "=\n",
        "\\left(\\begin{array}{ccc}\n",
        "\\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n",
        "\\vdots & \\ddots & \\vdots\\\\\n",
        "\\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
        "\\end{array}\\right)\n",
        "\\end{aligned}$$\n",
        "\n",
        "A second function, $l=g\\left(\\vec{y}\\right)$ that takes m-dimensional input and produces a scalar output (like a loss function),  you can express its gradients with respect to $\\vec{y}$ as a column vector,\n",
        "$v=\\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T}$\n",
        "\n",
        "\n",
        "Now imagine 'J' is the PyTorch model, and 'v' is the loss function, now they can be multiplied to obtain the required column matrix, which contains the gradient of Loss with respect to inputs. Thats all we want!!\n",
        "\n",
        "\n",
        "$$\\begin{aligned}\n",
        "J^{T}\\cdot v=\\left(\\begin{array}{ccc}\n",
        "\\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\\n",
        "\\vdots & \\ddots & \\vdots\\\\\n",
        "\\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
        "\\end{array}\\right)\\left(\\begin{array}{c}\n",
        "\\frac{\\partial l}{\\partial y_{1}}\\\\\n",
        "\\vdots\\\\\n",
        "\\frac{\\partial l}{\\partial y_{m}}\n",
        "\\end{array}\\right)=\\left(\\begin{array}{c}\n",
        "\\frac{\\partial l}{\\partial x_{1}}\\\\\n",
        "\\vdots\\\\\n",
        "\\frac{\\partial l}{\\partial x_{n}}\n",
        "\\end{array}\\right)\n",
        "\\end{aligned}$$\n",
        "\n",
        "\n",
        "**torch.autograd** is an engine for computing these products.\n",
        "This is how we accumulate the gradients over the learning weights during\n",
        "the backward pass.\n",
        "\n",
        "Note that the `backward()` call can *also* take an optional\n",
        "vector input. This vector represents a set of gradients over the tensor,\n",
        "which are multiplied by the Jacobian of the autograd-traced tensor that proceeds it.\n",
        "\n",
        "Lets check with few examples.."
      ],
      "metadata": {
        "id": "b_T9iraeSK_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.ticker as ticker\n",
        "import math\n",
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ni_QT6yCS23A"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.linspace(0.0, 10.0, steps=20, requires_grad=True)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwfXslwlJyd8",
        "outputId": "7b2b4203-fb84-4fe3-e37e-aae3682639f2"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.0000,  0.5263,  1.0526,  1.5789,  2.1053,  2.6316,  3.1579,  3.6842,\n",
            "         4.2105,  4.7368,  5.2632,  5.7895,  6.3158,  6.8421,  7.3684,  7.8947,\n",
            "         8.4211,  8.9474,  9.4737, 10.0000], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.sin(a)\n",
        "plt.plot(a.detach(), b.detach())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "kGt6miC3KRWU",
        "outputId": "8f1649a8-ac45-43c1-98d6-4f31480af2b9"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7b6bf1a00a90>]"
            ]
          },
          "metadata": {},
          "execution_count": 139
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Upon printing b, we can see that the computation history of b is being tracked\n",
        "* For backpropagation to be successful, we need to compute gradient, and for that we need to calculate the derivate of exp(x). This is shown when we print `grad_fn`"
      ],
      "metadata": {
        "id": "hcpQYW3UK324"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(b)\n",
        "print(\"\\n\")\n",
        "print(b.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GzcqPOyL3AU",
        "outputId": "33088ce2-ba46-4f25-8ee3-f1820d09e555"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.0000,  0.5024,  0.8687,  1.0000,  0.8605,  0.4882, -0.0163, -0.5164,\n",
            "        -0.8767, -0.9997, -0.8521, -0.4739,  0.0326,  0.5303,  0.8844,  0.9992,\n",
            "         0.8435,  0.4595, -0.0489, -0.5440], grad_fn=<SinBackward0>)\n",
            "\n",
            "\n",
            "<SinBackward0 object at 0x7b6bf24b0370>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets expand the computation graph by compputing some more simple arithmetics. The tensor 'out' will contain the scalar value."
      ],
      "metadata": {
        "id": "ljg8YADbNYJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = 2 * b\n",
        "print(c)\n",
        "\n",
        "d = c + 1\n",
        "print(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcm6NX3cMUa4",
        "outputId": "df6f7445-07cb-4c7a-c88e-c543d9b8dd80"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.0000,  1.0047,  1.7375,  1.9999,  1.7211,  0.9764, -0.0326, -1.0328,\n",
            "        -1.7534, -1.9994, -1.7042, -0.9478,  0.0652,  1.0605,  1.7688,  1.9983,\n",
            "         1.6870,  0.9190, -0.0978, -1.0880], grad_fn=<MulBackward0>)\n",
            "tensor([ 1.0000,  2.0047,  2.7375,  2.9999,  2.7211,  1.9764,  0.9674, -0.0328,\n",
            "        -0.7534, -0.9994, -0.7042,  0.0522,  1.0652,  2.0605,  2.7688,  2.9983,\n",
            "         2.6870,  1.9190,  0.9022, -0.0880], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = d.sum()\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDjWzPfiMclS",
        "outputId": "4933afdf-762e-4ac3-d43a-cd89203f5dd0"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(26.2824, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use `grad_fn` to know how the current tensor came to be from the penultimate tensor. Also each grad_fn allows us to traverse the entire history with `next_functions`. Lets do so for \"d\" tensor."
      ],
      "metadata": {
        "id": "d9pD-MQJN1nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(d.grad_fn)                                                                                   # how d came to be  (by addition)\n",
        "print(d.grad_fn.next_functions)                                                                    # (mult)\n",
        "print(d.grad_fn.next_functions[0][0].next_functions)                                               # (exp)\n",
        "print(d.grad_fn.next_functions[0][0].next_functions[0][0].next_functions)                          # (gradient accumulated at leaf)\n",
        "print(d.grad_fn.next_functions[0][0].next_functions[0][0].next_functions[0][0].next_functions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg9P5b__ObMM",
        "outputId": "4c6151ba-40e0-4182-bc1c-825768c9bebb"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<AddBackward0 object at 0x7b6bf24b1540>\n",
            "((<MulBackward0 object at 0x7b6bf21db610>, 0), (None, 0))\n",
            "((<SinBackward0 object at 0x7b6bf24b1540>, 0), (None, 0))\n",
            "((<AccumulateGrad object at 0x7b6bf21d9ba0>, 0),)\n",
            "()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad_fn.next_functions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lz5B2BTPWdu",
        "outputId": "2eeb7aaf-f817-4536-f849-b72f9c3e3adc"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((<AccumulateGrad at 0x7b6bf21da140>, 0),)"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets call the **backward()** method on the output to get the gradients. To check the gradients with respect to inputs, we can simply use the **grad** attribute. Keep in mind that gradient is computed wrt leaf node. Here leaf node is a. Infact, PyTorch computes the gradients of out with respect to all the tensors that have \"requires_grad=True\"` and were involved in its computation.\n",
        "\n",
        "To obtain the gradients of intermediate tensors like b or c, you need to call .`retain_grad()` on them. This tells PyTorch to retain their gradients during the backward pass."
      ],
      "metadata": {
        "id": "hx5b0NPaSvMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retain gradients for intermediate tensors\n",
        "b.retain_grad()\n",
        "c.retain_grad()\n",
        "\n",
        "# Perform backward pass\n",
        "out.backward()             # if retain_graph parameter is set to false, can't call the same backward method on output twice without supplying the inputs(without making a computational graph once again)\n"
      ],
      "metadata": {
        "id": "7ObGRCA1aKCS"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5DIh3h2S6fF",
        "outputId": "e7dcfb23-40c6-4112-c020-77a702392f8e"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2.0000,  1.7293,  0.9906, -0.0163, -1.0188, -1.7455, -1.9997, -1.7127,\n",
              "        -0.9621,  0.0489,  1.0467,  1.7612,  1.9989,  1.6957,  0.9334, -0.0815,\n",
              "        -1.0743, -1.7764, -1.9976, -1.6781])"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrXsxsh5aNdr",
        "outputId": "ec23fc58-2ebc-4c4d-ccce-a41618101624"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "        2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCMMlTp2aQeF",
        "outputId": "67ca4ec6-b43f-48ec-b314-52271f771ed1"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "        1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall our overall computation:\n",
        "\n",
        "* a = torch.linspace(0., 2. * math.pi, steps=20, requires_grad=True)\n",
        "* b = torch.sin(a)\n",
        "* c = 2 * b\n",
        "* d = c + 1\n",
        "* out = d.sum()\n",
        "\n",
        "Please run a simple calculation on your copy (or head):\n",
        "\n",
        "* Gradient of out with respect to (wrt) d = 1\n",
        "* Gradient of d wrt c = 1\n",
        "* Gradient of c wrt b = 2\n",
        "* Gradient of b wrt a = cos(a)\n",
        "\n",
        "**Thus the derivative of out wrt a should be 2cos(a)**\n",
        "\n",
        "Now lets plot the gradient with respect to input and see if it's $2*\\cos(a)$.\n",
        "Looking at the graph below, that's just what we see. So the calculation is correct."
      ],
      "metadata": {
        "id": "AqJ-pSV7UWPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(a.detach(), a.grad.detach())    # matplotlib requires numpy (=  tensor.detach )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Imbcbkp5RftB",
        "outputId": "36411708-8b42-44ba-b24b-06a4bb9282e2"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7b6bf2617e50>]"
            ]
          },
          "metadata": {},
          "execution_count": 149
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ANN Implementation:\n",
        "Now that we know PyTorch is very similar to Numpy, let's get started with the actual motive of this notebook.\n",
        "\n",
        "### Learning Objectives:\n",
        "Here you will learn:\n",
        "* How to define a model with stack of multiple linear layers\n",
        "* How to define a dataloader, loss criterion, and optimizer\n",
        "* How to write a training loop with:\n",
        "  * Forward pass\n",
        "  * Computation of loss\n",
        "  * Computation of gradients\n",
        "  * Updating the parameters by the optimizer\n",
        "\n",
        "\\\n",
        "\n",
        "#### **First we we will begin with the detail implementation of all the minor steps. Then we will jump into the standard pipeline**"
      ],
      "metadata": {
        "id": "4wxVNzAuHDMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Network Architecture:\n",
        "Lets begin by building neural network architecture.\n",
        "The architecture looks something like this:\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=18Z0NofFLsTIxW4zBdILxcMEczhd113c4\" alt=\"ANN\" height=\"550\" width=\"650\">\n",
        "\n",
        "Figure 1: Neural Network with two hidden layers\n",
        "</center>\n",
        "\n",
        "In the above figure, the layers with the number of neurons are:\n",
        "* First layer = 10 neurons\n",
        "* Second layer = 16 neurons\n",
        "* Third layer = 8 neurons\n",
        "* Fourt layer = 1 neuron\n"
      ],
      "metadata": {
        "id": "5uoIaa9ZQiwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: It is important to note that the term `layer` can create some confusion due to hasty use of words in different situations. It may refer to any of the following:\n",
        "\n",
        "1. The set of neurons at a specific depth in the network.\n",
        "2. The computational transformation (connections and operations) applied to the inputs to produce the outputs.\n",
        "\n",
        "We referred to the first point in the above figure, when we talked about adding the number of neurons at each layer.\n",
        "In PyTorch, the word layer (or linear layer) refers to the second point. That is, the first linear layer refer to the transformation between the input layer and the first hidden layer. The second linear layer is the connection between first hidden layer and second hidden layer, and so on.\n",
        "\n",
        "Here,`torch.nn.Linear(in_features, out_features)` defines a fully connected layer (also known as a dense layer), which specifies the transformation from in_features to out_features. So, when you see torch.nn.Linear(10, 16), it means:\n",
        "\n",
        "  * There are 10 input features (neurons in the previous layer).\n",
        "  * There are 16 output features (neurons in the next layer)."
      ],
      "metadata": {
        "id": "4x7X79qIlxb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "k05m2kCjpIVZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear1 = nn.Linear(10,16)\n",
        "print(linear1)\n",
        "\n",
        "linear2 = nn.Linear(16,8)\n",
        "print(linear2)\n",
        "\n",
        "linear3 = nn.Linear(8,1)\n",
        "print(linear3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WD436PspL7W",
        "outputId": "689af334-7d4c-4fa2-f008-c6dd82edd6e1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=10, out_features=16, bias=True)\n",
            "Linear(in_features=16, out_features=8, bias=True)\n",
            "Linear(in_features=8, out_features=1, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forward Pass (manually):\n",
        "At each linear layer, the computation `[w].[X] + b` is done.\n",
        "\n",
        "In PyTorch, this is done by `w @ X + b`\n",
        "\n",
        "Lets create an input and pass it to the first dense layer to see the intermediate output (of the first dense layer) for ourselves."
      ],
      "metadata": {
        "id": "WcwTSFfGtDGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "input1 = torch.randn(10)   # input to the model (fixed set of random numbers for reproducibility)\n",
        "input1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki7sEbY1yPDk",
        "outputId": "a4d5afab-3072-4880-e471-fcf99794dcce"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380,\n",
              "         0.4617,  0.2674])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input to linear1:\\n\",input1, sep = '')\n",
        "\n",
        "output1 = linear1(input1)                           # input fed to the first dense layer\n",
        "print(\"\\nOutput of linear1:\\n\",output1, sep = '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22S1xWMmsehQ",
        "outputId": "9eae37f5-9976-4263-937b-5824c7e7e331"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input to linear1:\n",
            "tensor([ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380,\n",
            "         0.4617,  0.2674])\n",
            "\n",
            "Output of linear1:\n",
            "tensor([-0.4508,  0.2718, -0.0172,  0.0688,  0.2971, -0.2571,  0.3474, -0.7919,\n",
            "        -0.3481,  0.0846, -0.2356,  0.7046,  0.6394,  0.7833,  0.3670,  0.2439],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of input:\", input1.shape)\n",
        "print(\"Shape of output:\", output1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Kje3KfCvDY7",
        "outputId": "3b681d7a-6542-401a-c39d-0e37a9890613"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of input: torch.Size([10])\n",
            "Shape of output: torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, lets pass the output1 as input to linear2, then lets pass the output of linear2 as input to linear3."
      ],
      "metadata": {
        "id": "JpoHktSguWRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output2 = linear2(output1)\n",
        "print(output2)\n",
        "print(output1.shape)\n",
        "print(output2.shape)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "output3 = linear3(output2)\n",
        "print(output3)\n",
        "print(output2.shape)\n",
        "print(output3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjwcxsgUufvW",
        "outputId": "316b1615-dc2d-4df2-9313-cf0447491e8d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.1445,  0.3474,  0.4835,  0.2445, -0.1360, -0.2979,  0.1422,  0.0023],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "torch.Size([16])\n",
            "torch.Size([8])\n",
            "\n",
            "\n",
            "tensor([-0.5047], grad_fn=<ViewBackward0>)\n",
            "torch.Size([8])\n",
            "torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forward Pass (Model instantiation):\n",
        "Voila! We just completed a forward pass by manually writing the code by specifying inputs to each neuron for each layers. (Here `input1` is the input to the model and `output3 = 0.3403` is the final output of the model.) However, our approach was exhausting. Luckily, PyTorch offers a solution.\n",
        "\n",
        "Instead, lets stack all the layers in a single place using `nn.Sequential`. This way we can instantiate our model as a black box instead of manually specifying the inputs for each neurons."
      ],
      "metadata": {
        "id": "Ne1tTmk7wId5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # layer1, layer2, layer3 are already defined above, so we can stack directly\n",
        "\n",
        "model = nn.Sequential(linear1, linear2, linear3)   # instantiation as \"model\"\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GgPLcYTxMFm",
        "outputId": "1339a118-4f24-48e4-8fc1-51eccceacd68"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=10, out_features=16, bias=True)\n",
              "  (1): Linear(in_features=16, out_features=8, bias=True)\n",
              "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets suppy the same input to the model and check if the output obtained will be same."
      ],
      "metadata": {
        "id": "SBAOzsQtxurn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_output = model(input1)\n",
        "print(model_output)\n",
        "print(model_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns4PaFcLyLL9",
        "outputId": "a7ff3dfc-1bd5-49c8-a292-1b4aa9cebfbf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.5047], grad_fn=<ViewBackward0>)\n",
            "torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we can see that `output3 = model_output = 0.3403`"
      ],
      "metadata": {
        "id": "Kr4qpJVMz_W4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With Activation function:\n",
        "Until now, the model is simple, it is not able to properly learn non-linearity. Lets add activation function to the model. There are various activation functions, but they shall not be discussed here.\n",
        "\n",
        "Lets instantiate a different model named `model2` that has activation functions as well.  Lets change the architecture just a little bit so that there are 2 neurons in the output layer as well."
      ],
      "metadata": {
        "id": "bKxxE1Mz0JJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear1 = nn.Linear(10,16)\n",
        "linear2 = nn.Linear(16,8)\n",
        "linear3 = nn.Linear(8,2)\n",
        "\n",
        "model2 = nn.Sequential(\n",
        "    linear1,\n",
        "    nn.LeakyReLU(0.02),\n",
        "    linear2,\n",
        "    nn.Sigmoid(),\n",
        "    linear3,\n",
        "    nn.Softmax(dim = -1)\n",
        ")\n",
        "model2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX8OJTJw1eAv",
        "outputId": "71fb1cd3-739a-4c78-9359-60d3bc05030f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=10, out_features=16, bias=True)\n",
              "  (1): LeakyReLU(negative_slope=0.02)\n",
              "  (2): Linear(in_features=16, out_features=8, bias=True)\n",
              "  (3): Sigmoid()\n",
              "  (4): Linear(in_features=8, out_features=2, bias=True)\n",
              "  (5): Softmax(dim=-1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_of_model = model2(input1)\n",
        "print(output_of_model)\n",
        "\n",
        "print(\"The output class is \", torch.argmax(output_of_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOF7vems8iEL",
        "outputId": "320bda77-ebc4-466b-ebd4-1d516a3beb01"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4489, 0.5511], grad_fn=<SoftmaxBackward0>)\n",
            "The output class is  tensor(1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we have modified 'model2' from 'model' just a little bit so that the output layer has 2 neurons. Softmax is applied to the outermost layer so that the raw logits is converted into probabilites.\n",
        "\n",
        "Sigmoid function is a good activation function that squeezes the numbers in a range [0,1]. This is suitable for binary classification problem by thresholding the output at a certain value (like 0.5 can be chosen as a threshold and numbers below 0.5 are negative class while numbers above 0.5 are positive class).\n",
        "\n",
        "For multiclass classification, softmax function is used to convert the raw output logits to the probablitites of each classes, ensuring that the total sum of probabilitites is 1.\n",
        "\n",
        "`prob = nn.Softmax(dim = -1)`\n",
        "\n",
        "Here prob is the tensor of shape `model_output.shape` which has the probability values of a particular input belonging to the different classes.\n"
      ],
      "metadata": {
        "id": "7psI_QqO550A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backpropagation and weight updation:\n",
        "\n",
        "### Ground Truth Creation and One-Hot Encoding:\n",
        "\n",
        "Lets create the ground truth ourselves.\n",
        "\n",
        "Until now, we have:\n",
        "* Input = `input1` = [ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380, 0.4617,  0.2674]\n",
        "* Output = `output_of_model` = [prob1, prob2]\n",
        "\n",
        "  ( We could also say Output = torch.argmax([prob1, prob2]) = class )\n",
        "\n",
        "Now we can create ground truth as:\n",
        "* GT = `actual_output` = [actual_prob1, actual_prob2]\n",
        "\n",
        "But often in real world dataset, the ground truth could only mention the target class instead of probabilities such as:\n",
        "* GT = `actual_output` = Class 0\n",
        "\n",
        "In such case, how do we compare `output_of_model` and `actual_output` to calculate loss function?? Here they are simply incompatible in shape!!\n",
        "\n",
        "We can instead encode the `actual_output` in a shape similar to `output_of_model` for better comparison.\n",
        "\n",
        "\\\n",
        "\n",
        "Lets say the output is class2. So the objective is to make it [0, 1] so that it can be compared to [prob1, prob2]"
      ],
      "metadata": {
        "id": "USoKkHte--ZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "actual_output_class = 0\n",
        "\n",
        "actual_output_one_hot = F.one_hot(torch.tensor(actual_output_class), num_classes=2).float()\n",
        "print(\"One-hot encoded ground truth:\", actual_output_one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnx4SiFVCUZQ",
        "outputId": "02a83986-2b05-496b-d494-0181ea4e2fc7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot encoded ground truth: tensor([1., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss Function criterion:\n",
        "\n",
        "Until now, the model has just been able to compute output without learning anything. It is not able to learn anything yet because we haven't specififed the loss function. Loss function calculates the deviation of the model output from the ground truth. Without loss function calculation, the model can't calculate how much it has deviated from the truth, thus it can't be able to determine the direction it should go to  minimize the loss.\n",
        "\n",
        "The \"direction\" that model must go to minimize the loss function is given by `gradient`. Gradient is the partial derivative of loss with respect to the learnable parameters (weights and biases), so that the parameters can be updated and model can learn.\n",
        "\n",
        "For classification task, lets choose crossentropy loss as our loss criterion."
      ],
      "metadata": {
        "id": "VKD_pbBH2VAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criteria = nn.CrossEntropyLoss()                           # this is defined before the training loop\n",
        "criteria"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CUVdF-C5w36",
        "outputId": "27e0ad99-dd95-45ba-a69e-9fb7cda59ff1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_of_model = model2(input1)\n",
        "print(output_of_model)\n",
        "print(actual_output_one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSbHPC4VOrtX",
        "outputId": "354c2c95-2b2a-4217-dd4d-d8ef0441bb03"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4489, 0.5511], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([1., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = criteria(output_of_model, actual_output_one_hot)      # this will be done in the training loop.\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBAd_R7c-bYm",
        "outputId": "da502186-cb69-4aa0-b039-b36cdac0b3d3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7456, grad_fn=<DivBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward(retain_graph = True)"
      ],
      "metadata": {
        "id": "x5GB-Fs7M9MO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weights and Gradients:\n",
        "We can access the parameters and gradients at each layers."
      ],
      "metadata": {
        "id": "TnqK6F6lJBGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing parameters of specific layers\n",
        "print(\"Linear1 weights:\", model2[0].weight)\n",
        "print(\"Linear1 biases:\", model2[0].bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NamvhAv9ME6g",
        "outputId": "4ff07f77-3874-4582-8638-3a99c55ebeff"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear1 weights: Parameter containing:\n",
            "tensor([[-0.1457, -0.0371, -0.1284,  0.2098, -0.2496, -0.1458, -0.0893, -0.1901,\n",
            "          0.0298, -0.3123],\n",
            "        [ 0.2856, -0.2686,  0.2441,  0.0526, -0.1027,  0.1954,  0.0493,  0.2555,\n",
            "          0.0346, -0.0997],\n",
            "        [ 0.0850, -0.0858,  0.1331,  0.2823,  0.1828, -0.1382,  0.1825,  0.0566,\n",
            "          0.1606, -0.1927],\n",
            "        [-0.3130, -0.1222, -0.2426,  0.2595,  0.0911,  0.1310,  0.1000, -0.0055,\n",
            "          0.2475, -0.2247],\n",
            "        [ 0.0199, -0.2158,  0.0975, -0.1089,  0.0969, -0.0659,  0.2623, -0.1874,\n",
            "         -0.1886, -0.1886],\n",
            "        [ 0.2844,  0.1054,  0.3043, -0.2610, -0.3137, -0.2474, -0.2127,  0.1281,\n",
            "          0.1132,  0.2628],\n",
            "        [-0.1633, -0.2156,  0.1678, -0.1278,  0.1919, -0.0750,  0.1809, -0.2457,\n",
            "         -0.1596,  0.0964],\n",
            "        [ 0.0669, -0.0806,  0.1885,  0.2150, -0.2293, -0.1688,  0.2896, -0.1067,\n",
            "         -0.1121, -0.3060],\n",
            "        [-0.1811,  0.0790, -0.0417, -0.2295,  0.0074, -0.2160, -0.2683, -0.1741,\n",
            "         -0.2768, -0.2014],\n",
            "        [ 0.3161,  0.0597,  0.0974, -0.2949, -0.2077, -0.1053,  0.0494, -0.2783,\n",
            "         -0.1363, -0.1893],\n",
            "        [ 0.0009, -0.1177, -0.0219, -0.2143, -0.2171, -0.1845, -0.1082, -0.2496,\n",
            "          0.2651, -0.0628],\n",
            "        [ 0.2721,  0.0985, -0.2678,  0.2188, -0.0870, -0.1212, -0.2625, -0.3144,\n",
            "          0.0905, -0.0691],\n",
            "        [ 0.1231, -0.2595,  0.2348, -0.2321, -0.0546,  0.0661,  0.1633,  0.2553,\n",
            "          0.2881, -0.2507],\n",
            "        [ 0.0796, -0.1360, -0.0347, -0.2367,  0.2880, -0.2321,  0.1690,  0.1111,\n",
            "          0.1028, -0.1710],\n",
            "        [ 0.2874,  0.0695,  0.0407, -0.2787,  0.1327, -0.0474, -0.1449,  0.2716,\n",
            "          0.0705, -0.1750],\n",
            "        [-0.1601, -0.0151,  0.1766, -0.0808, -0.1804, -0.1083, -0.2362,  0.1128,\n",
            "          0.2448, -0.2977]], requires_grad=True)\n",
            "Linear1 biases: Parameter containing:\n",
            "tensor([ 0.0734,  0.1634,  0.0573, -0.1126,  0.1651,  0.1662,  0.1182, -0.0556,\n",
            "        -0.0837,  0.0338, -0.0559, -0.0942,  0.2021,  0.2718, -0.0313, -0.0708],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the gradients of the first layer's parameters\n",
        "print(\"Gradients of Linear1 weights:\", model2[0].weight.grad)\n",
        "print(\"Gradients of Linear1 biases:\", model2[0].bias.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlqo8SC-Nlex",
        "outputId": "89f62c59-2229-4ca0-c4bd-b7e74afcb7a2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients of Linear1 weights: tensor([[-1.1016e-03, -4.2145e-04, -7.6714e-04, -7.5363e-04,  3.6739e-03,\n",
            "          6.0965e-04, -7.2250e-03,  2.0875e-03, -1.5105e-03, -8.7474e-04],\n",
            "        [-7.7563e-04, -2.9674e-04, -5.4013e-04, -5.3062e-04,  2.5867e-03,\n",
            "          4.2924e-04, -5.0870e-03,  1.4697e-03, -1.0635e-03, -6.1589e-04],\n",
            "        [ 1.8456e-04,  7.0609e-05,  1.2852e-04,  1.2626e-04, -6.1551e-04,\n",
            "         -1.0214e-04,  1.2105e-03, -3.4973e-04,  2.5307e-04,  1.4655e-04],\n",
            "        [ 1.1969e-05,  4.5789e-06,  8.3346e-06,  8.1878e-06, -3.9915e-05,\n",
            "         -6.6235e-06,  7.8496e-05, -2.2679e-05,  1.6411e-05,  9.5037e-06],\n",
            "        [-3.0357e-03, -1.1614e-03, -2.1140e-03, -2.0767e-03,  1.0124e-02,\n",
            "          1.6800e-03, -1.9910e-02,  5.7524e-03, -4.1624e-03, -2.4105e-03],\n",
            "        [-3.0969e-03, -1.1848e-03, -2.1566e-03, -2.1186e-03,  1.0328e-02,\n",
            "          1.7139e-03, -2.0311e-02,  5.8683e-03, -4.2463e-03, -2.4591e-03],\n",
            "        [-6.3868e-04, -2.4434e-04, -4.4476e-04, -4.3693e-04,  2.1300e-03,\n",
            "          3.5345e-04, -4.1888e-03,  1.2102e-03, -8.7574e-04, -5.0715e-04],\n",
            "        [-3.0471e-04, -1.1658e-04, -2.1220e-04, -2.0846e-04,  1.0162e-03,\n",
            "          1.6863e-04, -1.9985e-03,  5.7741e-04, -4.1781e-04, -2.4196e-04],\n",
            "        [ 4.2807e-07,  1.6377e-07,  2.9810e-07,  2.9285e-07, -1.4276e-06,\n",
            "         -2.3690e-07,  2.8075e-06, -8.1116e-07,  5.8696e-07,  3.3991e-07],\n",
            "        [ 2.0199e-03,  7.7275e-04,  1.4066e-03,  1.3818e-03, -6.7362e-03,\n",
            "         -1.1178e-03,  1.3247e-02, -3.8275e-03,  2.7696e-03,  1.6039e-03],\n",
            "        [ 8.3624e-04,  3.1992e-04,  5.8234e-04,  5.7208e-04, -2.7888e-03,\n",
            "         -4.6278e-04,  5.4845e-03, -1.5846e-03,  1.1466e-03,  6.6402e-04],\n",
            "        [-2.1093e-05, -8.0697e-06, -1.4689e-05, -1.4430e-05,  7.0346e-05,\n",
            "          1.1673e-05, -1.3834e-04,  3.9970e-05, -2.8922e-05, -1.6749e-05],\n",
            "        [-6.5745e-03, -2.5152e-03, -4.5783e-03, -4.4977e-03,  2.1926e-02,\n",
            "          3.6384e-03, -4.3119e-02,  1.2458e-02, -9.0147e-03, -5.2205e-03],\n",
            "        [ 4.0126e-03,  1.5351e-03,  2.7942e-03,  2.7450e-03, -1.3382e-02,\n",
            "         -2.2206e-03,  2.6317e-02, -7.6034e-03,  5.5019e-03,  3.1862e-03],\n",
            "        [-1.5682e-05, -5.9997e-06, -1.0921e-05, -1.0728e-05,  5.2300e-05,\n",
            "          8.6788e-06, -1.0285e-04,  2.9717e-05, -2.1503e-05, -1.2453e-05],\n",
            "        [ 6.8444e-05,  2.6185e-05,  4.7662e-05,  4.6823e-05, -2.2826e-04,\n",
            "         -3.7877e-05,  4.4889e-04, -1.2969e-04,  9.3847e-05,  5.4348e-05]])\n",
            "Gradients of Linear1 biases: tensor([-3.2719e-03, -2.3037e-03,  5.4817e-04,  3.5548e-05, -9.0163e-03,\n",
            "        -9.1980e-03, -1.8969e-03, -9.0503e-04,  1.2714e-06,  5.9992e-03,\n",
            "         2.4837e-03, -6.2649e-05, -1.9527e-02,  1.1918e-02, -4.6578e-05,\n",
            "         2.0328e-04])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weight updation:\n",
        "\n",
        "We could update the weights of the first layers using the formula:\n",
        "\n",
        "`model2[0].weight = model2[0].weight - learning_rate * model2[0].weight.grad`.\n",
        "\n",
        "But there are various reasons we don't do so. They are:\n",
        "\n",
        "1. PyTorch doesn't allow assigning a new tensor to a parameter.\n",
        "\n",
        "  Thus, we can instead do this:\n",
        "\n",
        "  `model2[0].weight -= learning_rate * model2[0].weight.grad`\n",
        "\n",
        "2. Even though the above update works, Non-convex functions dont converge easily, so we need a proper optimizer to update the weights.\n",
        "\n",
        "  Thus we may use one of the most popular, simple and effective optimizer called `SGD`"
      ],
      "metadata": {
        "id": "OBhIi-bXhWde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "mlPixvw6gdt4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model2[0].weight -= learning_rate * model2[0].weight.grad    # updation using the above point number 1.\n",
        "    model2[0].bias -= learning_rate * model2[0].bias.grad"
      ],
      "metadata": {
        "id": "ni041PiHNS8Z"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the gradients of the first layer's parameters\n",
        "print(\"Gradients of Linear1 weights:\", model2[0].weight.grad)\n",
        "print(\"Gradients of Linear1 biases:\", model2[0].bias.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYqaWOjOOfri",
        "outputId": "d34e21ec-0917-43f4-c294-0534b2cc8c0a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradients of Linear1 weights: tensor([[-1.1016e-03, -4.2145e-04, -7.6714e-04, -7.5363e-04,  3.6739e-03,\n",
            "          6.0965e-04, -7.2250e-03,  2.0875e-03, -1.5105e-03, -8.7474e-04],\n",
            "        [-7.7563e-04, -2.9674e-04, -5.4013e-04, -5.3062e-04,  2.5867e-03,\n",
            "          4.2924e-04, -5.0870e-03,  1.4697e-03, -1.0635e-03, -6.1589e-04],\n",
            "        [ 1.8456e-04,  7.0609e-05,  1.2852e-04,  1.2626e-04, -6.1551e-04,\n",
            "         -1.0214e-04,  1.2105e-03, -3.4973e-04,  2.5307e-04,  1.4655e-04],\n",
            "        [ 1.1969e-05,  4.5789e-06,  8.3346e-06,  8.1878e-06, -3.9915e-05,\n",
            "         -6.6235e-06,  7.8496e-05, -2.2679e-05,  1.6411e-05,  9.5037e-06],\n",
            "        [-3.0357e-03, -1.1614e-03, -2.1140e-03, -2.0767e-03,  1.0124e-02,\n",
            "          1.6800e-03, -1.9910e-02,  5.7524e-03, -4.1624e-03, -2.4105e-03],\n",
            "        [-3.0969e-03, -1.1848e-03, -2.1566e-03, -2.1186e-03,  1.0328e-02,\n",
            "          1.7139e-03, -2.0311e-02,  5.8683e-03, -4.2463e-03, -2.4591e-03],\n",
            "        [-6.3868e-04, -2.4434e-04, -4.4476e-04, -4.3693e-04,  2.1300e-03,\n",
            "          3.5345e-04, -4.1888e-03,  1.2102e-03, -8.7574e-04, -5.0715e-04],\n",
            "        [-3.0471e-04, -1.1658e-04, -2.1220e-04, -2.0846e-04,  1.0162e-03,\n",
            "          1.6863e-04, -1.9985e-03,  5.7741e-04, -4.1781e-04, -2.4196e-04],\n",
            "        [ 4.2807e-07,  1.6377e-07,  2.9810e-07,  2.9285e-07, -1.4276e-06,\n",
            "         -2.3690e-07,  2.8075e-06, -8.1116e-07,  5.8696e-07,  3.3991e-07],\n",
            "        [ 2.0199e-03,  7.7275e-04,  1.4066e-03,  1.3818e-03, -6.7362e-03,\n",
            "         -1.1178e-03,  1.3247e-02, -3.8275e-03,  2.7696e-03,  1.6039e-03],\n",
            "        [ 8.3624e-04,  3.1992e-04,  5.8234e-04,  5.7208e-04, -2.7888e-03,\n",
            "         -4.6278e-04,  5.4845e-03, -1.5846e-03,  1.1466e-03,  6.6402e-04],\n",
            "        [-2.1093e-05, -8.0697e-06, -1.4689e-05, -1.4430e-05,  7.0346e-05,\n",
            "          1.1673e-05, -1.3834e-04,  3.9970e-05, -2.8922e-05, -1.6749e-05],\n",
            "        [-6.5745e-03, -2.5152e-03, -4.5783e-03, -4.4977e-03,  2.1926e-02,\n",
            "          3.6384e-03, -4.3119e-02,  1.2458e-02, -9.0147e-03, -5.2205e-03],\n",
            "        [ 4.0126e-03,  1.5351e-03,  2.7942e-03,  2.7450e-03, -1.3382e-02,\n",
            "         -2.2206e-03,  2.6317e-02, -7.6034e-03,  5.5019e-03,  3.1862e-03],\n",
            "        [-1.5682e-05, -5.9997e-06, -1.0921e-05, -1.0728e-05,  5.2300e-05,\n",
            "          8.6788e-06, -1.0285e-04,  2.9717e-05, -2.1503e-05, -1.2453e-05],\n",
            "        [ 6.8444e-05,  2.6185e-05,  4.7662e-05,  4.6823e-05, -2.2826e-04,\n",
            "         -3.7877e-05,  4.4889e-04, -1.2969e-04,  9.3847e-05,  5.4348e-05]])\n",
            "Gradients of Linear1 biases: tensor([-3.2719e-03, -2.3037e-03,  5.4817e-04,  3.5548e-05, -9.0163e-03,\n",
            "        -9.1980e-03, -1.8969e-03, -9.0503e-04,  1.2714e-06,  5.9992e-03,\n",
            "         2.4837e-03, -6.2649e-05, -1.9527e-02,  1.1918e-02, -4.6578e-05,\n",
            "         2.0328e-04])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation Pipeline:\n",
        "\n",
        "#### **Actual standard pipeline begins here. Until now we have just played with the PyTorch syntax to see the minor details in model building and training**"
      ],
      "metadata": {
        "id": "u5z2JOQupHCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing and DataLoader:\n",
        "\n",
        "Lets first load the dataset. Here we can use sklearn.datasets only to load the data."
      ],
      "metadata": {
        "id": "8KxIkt5OOj5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=5000, n_features=10, n_redundant=0, n_informative=3, n_clusters_per_class=2, n_classes=2)"
      ],
      "metadata": {
        "id": "WgKkeUV7RMe1"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zc6aJoiUvoW",
        "outputId": "09b39a10-3012-4fa3-a8ec-9dd2f557b2c1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 10)\n",
            "(5000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "ROFBfQntW-jg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.unique(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6F9bHoxufJS",
        "outputId": "7e09b7ba-001a-46bf-90ae-2b5b7094858e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uu1ehaaXIe6",
        "outputId": "3bd974cb-a22c-4ca7-c19d-021206bd03a8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4000, 10)\n",
            "(4000,)\n",
            "(1000, 10)\n",
            "(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets preprocess the dataset now.\n",
        "\n",
        "Lets create a class called `CustomDataset` inheriting the properties of `torch.utils.data.Dataset`.\n",
        "\n",
        "This class will contain various user-defined functions (methods) that carry out simple tasks that may be needed later."
      ],
      "metadata": {
        "id": "cfSUGVsaXauu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    # method to initialize dataset, and conversion to tensor\n",
        "    def __init__(self, X_train, y_train):\n",
        "        self.X = torch.from_numpy(X_train.astype(np.float32))\n",
        "        self.y = torch.from_numpy(y_train).type(torch.LongTensor)\n",
        "        self.len = self.X.shape[0]\n",
        "\n",
        "    # method to return a single sample from the dataset given an index.\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index]\n",
        "\n",
        "    # method to return the number of samples in the dataset.\n",
        "    def __len__(self):\n",
        "        return self.len\n"
      ],
      "metadata": {
        "id": "lHvemxZgXgV6"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So what did we achieve from the above class and its methods? Nothing fancy really, lets check by accessing the sample by both methods-without and with the help of above class' method."
      ],
      "metadata": {
        "id": "Y-UblJTib47m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[25])                                     # simple access\n",
        "\n",
        "traindata = CustomDataset(X_train, y_train)\n",
        "print(traindata[25])                                   # access with above class' method"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MxTH8zhYDE5",
        "outputId": "8aa10ff3-6771-49d1-b875-53b67a508270"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.88813082 -0.72732207  1.28919598  1.27135308 -1.03232921 -1.73411435\n",
            " -0.9962748   0.19894904 -1.75137951 -0.07612058]\n",
            "(tensor([ 0.8881, -0.7273,  1.2892,  1.2714, -1.0323, -1.7341, -0.9963,  0.1989,\n",
            "        -1.7514, -0.0761]), tensor(1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets get to the important part of creating a dataloader. DataLoader combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
        "\n",
        "Benefits of Using DataLoader:\n",
        "\n",
        "  * Batching: Automatically handles batching of data.\n",
        "  * Shuffling: Easily shuffle data at each epoch.\n",
        "  * Parallel Data Loading: Load data in parallel using multiple workers for faster data loading."
      ],
      "metadata": {
        "id": "r90vwBw-ccKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "trainloader = DataLoader(traindata, batch_size = 4)"
      ],
      "metadata": {
        "id": "DuoGk__scrjV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"trainloader\" is now an `iterable` that is instantiated from DataLoader class.\n",
        "\n",
        "What's the use? Well, instead of accessing just X_train and y_train, we can now access the training examples in batches. That means the iterable trainloader has batches of X_train and y_train.\n",
        "\n",
        "Lets call them `batch_X` and `batch_y`. These will be used in the training loop to speed up the computation. (Remember that we used to just use X_train and y_train without batches before)"
      ],
      "metadata": {
        "id": "HpOWgj4ZeG0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the TrainLoader\n",
        "\n",
        "for batch_X, batch_y in trainloader:\n",
        "    print(batch_X.shape, batch_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-mzBhtMc8vO",
        "outputId": "09eb6861-f731-4370-c2b7-45fde8b2d0bf"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n",
            "torch.Size([4, 10]) torch.Size([4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recreating the model within a Class:\n",
        "\n",
        "Creating a Class allows for more flexibility and is the standard practice for building models.\n",
        "\n",
        "Remember we previously created a model called `model2` with activation functions and all? Well, lets write that architecture within a custom Class called `Network`. It inherits from the parent class nn.Module.\n",
        "\n",
        "* The parent class must be initialized within the constructor of the child class.\n",
        "* `super(Network, self).__init__()` can be used to call the constructor of the parent class.\n"
      ],
      "metadata": {
        "id": "JIPJOVPMh8GQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "\n",
        "    # Define the layers and all in the constructor.\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()  # Initialize parent class within the constructor\n",
        "        self.linear1 = nn.Linear(10, 16)\n",
        "        self.leaky_relu = nn.LeakyReLU()\n",
        "        self.linear2 = nn.Linear(16, 8)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.linear3 = nn.Linear(8, 2)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    # Method for forward pass\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.leaky_relu(x)\n",
        "        x = self.linear2(x)  # Pass input to the linear2 layer\n",
        "        x = self.sigmoid(x)  # Pass input to the sigmoid layer\n",
        "        x = self.linear3(x)  # Pass input to the linear3 layer\n",
        "        x = self.softmax(x)  # Pass input to the softmax layer\n",
        "        return x"
      ],
      "metadata": {
        "id": "5vbfeGcah7jB"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets instantiate our model. In this approach, we can just call our custom class, and the constructor will be automatically called. The constructor has the layers, and thus the model is instantiated."
      ],
      "metadata": {
        "id": "lVwfMnQXnnx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = Network()\n",
        "print(model3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJmtQg6Rn85r",
        "outputId": "f9e62cec-c780-447a-f360-4a701aa328e2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Network(\n",
            "  (linear1): Linear(in_features=10, out_features=16, bias=True)\n",
            "  (leaky_relu): LeakyReLU(negative_slope=0.01)\n",
            "  (linear2): Linear(in_features=16, out_features=8, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            "  (linear3): Linear(in_features=8, out_features=2, bias=True)\n",
            "  (softmax): Softmax(dim=-1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer and Loss Functions (Definition):\n",
        "\n",
        "Here loss function and optimizer are defined only. They are used inside the training loop when:\n",
        "* `loss = criterion (target, predicted)` parameters are supplied\n",
        "* `optimizer.step()` is done to update the parameters."
      ],
      "metadata": {
        "id": "RGpl6bzDozdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "print(criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqes-LEsoIrm",
        "outputId": "b0fbcba6-8ca2-44a0-a050-f2d849e1db3d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CrossEntropyLoss()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(model3.parameters(), lr = 0.001)\n",
        "print(optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvmZyPnfrDbN",
        "outputId": "2c9cbc93-795e-4ac0-f944-dcc0ae5cc572"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Writing a Training Loop:\n",
        "\n",
        "Unlike in TensorFlow, where you'd call `fit` method, you should write your own training loop in PyTorch.\n",
        "\n",
        "Steps:\n",
        "1. Set gradients to zero: `optimizer.zero_grad()`\n",
        "2. Run forward pass:  `predicted = model(features)`\n",
        "3. Calculate loss: `loss = criterion(target,predicted)`\n",
        "4. Calculate gradients : `loss.backward()`\n",
        "5. Update weights : `optimizer.step()`\n",
        "\n",
        "\n",
        "### Evaluation:\n",
        "\n",
        "6. For train loss:\n",
        "  * In training loop, use `train_loss += loss.item()` and `epoch_loss = train_loss/len(trainloader)`\n",
        "\n",
        "7. For validation loss:\n",
        "  * First put model in eval mode, because some layers behave differently in validation mode. `model.eval()`\n",
        "  * Set no gradient mode: `with torch.no_grad()`\n",
        "  * In training loop (with validationloader), `use val_loss = loss.item()` and `epoch_loss = val_loss/len(validationloader)`\n",
        "  * Set model back to train mode for next epoch: `model.train()`\n",
        "\n",
        "8. For accuracy:\n",
        "  * Use `metric = torchmetrics.Accuracy(task = \"multiclass\", num_class = number)`\n",
        "  * In training loop, use `acc = metric(outputs, labels.argmax(dim = -1)`\n",
        "  * Use `acc = metric.compute()`\n",
        "  * Reset metric for next epoch: `metric.reset()`"
      ],
      "metadata": {
        "id": "B-I2q9d4I5ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "epoch_loss = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  train_loss = 0\n",
        "  for batch_X, batch_y in trainloader:\n",
        "    optimizer.zero_grad()\n",
        "    predicted = model3(batch_X)                      # forward pass in batches\n",
        "    loss = criterion(predicted, batch_y)\n",
        "    loss.backward()                                  # gradient calculation with help of loss\n",
        "    optimizer.step()                                 # weight update\n",
        "\n",
        "    # Evaluation example\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    # After processing all batches, calculate average loss for the epoch\n",
        "    average_loss = train_loss / len(trainloader)\n",
        "    epoch_loss.append(average_loss)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {average_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WeqdJgH6JrB",
        "outputId": "80a49a9d-5494-4687-9cf5-66df47d1182f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 6/10, Loss: 0.0006925097703933716\n",
            "Epoch 6/10, Loss: 0.0013859906196594237\n",
            "Epoch 6/10, Loss: 0.0020798425674438477\n",
            "Epoch 6/10, Loss: 0.002774678885936737\n",
            "Epoch 6/10, Loss: 0.0034560810327529906\n",
            "Epoch 6/10, Loss: 0.0041492058634758\n",
            "Epoch 6/10, Loss: 0.004834515154361725\n",
            "Epoch 6/10, Loss: 0.005528079926967621\n",
            "Epoch 6/10, Loss: 0.0062104352116584775\n",
            "Epoch 6/10, Loss: 0.0068897224068641665\n",
            "Epoch 6/10, Loss: 0.007574898898601532\n",
            "Epoch 6/10, Loss: 0.008257112324237823\n",
            "Epoch 6/10, Loss: 0.00894071751832962\n",
            "Epoch 6/10, Loss: 0.00963509601354599\n",
            "Epoch 6/10, Loss: 0.010334896326065064\n",
            "Epoch 6/10, Loss: 0.011035058856010437\n",
            "Epoch 6/10, Loss: 0.011739851713180541\n",
            "Epoch 6/10, Loss: 0.012412951469421387\n",
            "Epoch 6/10, Loss: 0.013113734483718872\n",
            "Epoch 6/10, Loss: 0.01380626618862152\n",
            "Epoch 6/10, Loss: 0.014499263525009156\n",
            "Epoch 6/10, Loss: 0.015191304922103882\n",
            "Epoch 6/10, Loss: 0.0158888578414917\n",
            "Epoch 6/10, Loss: 0.01657461380958557\n",
            "Epoch 6/10, Loss: 0.017253323793411254\n",
            "Epoch 6/10, Loss: 0.017923304855823517\n",
            "Epoch 6/10, Loss: 0.018613898694515227\n",
            "Epoch 6/10, Loss: 0.019305029511451723\n",
            "Epoch 6/10, Loss: 0.019998877704143523\n",
            "Epoch 6/10, Loss: 0.02069477719068527\n",
            "Epoch 6/10, Loss: 0.021382068574428557\n",
            "Epoch 6/10, Loss: 0.022079233944416046\n",
            "Epoch 6/10, Loss: 0.022775700271129608\n",
            "Epoch 6/10, Loss: 0.023473193764686585\n",
            "Epoch 6/10, Loss: 0.024178562343120574\n",
            "Epoch 6/10, Loss: 0.024860387444496156\n",
            "Epoch 6/10, Loss: 0.025553991198539735\n",
            "Epoch 6/10, Loss: 0.026242617905139924\n",
            "Epoch 6/10, Loss: 0.026926298320293425\n",
            "Epoch 6/10, Loss: 0.027617410600185393\n",
            "Epoch 6/10, Loss: 0.028306344747543333\n",
            "Epoch 6/10, Loss: 0.02899594712257385\n",
            "Epoch 6/10, Loss: 0.02969968867301941\n",
            "Epoch 6/10, Loss: 0.03039833801984787\n",
            "Epoch 6/10, Loss: 0.031100383400917052\n",
            "Epoch 6/10, Loss: 0.031781495332717895\n",
            "Epoch 6/10, Loss: 0.032472488522529604\n",
            "Epoch 6/10, Loss: 0.033163567006587985\n",
            "Epoch 6/10, Loss: 0.03386791586875915\n",
            "Epoch 6/10, Loss: 0.03456769895553589\n",
            "Epoch 6/10, Loss: 0.03526715612411499\n",
            "Epoch 6/10, Loss: 0.03594844383001328\n",
            "Epoch 6/10, Loss: 0.03664359551668167\n",
            "Epoch 6/10, Loss: 0.037328146278858186\n",
            "Epoch 6/10, Loss: 0.03802634423971176\n",
            "Epoch 6/10, Loss: 0.03872994941473007\n",
            "Epoch 6/10, Loss: 0.039423186123371125\n",
            "Epoch 6/10, Loss: 0.04011274689435959\n",
            "Epoch 6/10, Loss: 0.04081544107198715\n",
            "Epoch 6/10, Loss: 0.041504269540309904\n",
            "Epoch 6/10, Loss: 0.04219226711988449\n",
            "Epoch 6/10, Loss: 0.04288504177331925\n",
            "Epoch 6/10, Loss: 0.04357113665342331\n",
            "Epoch 6/10, Loss: 0.044277735710144046\n",
            "Epoch 6/10, Loss: 0.04496518576145172\n",
            "Epoch 6/10, Loss: 0.0456510272026062\n",
            "Epoch 6/10, Loss: 0.04634375458955765\n",
            "Epoch 6/10, Loss: 0.047031648814678195\n",
            "Epoch 6/10, Loss: 0.04773806422948837\n",
            "Epoch 6/10, Loss: 0.04844054591655731\n",
            "Epoch 6/10, Loss: 0.049135591328144074\n",
            "Epoch 6/10, Loss: 0.049824107825756074\n",
            "Epoch 6/10, Loss: 0.05051444035768509\n",
            "Epoch 6/10, Loss: 0.051207374155521394\n",
            "Epoch 6/10, Loss: 0.051902332305908204\n",
            "Epoch 6/10, Loss: 0.05259017717838287\n",
            "Epoch 6/10, Loss: 0.053292007982730864\n",
            "Epoch 6/10, Loss: 0.053985788762569424\n",
            "Epoch 6/10, Loss: 0.054674280166625976\n",
            "Epoch 6/10, Loss: 0.05536839652061462\n",
            "Epoch 6/10, Loss: 0.05605670565366745\n",
            "Epoch 6/10, Loss: 0.0567334446310997\n",
            "Epoch 6/10, Loss: 0.057424837052822114\n",
            "Epoch 6/10, Loss: 0.05811514109373093\n",
            "Epoch 6/10, Loss: 0.05878939479589462\n",
            "Epoch 6/10, Loss: 0.05947913366556168\n",
            "Epoch 6/10, Loss: 0.060171589314937594\n",
            "Epoch 6/10, Loss: 0.06086825424432755\n",
            "Epoch 6/10, Loss: 0.06155789130926132\n",
            "Epoch 6/10, Loss: 0.06223950117826462\n",
            "Epoch 6/10, Loss: 0.06293461185693741\n",
            "Epoch 6/10, Loss: 0.0636188594698906\n",
            "Epoch 6/10, Loss: 0.06430650359392166\n",
            "Epoch 6/10, Loss: 0.06500221061706543\n",
            "Epoch 6/10, Loss: 0.06569057178497315\n",
            "Epoch 6/10, Loss: 0.06637096077203751\n",
            "Epoch 6/10, Loss: 0.0670573183298111\n",
            "Epoch 6/10, Loss: 0.06773331218957901\n",
            "Epoch 6/10, Loss: 0.06841808813810349\n",
            "Epoch 6/10, Loss: 0.06911822825670243\n",
            "Epoch 6/10, Loss: 0.06981048381328583\n",
            "Epoch 6/10, Loss: 0.07049151700735092\n",
            "Epoch 6/10, Loss: 0.07118187755346299\n",
            "Epoch 6/10, Loss: 0.07187219971418381\n",
            "Epoch 6/10, Loss: 0.07255815041065217\n",
            "Epoch 6/10, Loss: 0.07323292887210846\n",
            "Epoch 6/10, Loss: 0.07393297362327576\n",
            "Epoch 6/10, Loss: 0.07462695395946503\n",
            "Epoch 6/10, Loss: 0.07531459176540375\n",
            "Epoch 6/10, Loss: 0.07600155854225159\n",
            "Epoch 6/10, Loss: 0.07668657976388932\n",
            "Epoch 6/10, Loss: 0.07738128501176834\n",
            "Epoch 6/10, Loss: 0.07807777291536332\n",
            "Epoch 6/10, Loss: 0.07876444047689438\n",
            "Epoch 6/10, Loss: 0.07945289379358292\n",
            "Epoch 6/10, Loss: 0.08015693235397339\n",
            "Epoch 6/10, Loss: 0.08084337669610978\n",
            "Epoch 6/10, Loss: 0.08153490155935288\n",
            "Epoch 6/10, Loss: 0.08222090524435044\n",
            "Epoch 6/10, Loss: 0.08291285759210587\n",
            "Epoch 6/10, Loss: 0.08359650737047196\n",
            "Epoch 6/10, Loss: 0.08428004825115204\n",
            "Epoch 6/10, Loss: 0.08496980649232865\n",
            "Epoch 6/10, Loss: 0.08566925364732743\n",
            "Epoch 6/10, Loss: 0.08636231273412705\n",
            "Epoch 6/10, Loss: 0.08705534350872039\n",
            "Epoch 6/10, Loss: 0.08774918484687805\n",
            "Epoch 6/10, Loss: 0.08844776678085327\n",
            "Epoch 6/10, Loss: 0.08914851129055024\n",
            "Epoch 6/10, Loss: 0.08983988153934479\n",
            "Epoch 6/10, Loss: 0.0905389688014984\n",
            "Epoch 6/10, Loss: 0.0912267016172409\n",
            "Epoch 6/10, Loss: 0.09191799354553222\n",
            "Epoch 6/10, Loss: 0.09260671204328537\n",
            "Epoch 6/10, Loss: 0.09328066235780716\n",
            "Epoch 6/10, Loss: 0.09396553152799607\n",
            "Epoch 6/10, Loss: 0.09466380113363267\n",
            "Epoch 6/10, Loss: 0.09535169667005539\n",
            "Epoch 6/10, Loss: 0.09604283499717713\n",
            "Epoch 6/10, Loss: 0.09674285590648651\n",
            "Epoch 6/10, Loss: 0.09743699806928635\n",
            "Epoch 6/10, Loss: 0.09812499350309371\n",
            "Epoch 6/10, Loss: 0.09881811648607254\n",
            "Epoch 6/10, Loss: 0.09952112984657288\n",
            "Epoch 6/10, Loss: 0.10021070551872253\n",
            "Epoch 6/10, Loss: 0.10090431624650956\n",
            "Epoch 6/10, Loss: 0.10159569746255874\n",
            "Epoch 6/10, Loss: 0.10229510909318924\n",
            "Epoch 6/10, Loss: 0.10297619634866714\n",
            "Epoch 6/10, Loss: 0.10365463042259217\n",
            "Epoch 6/10, Loss: 0.10434907448291779\n",
            "Epoch 6/10, Loss: 0.10503720557689666\n",
            "Epoch 6/10, Loss: 0.10572673064470291\n",
            "Epoch 6/10, Loss: 0.10640888398885727\n",
            "Epoch 6/10, Loss: 0.10710081076622009\n",
            "Epoch 6/10, Loss: 0.10778419494628906\n",
            "Epoch 6/10, Loss: 0.1084723402261734\n",
            "Epoch 6/10, Loss: 0.10915912503004074\n",
            "Epoch 6/10, Loss: 0.10984510254859925\n",
            "Epoch 6/10, Loss: 0.11053327500820159\n",
            "Epoch 6/10, Loss: 0.11121769034862518\n",
            "Epoch 6/10, Loss: 0.11191374617815018\n",
            "Epoch 6/10, Loss: 0.11260342925786972\n",
            "Epoch 6/10, Loss: 0.11329386109113693\n",
            "Epoch 6/10, Loss: 0.11397833609580994\n",
            "Epoch 6/10, Loss: 0.11466591393947602\n",
            "Epoch 6/10, Loss: 0.11535823369026184\n",
            "Epoch 6/10, Loss: 0.11604933965206146\n",
            "Epoch 6/10, Loss: 0.11674514126777649\n",
            "Epoch 6/10, Loss: 0.11743640631437302\n",
            "Epoch 6/10, Loss: 0.11812944346666336\n",
            "Epoch 6/10, Loss: 0.11881262528896332\n",
            "Epoch 6/10, Loss: 0.11950223886966706\n",
            "Epoch 6/10, Loss: 0.1201990031003952\n",
            "Epoch 6/10, Loss: 0.12090379875898362\n",
            "Epoch 6/10, Loss: 0.1216012812256813\n",
            "Epoch 6/10, Loss: 0.12228406101465225\n",
            "Epoch 6/10, Loss: 0.12296931624412537\n",
            "Epoch 6/10, Loss: 0.12366087752580643\n",
            "Epoch 6/10, Loss: 0.12435495448112488\n",
            "Epoch 6/10, Loss: 0.1250539736151695\n",
            "Epoch 6/10, Loss: 0.12574112671613694\n",
            "Epoch 6/10, Loss: 0.12643458032608032\n",
            "Epoch 6/10, Loss: 0.1271295404434204\n",
            "Epoch 6/10, Loss: 0.127812770485878\n",
            "Epoch 6/10, Loss: 0.1285118453502655\n",
            "Epoch 6/10, Loss: 0.12919775307178497\n",
            "Epoch 6/10, Loss: 0.12989565867185593\n",
            "Epoch 6/10, Loss: 0.1305796068906784\n",
            "Epoch 6/10, Loss: 0.13126049494743347\n",
            "Epoch 6/10, Loss: 0.13194967353343964\n",
            "Epoch 6/10, Loss: 0.1326464688181877\n",
            "Epoch 6/10, Loss: 0.13333059018850327\n",
            "Epoch 6/10, Loss: 0.13402378100156784\n",
            "Epoch 6/10, Loss: 0.13470433223247527\n",
            "Epoch 6/10, Loss: 0.13539071398973465\n",
            "Epoch 6/10, Loss: 0.13607960337400438\n",
            "Epoch 6/10, Loss: 0.13676553505659103\n",
            "Epoch 6/10, Loss: 0.1374511039853096\n",
            "Epoch 6/10, Loss: 0.1381348152756691\n",
            "Epoch 6/10, Loss: 0.13881537407636643\n",
            "Epoch 6/10, Loss: 0.13951125597953795\n",
            "Epoch 6/10, Loss: 0.14020441806316375\n",
            "Epoch 6/10, Loss: 0.14089640635252\n",
            "Epoch 6/10, Loss: 0.14158940696716307\n",
            "Epoch 6/10, Loss: 0.14228777688741684\n",
            "Epoch 6/10, Loss: 0.1429824160337448\n",
            "Epoch 6/10, Loss: 0.14367493402957915\n",
            "Epoch 6/10, Loss: 0.14436035138368605\n",
            "Epoch 6/10, Loss: 0.14505775624513625\n",
            "Epoch 6/10, Loss: 0.14576332956552507\n",
            "Epoch 6/10, Loss: 0.14645776605606078\n",
            "Epoch 6/10, Loss: 0.14714645165205\n",
            "Epoch 6/10, Loss: 0.1478424837589264\n",
            "Epoch 6/10, Loss: 0.14852275264263154\n",
            "Epoch 6/10, Loss: 0.14922346192598343\n",
            "Epoch 6/10, Loss: 0.14991341161727906\n",
            "Epoch 6/10, Loss: 0.15060562360286714\n",
            "Epoch 6/10, Loss: 0.15129017698764802\n",
            "Epoch 6/10, Loss: 0.1519839366674423\n",
            "Epoch 6/10, Loss: 0.1526827830672264\n",
            "Epoch 6/10, Loss: 0.1533788600564003\n",
            "Epoch 6/10, Loss: 0.15406312531232833\n",
            "Epoch 6/10, Loss: 0.15476330924034118\n",
            "Epoch 6/10, Loss: 0.15545179212093355\n",
            "Epoch 6/10, Loss: 0.15613695806264877\n",
            "Epoch 6/10, Loss: 0.15682863527536392\n",
            "Epoch 6/10, Loss: 0.15751962864398955\n",
            "Epoch 6/10, Loss: 0.15820510190725326\n",
            "Epoch 6/10, Loss: 0.1588964883685112\n",
            "Epoch 6/10, Loss: 0.159585526406765\n",
            "Epoch 6/10, Loss: 0.16027651983499527\n",
            "Epoch 6/10, Loss: 0.1609790764451027\n",
            "Epoch 6/10, Loss: 0.1616713346838951\n",
            "Epoch 6/10, Loss: 0.16236434304714203\n",
            "Epoch 6/10, Loss: 0.163055095911026\n",
            "Epoch 6/10, Loss: 0.16374601686000825\n",
            "Epoch 6/10, Loss: 0.16442457419633866\n",
            "Epoch 6/10, Loss: 0.16510745960474013\n",
            "Epoch 6/10, Loss: 0.16579935139417648\n",
            "Epoch 6/10, Loss: 0.16649022936820984\n",
            "Epoch 6/10, Loss: 0.16719300788640976\n",
            "Epoch 6/10, Loss: 0.1678877256512642\n",
            "Epoch 6/10, Loss: 0.16858114743232727\n",
            "Epoch 6/10, Loss: 0.1692714352607727\n",
            "Epoch 6/10, Loss: 0.16996045029163362\n",
            "Epoch 6/10, Loss: 0.1706541901230812\n",
            "Epoch 6/10, Loss: 0.17133672595024108\n",
            "Epoch 6/10, Loss: 0.17202836310863495\n",
            "Epoch 6/10, Loss: 0.1727247884273529\n",
            "Epoch 6/10, Loss: 0.17339994758367538\n",
            "Epoch 6/10, Loss: 0.17409206873178482\n",
            "Epoch 6/10, Loss: 0.17478398603200912\n",
            "Epoch 6/10, Loss: 0.17547641015052795\n",
            "Epoch 6/10, Loss: 0.17616846251487733\n",
            "Epoch 6/10, Loss: 0.17686573988199233\n",
            "Epoch 6/10, Loss: 0.1775525408387184\n",
            "Epoch 6/10, Loss: 0.17824027144908905\n",
            "Epoch 6/10, Loss: 0.17893628203868867\n",
            "Epoch 6/10, Loss: 0.17963531064987182\n",
            "Epoch 6/10, Loss: 0.18033629083633423\n",
            "Epoch 6/10, Loss: 0.18102223712205887\n",
            "Epoch 6/10, Loss: 0.18170733088254928\n",
            "Epoch 6/10, Loss: 0.18238966423273087\n",
            "Epoch 6/10, Loss: 0.18307433158159256\n",
            "Epoch 6/10, Loss: 0.1837582179903984\n",
            "Epoch 6/10, Loss: 0.18446271312236787\n",
            "Epoch 6/10, Loss: 0.18516813677549362\n",
            "Epoch 6/10, Loss: 0.18587329906225206\n",
            "Epoch 6/10, Loss: 0.18656362700462342\n",
            "Epoch 6/10, Loss: 0.18726768350601197\n",
            "Epoch 6/10, Loss: 0.1879565010666847\n",
            "Epoch 6/10, Loss: 0.188641310274601\n",
            "Epoch 6/10, Loss: 0.18933139914274216\n",
            "Epoch 6/10, Loss: 0.19002229708433152\n",
            "Epoch 6/10, Loss: 0.1907297263741493\n",
            "Epoch 6/10, Loss: 0.19142852145433426\n",
            "Epoch 6/10, Loss: 0.19211665731668473\n",
            "Epoch 6/10, Loss: 0.1927974387407303\n",
            "Epoch 6/10, Loss: 0.1935039085149765\n",
            "Epoch 6/10, Loss: 0.194195845246315\n",
            "Epoch 6/10, Loss: 0.19488571691513062\n",
            "Epoch 6/10, Loss: 0.19556969213485717\n",
            "Epoch 6/10, Loss: 0.19625840073823927\n",
            "Epoch 6/10, Loss: 0.19695953160524368\n",
            "Epoch 6/10, Loss: 0.19764930152893068\n",
            "Epoch 6/10, Loss: 0.19833526051044464\n",
            "Epoch 6/10, Loss: 0.19902909559011459\n",
            "Epoch 6/10, Loss: 0.19971163588762283\n",
            "Epoch 6/10, Loss: 0.20040898239612578\n",
            "Epoch 6/10, Loss: 0.2011028109192848\n",
            "Epoch 6/10, Loss: 0.20179594486951827\n",
            "Epoch 6/10, Loss: 0.20247629785537719\n",
            "Epoch 6/10, Loss: 0.20318539559841156\n",
            "Epoch 6/10, Loss: 0.20387486773729324\n",
            "Epoch 6/10, Loss: 0.20457826626300812\n",
            "Epoch 6/10, Loss: 0.20529147762060165\n",
            "Epoch 6/10, Loss: 0.20598019248247146\n",
            "Epoch 6/10, Loss: 0.20667126071453096\n",
            "Epoch 6/10, Loss: 0.2073620519042015\n",
            "Epoch 6/10, Loss: 0.20805027669668197\n",
            "Epoch 6/10, Loss: 0.20873028719425202\n",
            "Epoch 6/10, Loss: 0.20942794770002365\n",
            "Epoch 6/10, Loss: 0.2101204052567482\n",
            "Epoch 6/10, Loss: 0.21081795412302018\n",
            "Epoch 6/10, Loss: 0.21151521402597429\n",
            "Epoch 6/10, Loss: 0.21220067709684373\n",
            "Epoch 6/10, Loss: 0.21288553518056869\n",
            "Epoch 6/10, Loss: 0.21356968653202058\n",
            "Epoch 6/10, Loss: 0.21426631504297255\n",
            "Epoch 6/10, Loss: 0.2149618713259697\n",
            "Epoch 6/10, Loss: 0.21565956723690033\n",
            "Epoch 6/10, Loss: 0.21635686337947846\n",
            "Epoch 6/10, Loss: 0.21704736244678496\n",
            "Epoch 6/10, Loss: 0.2177317681312561\n",
            "Epoch 6/10, Loss: 0.21842306172847747\n",
            "Epoch 6/10, Loss: 0.21912184870243073\n",
            "Epoch 6/10, Loss: 0.21980220741033554\n",
            "Epoch 6/10, Loss: 0.22049836659431457\n",
            "Epoch 6/10, Loss: 0.22118997061252593\n",
            "Epoch 6/10, Loss: 0.22187929785251617\n",
            "Epoch 6/10, Loss: 0.22256821870803833\n",
            "Epoch 6/10, Loss: 0.22326159358024597\n",
            "Epoch 6/10, Loss: 0.223950608253479\n",
            "Epoch 6/10, Loss: 0.22464479333162307\n",
            "Epoch 6/10, Loss: 0.2253336574435234\n",
            "Epoch 6/10, Loss: 0.22603283327817916\n",
            "Epoch 6/10, Loss: 0.22672118520736695\n",
            "Epoch 6/10, Loss: 0.2273972066640854\n",
            "Epoch 6/10, Loss: 0.22809701216220857\n",
            "Epoch 6/10, Loss: 0.22877111077308654\n",
            "Epoch 6/10, Loss: 0.22946827280521392\n",
            "Epoch 6/10, Loss: 0.23016519260406493\n",
            "Epoch 6/10, Loss: 0.23084983998537065\n",
            "Epoch 6/10, Loss: 0.2315399507880211\n",
            "Epoch 6/10, Loss: 0.23221568489074706\n",
            "Epoch 6/10, Loss: 0.23290419805049897\n",
            "Epoch 6/10, Loss: 0.23360554206371306\n",
            "Epoch 6/10, Loss: 0.2342966820001602\n",
            "Epoch 6/10, Loss: 0.23498124331235887\n",
            "Epoch 6/10, Loss: 0.2356656237244606\n",
            "Epoch 6/10, Loss: 0.23636011344194413\n",
            "Epoch 6/10, Loss: 0.23705410706996918\n",
            "Epoch 6/10, Loss: 0.2377594546675682\n",
            "Epoch 6/10, Loss: 0.2384572651386261\n",
            "Epoch 6/10, Loss: 0.23915610629320144\n",
            "Epoch 6/10, Loss: 0.23984387296438217\n",
            "Epoch 6/10, Loss: 0.24053333908319474\n",
            "Epoch 6/10, Loss: 0.241229739010334\n",
            "Epoch 6/10, Loss: 0.24192296522855758\n",
            "Epoch 6/10, Loss: 0.24262520730495452\n",
            "Epoch 6/10, Loss: 0.24332845675945283\n",
            "Epoch 6/10, Loss: 0.2440240107178688\n",
            "Epoch 6/10, Loss: 0.24472248005867003\n",
            "Epoch 6/10, Loss: 0.24540848153829575\n",
            "Epoch 6/10, Loss: 0.2461064583659172\n",
            "Epoch 6/10, Loss: 0.2467866724729538\n",
            "Epoch 6/10, Loss: 0.24747600829601288\n",
            "Epoch 6/10, Loss: 0.2481623959541321\n",
            "Epoch 6/10, Loss: 0.24884520494937898\n",
            "Epoch 6/10, Loss: 0.2495547577738762\n",
            "Epoch 6/10, Loss: 0.2502438284158707\n",
            "Epoch 6/10, Loss: 0.25093951547145843\n",
            "Epoch 6/10, Loss: 0.25163606166839597\n",
            "Epoch 6/10, Loss: 0.25232322001457214\n",
            "Epoch 6/10, Loss: 0.2530011165738106\n",
            "Epoch 6/10, Loss: 0.25368800139427183\n",
            "Epoch 6/10, Loss: 0.2543744777441025\n",
            "Epoch 6/10, Loss: 0.25506655824184415\n",
            "Epoch 6/10, Loss: 0.2557645423412323\n",
            "Epoch 6/10, Loss: 0.25645013827085494\n",
            "Epoch 6/10, Loss: 0.2571376799941063\n",
            "Epoch 6/10, Loss: 0.25783652704954146\n",
            "Epoch 6/10, Loss: 0.25853339755535126\n",
            "Epoch 6/10, Loss: 0.25923485881090164\n",
            "Epoch 6/10, Loss: 0.25992181783914564\n",
            "Epoch 6/10, Loss: 0.2606115630269051\n",
            "Epoch 6/10, Loss: 0.2613066270947456\n",
            "Epoch 6/10, Loss: 0.26200124430656435\n",
            "Epoch 6/10, Loss: 0.26269276881217957\n",
            "Epoch 6/10, Loss: 0.26338631504774096\n",
            "Epoch 6/10, Loss: 0.2640797915458679\n",
            "Epoch 6/10, Loss: 0.26477452397346496\n",
            "Epoch 6/10, Loss: 0.2654772229790688\n",
            "Epoch 6/10, Loss: 0.2661640940308571\n",
            "Epoch 6/10, Loss: 0.26686580616235733\n",
            "Epoch 6/10, Loss: 0.26756841272115706\n",
            "Epoch 6/10, Loss: 0.26825184255838397\n",
            "Epoch 6/10, Loss: 0.2689344631433487\n",
            "Epoch 6/10, Loss: 0.26961996012926104\n",
            "Epoch 6/10, Loss: 0.27031661713123323\n",
            "Epoch 6/10, Loss: 0.2710112573504448\n",
            "Epoch 6/10, Loss: 0.271703929066658\n",
            "Epoch 6/10, Loss: 0.2723815686702728\n",
            "Epoch 6/10, Loss: 0.2730709698796272\n",
            "Epoch 6/10, Loss: 0.2737574266791344\n",
            "Epoch 6/10, Loss: 0.2744588608145714\n",
            "Epoch 6/10, Loss: 0.2751465686559677\n",
            "Epoch 6/10, Loss: 0.27584385812282564\n",
            "Epoch 6/10, Loss: 0.2765341123342514\n",
            "Epoch 6/10, Loss: 0.2772363865375519\n",
            "Epoch 6/10, Loss: 0.27792553889751437\n",
            "Epoch 6/10, Loss: 0.27861554741859434\n",
            "Epoch 6/10, Loss: 0.2793002588152885\n",
            "Epoch 6/10, Loss: 0.27999769324064255\n",
            "Epoch 6/10, Loss: 0.28068051075935363\n",
            "Epoch 6/10, Loss: 0.2813687015771866\n",
            "Epoch 6/10, Loss: 0.28206745064258576\n",
            "Epoch 6/10, Loss: 0.28276203870773314\n",
            "Epoch 6/10, Loss: 0.28343558037281036\n",
            "Epoch 6/10, Loss: 0.2841351501941681\n",
            "Epoch 6/10, Loss: 0.28483060878515243\n",
            "Epoch 6/10, Loss: 0.2855115637779236\n",
            "Epoch 6/10, Loss: 0.28619843792915345\n",
            "Epoch 6/10, Loss: 0.2868917732834816\n",
            "Epoch 6/10, Loss: 0.28758535170555116\n",
            "Epoch 6/10, Loss: 0.2882742898464203\n",
            "Epoch 6/10, Loss: 0.2889619176983833\n",
            "Epoch 6/10, Loss: 0.2896616432070732\n",
            "Epoch 6/10, Loss: 0.290350889980793\n",
            "Epoch 6/10, Loss: 0.2910403012037277\n",
            "Epoch 6/10, Loss: 0.29172476172447204\n",
            "Epoch 6/10, Loss: 0.29242656791210175\n",
            "Epoch 6/10, Loss: 0.2931106694340706\n",
            "Epoch 6/10, Loss: 0.2938018580675125\n",
            "Epoch 6/10, Loss: 0.2944962959289551\n",
            "Epoch 6/10, Loss: 0.29518163430690764\n",
            "Epoch 6/10, Loss: 0.2958689601421356\n",
            "Epoch 6/10, Loss: 0.2965480963587761\n",
            "Epoch 6/10, Loss: 0.2972397164106369\n",
            "Epoch 6/10, Loss: 0.29792285174131394\n",
            "Epoch 6/10, Loss: 0.29860761266946795\n",
            "Epoch 6/10, Loss: 0.29928619945049284\n",
            "Epoch 6/10, Loss: 0.2999817494750023\n",
            "Epoch 6/10, Loss: 0.3006735437512398\n",
            "Epoch 6/10, Loss: 0.30135818403959275\n",
            "Epoch 6/10, Loss: 0.30204557567834855\n",
            "Epoch 6/10, Loss: 0.3027343766093254\n",
            "Epoch 6/10, Loss: 0.30342001086473464\n",
            "Epoch 6/10, Loss: 0.3041142832040787\n",
            "Epoch 6/10, Loss: 0.30480454355478287\n",
            "Epoch 6/10, Loss: 0.30549115842580793\n",
            "Epoch 6/10, Loss: 0.3061767721772194\n",
            "Epoch 6/10, Loss: 0.30686603623628617\n",
            "Epoch 6/10, Loss: 0.307563949406147\n",
            "Epoch 6/10, Loss: 0.3082443588972092\n",
            "Epoch 6/10, Loss: 0.3089243018627167\n",
            "Epoch 6/10, Loss: 0.30961932986974716\n",
            "Epoch 6/10, Loss: 0.31030229991674424\n",
            "Epoch 6/10, Loss: 0.3109856978058815\n",
            "Epoch 6/10, Loss: 0.3116713687777519\n",
            "Epoch 6/10, Loss: 0.31236366838216784\n",
            "Epoch 6/10, Loss: 0.3130586677193642\n",
            "Epoch 6/10, Loss: 0.31375654220581056\n",
            "Epoch 6/10, Loss: 0.31446708154678343\n",
            "Epoch 6/10, Loss: 0.31514940088987353\n",
            "Epoch 6/10, Loss: 0.31583536678552626\n",
            "Epoch 6/10, Loss: 0.3165187250375748\n",
            "Epoch 6/10, Loss: 0.31720442962646483\n",
            "Epoch 6/10, Loss: 0.31789801228046416\n",
            "Epoch 6/10, Loss: 0.31859471154212954\n",
            "Epoch 6/10, Loss: 0.31927412098646163\n",
            "Epoch 6/10, Loss: 0.3199720950722694\n",
            "Epoch 6/10, Loss: 0.3206657677292824\n",
            "Epoch 6/10, Loss: 0.3213651462197304\n",
            "Epoch 6/10, Loss: 0.32206009298563004\n",
            "Epoch 6/10, Loss: 0.32276810830831526\n",
            "Epoch 6/10, Loss: 0.32344551223516466\n",
            "Epoch 6/10, Loss: 0.32412773185968397\n",
            "Epoch 6/10, Loss: 0.32481067985296247\n",
            "Epoch 6/10, Loss: 0.3254896671175957\n",
            "Epoch 6/10, Loss: 0.3261946759819984\n",
            "Epoch 6/10, Loss: 0.3268966952562332\n",
            "Epoch 6/10, Loss: 0.3275756841301918\n",
            "Epoch 6/10, Loss: 0.3282779965996742\n",
            "Epoch 6/10, Loss: 0.3289621636271477\n",
            "Epoch 6/10, Loss: 0.3296517567038536\n",
            "Epoch 6/10, Loss: 0.33034380239248273\n",
            "Epoch 6/10, Loss: 0.331053006708622\n",
            "Epoch 6/10, Loss: 0.3317473030090332\n",
            "Epoch 6/10, Loss: 0.3324322089552879\n",
            "Epoch 6/10, Loss: 0.333129940032959\n",
            "Epoch 6/10, Loss: 0.3338367403745651\n",
            "Epoch 6/10, Loss: 0.3345213589668274\n",
            "Epoch 6/10, Loss: 0.3352087761163712\n",
            "Epoch 6/10, Loss: 0.33590030926465986\n",
            "Epoch 6/10, Loss: 0.33660244435071945\n",
            "Epoch 6/10, Loss: 0.33728634649515155\n",
            "Epoch 6/10, Loss: 0.337982419192791\n",
            "Epoch 6/10, Loss: 0.3386782383918762\n",
            "Epoch 6/10, Loss: 0.3393665771484375\n",
            "Epoch 6/10, Loss: 0.3400522038340569\n",
            "Epoch 6/10, Loss: 0.3407436455488205\n",
            "Epoch 6/10, Loss: 0.34144931942224505\n",
            "Epoch 6/10, Loss: 0.3421341921687126\n",
            "Epoch 6/10, Loss: 0.34282056909799574\n",
            "Epoch 6/10, Loss: 0.34352640610933305\n",
            "Epoch 6/10, Loss: 0.3442301516532898\n",
            "Epoch 6/10, Loss: 0.3449193341135979\n",
            "Epoch 6/10, Loss: 0.34560267060995103\n",
            "Epoch 6/10, Loss: 0.3462981590628624\n",
            "Epoch 6/10, Loss: 0.346987650513649\n",
            "Epoch 6/10, Loss: 0.34769329726696013\n",
            "Epoch 6/10, Loss: 0.348382004737854\n",
            "Epoch 6/10, Loss: 0.349075608253479\n",
            "Epoch 6/10, Loss: 0.3497639091014862\n",
            "Epoch 6/10, Loss: 0.3504675300121307\n",
            "Epoch 6/10, Loss: 0.3511522741317749\n",
            "Epoch 6/10, Loss: 0.3518411133289337\n",
            "Epoch 6/10, Loss: 0.35253602010011675\n",
            "Epoch 6/10, Loss: 0.3532386682629585\n",
            "Epoch 6/10, Loss: 0.35393632447719575\n",
            "Epoch 6/10, Loss: 0.3546218842864037\n",
            "Epoch 6/10, Loss: 0.35531026661396026\n",
            "Epoch 6/10, Loss: 0.3560082002282143\n",
            "Epoch 6/10, Loss: 0.3567072162628174\n",
            "Epoch 6/10, Loss: 0.3574032714962959\n",
            "Epoch 6/10, Loss: 0.35809641098976136\n",
            "Epoch 6/10, Loss: 0.358795469224453\n",
            "Epoch 6/10, Loss: 0.3594832881093025\n",
            "Epoch 6/10, Loss: 0.3601716167330742\n",
            "Epoch 6/10, Loss: 0.36086155551671983\n",
            "Epoch 6/10, Loss: 0.36154278296232223\n",
            "Epoch 6/10, Loss: 0.362239875972271\n",
            "Epoch 6/10, Loss: 0.3629250683784485\n",
            "Epoch 6/10, Loss: 0.3636333600282669\n",
            "Epoch 6/10, Loss: 0.3643310722708702\n",
            "Epoch 6/10, Loss: 0.36501520782709124\n",
            "Epoch 6/10, Loss: 0.365694768846035\n",
            "Epoch 6/10, Loss: 0.36638863772153857\n",
            "Epoch 6/10, Loss: 0.36707883661985397\n",
            "Epoch 6/10, Loss: 0.36777523678541185\n",
            "Epoch 6/10, Loss: 0.36847805815935136\n",
            "Epoch 6/10, Loss: 0.36917318296432494\n",
            "Epoch 6/10, Loss: 0.36986400610208514\n",
            "Epoch 6/10, Loss: 0.37056361478567124\n",
            "Epoch 6/10, Loss: 0.37125392532348633\n",
            "Epoch 6/10, Loss: 0.3719522383213043\n",
            "Epoch 6/10, Loss: 0.3726452488899231\n",
            "Epoch 6/10, Loss: 0.37333831679821017\n",
            "Epoch 6/10, Loss: 0.3740324625968933\n",
            "Epoch 6/10, Loss: 0.37470899748802183\n",
            "Epoch 6/10, Loss: 0.3753913516998291\n",
            "Epoch 6/10, Loss: 0.3760805178880692\n",
            "Epoch 6/10, Loss: 0.37676691663265227\n",
            "Epoch 6/10, Loss: 0.3774528361558914\n",
            "Epoch 6/10, Loss: 0.3781405628323555\n",
            "Epoch 6/10, Loss: 0.3788278676271439\n",
            "Epoch 6/10, Loss: 0.37952089565992353\n",
            "Epoch 6/10, Loss: 0.38021650904417037\n",
            "Epoch 6/10, Loss: 0.38090698438882825\n",
            "Epoch 6/10, Loss: 0.3815993884801865\n",
            "Epoch 6/10, Loss: 0.3822951065301895\n",
            "Epoch 6/10, Loss: 0.3829756165742874\n",
            "Epoch 6/10, Loss: 0.3836637402176857\n",
            "Epoch 6/10, Loss: 0.38434757947921755\n",
            "Epoch 6/10, Loss: 0.38504103642702103\n",
            "Epoch 6/10, Loss: 0.3857220945954323\n",
            "Epoch 6/10, Loss: 0.38641783326864243\n",
            "Epoch 6/10, Loss: 0.3871098522543907\n",
            "Epoch 6/10, Loss: 0.38781241673231126\n",
            "Epoch 6/10, Loss: 0.3884996178150177\n",
            "Epoch 6/10, Loss: 0.3891847440600395\n",
            "Epoch 6/10, Loss: 0.38987578147649765\n",
            "Epoch 6/10, Loss: 0.3905656840205193\n",
            "Epoch 6/10, Loss: 0.3912549535632133\n",
            "Epoch 6/10, Loss: 0.39195150434970855\n",
            "Epoch 6/10, Loss: 0.3926460670828819\n",
            "Epoch 6/10, Loss: 0.39333855199813844\n",
            "Epoch 6/10, Loss: 0.3940333907008171\n",
            "Epoch 6/10, Loss: 0.3947076766490936\n",
            "Epoch 6/10, Loss: 0.39541021794080733\n",
            "Epoch 6/10, Loss: 0.39608486992120745\n",
            "Epoch 6/10, Loss: 0.39677209252119067\n",
            "Epoch 6/10, Loss: 0.39745703113079073\n",
            "Epoch 6/10, Loss: 0.3981530306339264\n",
            "Epoch 6/10, Loss: 0.39884940391778945\n",
            "Epoch 6/10, Loss: 0.39955253165960314\n",
            "Epoch 6/10, Loss: 0.40025151580572127\n",
            "Epoch 6/10, Loss: 0.400933556497097\n",
            "Epoch 6/10, Loss: 0.40161676251888273\n",
            "Epoch 6/10, Loss: 0.40230854070186617\n",
            "Epoch 6/10, Loss: 0.40300465530157087\n",
            "Epoch 6/10, Loss: 0.40368450379371645\n",
            "Epoch 6/10, Loss: 0.4043856813311577\n",
            "Epoch 6/10, Loss: 0.4050671333670616\n",
            "Epoch 6/10, Loss: 0.40575530964136125\n",
            "Epoch 6/10, Loss: 0.4064478095173836\n",
            "Epoch 6/10, Loss: 0.4071404346227646\n",
            "Epoch 6/10, Loss: 0.4078391292095184\n",
            "Epoch 6/10, Loss: 0.4085290160179138\n",
            "Epoch 6/10, Loss: 0.4092163465023041\n",
            "Epoch 6/10, Loss: 0.40990774041414263\n",
            "Epoch 6/10, Loss: 0.4106093905568123\n",
            "Epoch 6/10, Loss: 0.4113100330233574\n",
            "Epoch 6/10, Loss: 0.4120118266940117\n",
            "Epoch 6/10, Loss: 0.41270388865470886\n",
            "Epoch 6/10, Loss: 0.41339675104618073\n",
            "Epoch 6/10, Loss: 0.4140798044204712\n",
            "Epoch 6/10, Loss: 0.4147603393793106\n",
            "Epoch 6/10, Loss: 0.41545179080963135\n",
            "Epoch 6/10, Loss: 0.41614498442411424\n",
            "Epoch 6/10, Loss: 0.41683179277181626\n",
            "Epoch 6/10, Loss: 0.4175320034623146\n",
            "Epoch 6/10, Loss: 0.4182289224863052\n",
            "Epoch 6/10, Loss: 0.4189295989871025\n",
            "Epoch 6/10, Loss: 0.4196256747841835\n",
            "Epoch 6/10, Loss: 0.4203066734075546\n",
            "Epoch 6/10, Loss: 0.42099284040927887\n",
            "Epoch 6/10, Loss: 0.42168887782096864\n",
            "Epoch 6/10, Loss: 0.422386339366436\n",
            "Epoch 6/10, Loss: 0.4230705831646919\n",
            "Epoch 6/10, Loss: 0.4237698331475258\n",
            "Epoch 6/10, Loss: 0.42444179409742355\n",
            "Epoch 6/10, Loss: 0.4251410371661186\n",
            "Epoch 6/10, Loss: 0.4258333241343498\n",
            "Epoch 6/10, Loss: 0.4265293626785278\n",
            "Epoch 6/10, Loss: 0.4272194854617119\n",
            "Epoch 6/10, Loss: 0.4278960244655609\n",
            "Epoch 6/10, Loss: 0.42859021520614626\n",
            "Epoch 6/10, Loss: 0.4292790484428406\n",
            "Epoch 6/10, Loss: 0.42996909135580064\n",
            "Epoch 6/10, Loss: 0.43066746306419373\n",
            "Epoch 6/10, Loss: 0.431355019390583\n",
            "Epoch 6/10, Loss: 0.432041666328907\n",
            "Epoch 6/10, Loss: 0.43272956573963167\n",
            "Epoch 6/10, Loss: 0.4334256328940392\n",
            "Epoch 6/10, Loss: 0.43412851840257644\n",
            "Epoch 6/10, Loss: 0.43481183582544325\n",
            "Epoch 6/10, Loss: 0.4355126450061798\n",
            "Epoch 6/10, Loss: 0.43619767236709595\n",
            "Epoch 6/10, Loss: 0.4368800566196442\n",
            "Epoch 6/10, Loss: 0.4375869999527931\n",
            "Epoch 6/10, Loss: 0.4382798486351967\n",
            "Epoch 6/10, Loss: 0.4389760487675667\n",
            "Epoch 6/10, Loss: 0.439663242995739\n",
            "Epoch 6/10, Loss: 0.44036147969961165\n",
            "Epoch 6/10, Loss: 0.4410655358433723\n",
            "Epoch 6/10, Loss: 0.44175748109817503\n",
            "Epoch 6/10, Loss: 0.44244853758811953\n",
            "Epoch 6/10, Loss: 0.44313633733987806\n",
            "Epoch 6/10, Loss: 0.44382677322626113\n",
            "Epoch 6/10, Loss: 0.44451214212179185\n",
            "Epoch 6/10, Loss: 0.44521039694547654\n",
            "Epoch 6/10, Loss: 0.4458982834219933\n",
            "Epoch 6/10, Loss: 0.4465822057127953\n",
            "Epoch 6/10, Loss: 0.4472642058730125\n",
            "Epoch 6/10, Loss: 0.44795333689451217\n",
            "Epoch 6/10, Loss: 0.44863931250572203\n",
            "Epoch 6/10, Loss: 0.4493228565454483\n",
            "Epoch 6/10, Loss: 0.4500200508236885\n",
            "Epoch 6/10, Loss: 0.45073465585708616\n",
            "Epoch 6/10, Loss: 0.45143153750896453\n",
            "Epoch 6/10, Loss: 0.45213266587257384\n",
            "Epoch 6/10, Loss: 0.45283109378814695\n",
            "Epoch 6/10, Loss: 0.45351890099048614\n",
            "Epoch 6/10, Loss: 0.45421065598726273\n",
            "Epoch 6/10, Loss: 0.4549046842455864\n",
            "Epoch 6/10, Loss: 0.455599646627903\n",
            "Epoch 6/10, Loss: 0.45630000668764115\n",
            "Epoch 6/10, Loss: 0.4569866752028465\n",
            "Epoch 6/10, Loss: 0.4576776836514473\n",
            "Epoch 6/10, Loss: 0.4583537917137146\n",
            "Epoch 6/10, Loss: 0.4590421985387802\n",
            "Epoch 6/10, Loss: 0.45974450528621674\n",
            "Epoch 6/10, Loss: 0.4604329668283463\n",
            "Epoch 6/10, Loss: 0.4611240248084068\n",
            "Epoch 6/10, Loss: 0.46182304894924164\n",
            "Epoch 6/10, Loss: 0.46250913417339323\n",
            "Epoch 6/10, Loss: 0.4631865408420563\n",
            "Epoch 6/10, Loss: 0.46386591988801956\n",
            "Epoch 6/10, Loss: 0.46455500489473345\n",
            "Epoch 6/10, Loss: 0.4652437314987183\n",
            "Epoch 6/10, Loss: 0.4659330947995186\n",
            "Epoch 6/10, Loss: 0.46661534678936006\n",
            "Epoch 6/10, Loss: 0.4673152188062668\n",
            "Epoch 6/10, Loss: 0.4680049251914024\n",
            "Epoch 6/10, Loss: 0.4687019284963608\n",
            "Epoch 6/10, Loss: 0.4694020215272903\n",
            "Epoch 6/10, Loss: 0.47009541660547255\n",
            "Epoch 6/10, Loss: 0.470800652384758\n",
            "Epoch 6/10, Loss: 0.4714966216683388\n",
            "Epoch 6/10, Loss: 0.4721851434707642\n",
            "Epoch 6/10, Loss: 0.4728854621052742\n",
            "Epoch 6/10, Loss: 0.47358582985401154\n",
            "Epoch 6/10, Loss: 0.4742917232513428\n",
            "Epoch 6/10, Loss: 0.474984766125679\n",
            "Epoch 6/10, Loss: 0.47567375683784485\n",
            "Epoch 6/10, Loss: 0.47636023914813996\n",
            "Epoch 6/10, Loss: 0.4770530152916908\n",
            "Epoch 6/10, Loss: 0.47775475358963015\n",
            "Epoch 6/10, Loss: 0.47844533812999723\n",
            "Epoch 6/10, Loss: 0.47913129353523254\n",
            "Epoch 6/10, Loss: 0.47981608974933626\n",
            "Epoch 6/10, Loss: 0.4805070445537567\n",
            "Epoch 6/10, Loss: 0.4811963839530945\n",
            "Epoch 6/10, Loss: 0.48188730293512344\n",
            "Epoch 6/10, Loss: 0.4825806416273117\n",
            "Epoch 6/10, Loss: 0.4832681930065155\n",
            "Epoch 6/10, Loss: 0.4839664036631584\n",
            "Epoch 6/10, Loss: 0.48466347688436506\n",
            "Epoch 6/10, Loss: 0.4853603784441948\n",
            "Epoch 6/10, Loss: 0.4860565914511681\n",
            "Epoch 6/10, Loss: 0.48674643754959107\n",
            "Epoch 6/10, Loss: 0.4874430488348007\n",
            "Epoch 6/10, Loss: 0.48812967240810395\n",
            "Epoch 6/10, Loss: 0.4888148765563965\n",
            "Epoch 6/10, Loss: 0.48950294679403306\n",
            "Epoch 6/10, Loss: 0.4902071391940117\n",
            "Epoch 6/10, Loss: 0.49089920562505723\n",
            "Epoch 6/10, Loss: 0.4915872530341148\n",
            "Epoch 6/10, Loss: 0.4922761133313179\n",
            "Epoch 6/10, Loss: 0.4929708599448204\n",
            "Epoch 6/10, Loss: 0.49366165363788606\n",
            "Epoch 6/10, Loss: 0.49433955252170564\n",
            "Epoch 6/10, Loss: 0.49503733825683593\n",
            "Epoch 6/10, Loss: 0.4957379655838013\n",
            "Epoch 6/10, Loss: 0.4964337683916092\n",
            "Epoch 6/10, Loss: 0.49712433451414106\n",
            "Epoch 6/10, Loss: 0.4978071433901787\n",
            "Epoch 6/10, Loss: 0.4985119714140892\n",
            "Epoch 6/10, Loss: 0.49920116299390793\n",
            "Epoch 6/10, Loss: 0.4998970355391502\n",
            "Epoch 6/10, Loss: 0.5005898335576058\n",
            "Epoch 6/10, Loss: 0.5012880374193192\n",
            "Epoch 6/10, Loss: 0.501981333732605\n",
            "Epoch 6/10, Loss: 0.50267997777462\n",
            "Epoch 6/10, Loss: 0.503369999229908\n",
            "Epoch 6/10, Loss: 0.5040658958554268\n",
            "Epoch 6/10, Loss: 0.5047673459649086\n",
            "Epoch 6/10, Loss: 0.5054725543856621\n",
            "Epoch 6/10, Loss: 0.5061709188222885\n",
            "Epoch 6/10, Loss: 0.5068675787448883\n",
            "Epoch 6/10, Loss: 0.507561687529087\n",
            "Epoch 6/10, Loss: 0.5082435441613198\n",
            "Epoch 6/10, Loss: 0.5089244752526283\n",
            "Epoch 6/10, Loss: 0.5096138836741447\n",
            "Epoch 6/10, Loss: 0.5103096024394035\n",
            "Epoch 6/10, Loss: 0.5110093703866005\n",
            "Epoch 6/10, Loss: 0.511699621975422\n",
            "Epoch 6/10, Loss: 0.5123855490088463\n",
            "Epoch 6/10, Loss: 0.5130630262494087\n",
            "Epoch 6/10, Loss: 0.5137561355829239\n",
            "Epoch 6/10, Loss: 0.5144509316682816\n",
            "Epoch 6/10, Loss: 0.5151400016546249\n",
            "Epoch 6/10, Loss: 0.51583356320858\n",
            "Epoch 6/10, Loss: 0.5165203072428703\n",
            "Epoch 6/10, Loss: 0.5172231432199478\n",
            "Epoch 6/10, Loss: 0.5179076422452926\n",
            "Epoch 6/10, Loss: 0.5186002222299576\n",
            "Epoch 6/10, Loss: 0.5193011506199837\n",
            "Epoch 6/10, Loss: 0.519987283885479\n",
            "Epoch 6/10, Loss: 0.5206786633133889\n",
            "Epoch 6/10, Loss: 0.5213707064390183\n",
            "Epoch 6/10, Loss: 0.5220652347803116\n",
            "Epoch 6/10, Loss: 0.5227573078870773\n",
            "Epoch 6/10, Loss: 0.523448707997799\n",
            "Epoch 6/10, Loss: 0.5241491524577141\n",
            "Epoch 6/10, Loss: 0.524841202378273\n",
            "Epoch 6/10, Loss: 0.5255302913188934\n",
            "Epoch 6/10, Loss: 0.526228301346302\n",
            "Epoch 6/10, Loss: 0.526924646794796\n",
            "Epoch 6/10, Loss: 0.5276160081028938\n",
            "Epoch 6/10, Loss: 0.5283047462701798\n",
            "Epoch 6/10, Loss: 0.5289899063706398\n",
            "Epoch 6/10, Loss: 0.5296780461668968\n",
            "Epoch 6/10, Loss: 0.5303786426186562\n",
            "Epoch 6/10, Loss: 0.531074001967907\n",
            "Epoch 6/10, Loss: 0.5317573894858361\n",
            "Epoch 6/10, Loss: 0.5324469278454781\n",
            "Epoch 6/10, Loss: 0.5331463168263435\n",
            "Epoch 6/10, Loss: 0.5338466526865959\n",
            "Epoch 6/10, Loss: 0.5345434612631798\n",
            "Epoch 6/10, Loss: 0.5352440397143364\n",
            "Epoch 6/10, Loss: 0.5359295787811279\n",
            "Epoch 6/10, Loss: 0.5366240850090981\n",
            "Epoch 6/10, Loss: 0.5373183109164238\n",
            "Epoch 6/10, Loss: 0.5380212951898575\n",
            "Epoch 6/10, Loss: 0.5387115516662597\n",
            "Epoch 6/10, Loss: 0.5394123396277428\n",
            "Epoch 6/10, Loss: 0.5401013557314873\n",
            "Epoch 6/10, Loss: 0.5407830148935318\n",
            "Epoch 6/10, Loss: 0.5414730011224747\n",
            "Epoch 6/10, Loss: 0.5421646257638931\n",
            "Epoch 6/10, Loss: 0.5428460718989372\n",
            "Epoch 6/10, Loss: 0.5435345494151116\n",
            "Epoch 6/10, Loss: 0.544216817677021\n",
            "Epoch 6/10, Loss: 0.544907874763012\n",
            "Epoch 6/10, Loss: 0.5455922355651855\n",
            "Epoch 6/10, Loss: 0.5462765175104142\n",
            "Epoch 6/10, Loss: 0.5469619306325912\n",
            "Epoch 6/10, Loss: 0.5476469038128853\n",
            "Epoch 6/10, Loss: 0.5483374230861664\n",
            "Epoch 6/10, Loss: 0.5490322813987732\n",
            "Epoch 6/10, Loss: 0.5497177466750145\n",
            "Epoch 6/10, Loss: 0.5504006026983261\n",
            "Epoch 6/10, Loss: 0.5510909502506256\n",
            "Epoch 6/10, Loss: 0.5517692182064057\n",
            "Epoch 6/10, Loss: 0.552469621181488\n",
            "Epoch 6/10, Loss: 0.5531566609144211\n",
            "Epoch 6/10, Loss: 0.5538417404294014\n",
            "Epoch 6/10, Loss: 0.5545413404107093\n",
            "Epoch 6/10, Loss: 0.5552218139767647\n",
            "Epoch 6/10, Loss: 0.5559178571105003\n",
            "Epoch 6/10, Loss: 0.5566114070415497\n",
            "Epoch 6/10, Loss: 0.5572998564839363\n",
            "Epoch 6/10, Loss: 0.5579924802780152\n",
            "Epoch 6/10, Loss: 0.5586797907352448\n",
            "Epoch 6/10, Loss: 0.5593656035661697\n",
            "Epoch 6/10, Loss: 0.5600722113847733\n",
            "Epoch 6/10, Loss: 0.5607649832963943\n",
            "Epoch 6/10, Loss: 0.561458790242672\n",
            "Epoch 6/10, Loss: 0.5621518712639809\n",
            "Epoch 6/10, Loss: 0.5628453540205955\n",
            "Epoch 6/10, Loss: 0.5635404928326607\n",
            "Epoch 6/10, Loss: 0.5642277113795281\n",
            "Epoch 6/10, Loss: 0.5648972683548927\n",
            "Epoch 6/10, Loss: 0.5656037611365319\n",
            "Epoch 6/10, Loss: 0.5663023346662521\n",
            "Epoch 6/10, Loss: 0.5669872521162033\n",
            "Epoch 6/10, Loss: 0.5676785867214202\n",
            "Epoch 6/10, Loss: 0.56837090498209\n",
            "Epoch 6/10, Loss: 0.5690541440844535\n",
            "Epoch 6/10, Loss: 0.5697412673830986\n",
            "Epoch 6/10, Loss: 0.5704344153404236\n",
            "Epoch 6/10, Loss: 0.5711263050436973\n",
            "Epoch 6/10, Loss: 0.5718153649568558\n",
            "Epoch 6/10, Loss: 0.5725053625106812\n",
            "Epoch 6/10, Loss: 0.5731962953209877\n",
            "Epoch 6/10, Loss: 0.5738903591036797\n",
            "Epoch 6/10, Loss: 0.5745798760056495\n",
            "Epoch 6/10, Loss: 0.5752745040655136\n",
            "Epoch 6/10, Loss: 0.5759592314958573\n",
            "Epoch 6/10, Loss: 0.5766526478528976\n",
            "Epoch 6/10, Loss: 0.5773376087546349\n",
            "Epoch 6/10, Loss: 0.5780342268943787\n",
            "Epoch 6/10, Loss: 0.5787203090786934\n",
            "Epoch 6/10, Loss: 0.5794148034453392\n",
            "Epoch 6/10, Loss: 0.5801032463908196\n",
            "Epoch 6/10, Loss: 0.5808025894165039\n",
            "Epoch 6/10, Loss: 0.5814936802387237\n",
            "Epoch 6/10, Loss: 0.582187903881073\n",
            "Epoch 6/10, Loss: 0.5828791118860245\n",
            "Epoch 6/10, Loss: 0.5835594735741615\n",
            "Epoch 6/10, Loss: 0.5842364644408226\n",
            "Epoch 6/10, Loss: 0.5849355708956718\n",
            "Epoch 6/10, Loss: 0.5856305725574493\n",
            "Epoch 6/10, Loss: 0.5863330659270286\n",
            "Epoch 6/10, Loss: 0.5870245980620384\n",
            "Epoch 6/10, Loss: 0.5877100791335106\n",
            "Epoch 6/10, Loss: 0.5884053871035576\n",
            "Epoch 6/10, Loss: 0.589099853694439\n",
            "Epoch 6/10, Loss: 0.5897930116057396\n",
            "Epoch 6/10, Loss: 0.5904851809740067\n",
            "Epoch 6/10, Loss: 0.5911597879528999\n",
            "Epoch 6/10, Loss: 0.5918505820631981\n",
            "Epoch 6/10, Loss: 0.5925435705780983\n",
            "Epoch 6/10, Loss: 0.593224863767624\n",
            "Epoch 6/10, Loss: 0.5939086065292358\n",
            "Epoch 6/10, Loss: 0.5945892581939697\n",
            "Epoch 6/10, Loss: 0.5952717035412788\n",
            "Epoch 6/10, Loss: 0.5959612126350403\n",
            "Epoch 6/10, Loss: 0.5966625116467476\n",
            "Epoch 6/10, Loss: 0.5973454185128212\n",
            "Epoch 6/10, Loss: 0.5980340737700462\n",
            "Epoch 6/10, Loss: 0.5987156425714493\n",
            "Epoch 6/10, Loss: 0.5994004129171372\n",
            "Epoch 6/10, Loss: 0.6000980943441391\n",
            "Epoch 6/10, Loss: 0.6007975208163261\n",
            "Epoch 6/10, Loss: 0.6015011367201805\n",
            "Epoch 6/10, Loss: 0.6021881560087204\n",
            "Epoch 6/10, Loss: 0.602873317182064\n",
            "Epoch 6/10, Loss: 0.603570266366005\n",
            "Epoch 6/10, Loss: 0.6042568893432617\n",
            "Epoch 6/10, Loss: 0.6049512705802917\n",
            "Epoch 6/10, Loss: 0.6056390646100044\n",
            "Epoch 6/10, Loss: 0.6063192072510719\n",
            "Epoch 6/10, Loss: 0.6070101290345192\n",
            "Epoch 6/10, Loss: 0.6076949071288109\n",
            "Epoch 6/10, Loss: 0.6083791400194168\n",
            "Epoch 6/10, Loss: 0.6090761612653732\n",
            "Epoch 6/10, Loss: 0.6097664306163788\n",
            "Epoch 6/10, Loss: 0.6104607753753662\n",
            "Epoch 6/10, Loss: 0.6111570491790771\n",
            "Epoch 6/10, Loss: 0.6118465591073036\n",
            "Epoch 6/10, Loss: 0.6125349099040032\n",
            "Epoch 6/10, Loss: 0.6132192178368568\n",
            "Epoch 6/10, Loss: 0.613908441901207\n",
            "Epoch 6/10, Loss: 0.6146019473671913\n",
            "Epoch 6/10, Loss: 0.6152950400710105\n",
            "Epoch 6/10, Loss: 0.6159942262768745\n",
            "Epoch 6/10, Loss: 0.6166756642460823\n",
            "Epoch 6/10, Loss: 0.6173637152314186\n",
            "Epoch 6/10, Loss: 0.6180384711623191\n",
            "Epoch 6/10, Loss: 0.6187224450707436\n",
            "Epoch 6/10, Loss: 0.6194097798466682\n",
            "Epoch 6/10, Loss: 0.6201018182635307\n",
            "Epoch 6/10, Loss: 0.6207979953885079\n",
            "Epoch 6/10, Loss: 0.6214907556176186\n",
            "Epoch 6/10, Loss: 0.6221887413263321\n",
            "Epoch 6/10, Loss: 0.622875225186348\n",
            "Epoch 6/10, Loss: 0.6235645124316216\n",
            "Epoch 6/10, Loss: 0.6242564097046852\n",
            "Epoch 6/10, Loss: 0.6249544232487678\n",
            "Epoch 6/10, Loss: 0.6256435915827752\n",
            "Epoch 6/10, Loss: 0.6263261483907699\n",
            "Epoch 6/10, Loss: 0.6270125205516816\n",
            "Epoch 6/10, Loss: 0.627703499019146\n",
            "Epoch 6/10, Loss: 0.6283897541165352\n",
            "Epoch 6/10, Loss: 0.6290739066004754\n",
            "Epoch 6/10, Loss: 0.6297700181603432\n",
            "Epoch 6/10, Loss: 0.6304622255563735\n",
            "Epoch 6/10, Loss: 0.6311465274095536\n",
            "Epoch 6/10, Loss: 0.6318410878181457\n",
            "Epoch 6/10, Loss: 0.6325355216264724\n",
            "Epoch 6/10, Loss: 0.6332304638624191\n",
            "Epoch 6/10, Loss: 0.6339154105186462\n",
            "Epoch 6/10, Loss: 0.6346120507121086\n",
            "Epoch 6/10, Loss: 0.6353035250902176\n",
            "Epoch 6/10, Loss: 0.6359859288930892\n",
            "Epoch 6/10, Loss: 0.636682767868042\n",
            "Epoch 6/10, Loss: 0.6373863983154296\n",
            "Epoch 6/10, Loss: 0.6380705332159996\n",
            "Epoch 6/10, Loss: 0.6387663719058037\n",
            "Epoch 6/10, Loss: 0.6394505271911621\n",
            "Epoch 6/10, Loss: 0.6401424160003663\n",
            "Epoch 6/10, Loss: 0.6408207366466522\n",
            "Epoch 6/10, Loss: 0.6415139361619949\n",
            "Epoch 6/10, Loss: 0.6422039571404458\n",
            "Epoch 6/10, Loss: 0.6429027728438378\n",
            "Epoch 6/10, Loss: 0.6436004727482796\n",
            "Epoch 6/10, Loss: 0.6442874698638916\n",
            "Epoch 6/10, Loss: 0.6449652845859528\n",
            "Epoch 6/10, Loss: 0.64565539509058\n",
            "Epoch 6/10, Loss: 0.6463405982255935\n",
            "Epoch 6/10, Loss: 0.6470348688960076\n",
            "Epoch 6/10, Loss: 0.6477245481610299\n",
            "Epoch 6/10, Loss: 0.6484168144464493\n",
            "Epoch 6/10, Loss: 0.649119394481182\n",
            "Epoch 6/10, Loss: 0.6498210364580155\n",
            "Epoch 6/10, Loss: 0.6505066213607789\n",
            "Epoch 6/10, Loss: 0.6511927234530449\n",
            "Epoch 6/10, Loss: 0.651880403637886\n",
            "Epoch 6/10, Loss: 0.6525711429715156\n",
            "Epoch 6/10, Loss: 0.6532629294395447\n",
            "Epoch 6/10, Loss: 0.6539364801645279\n",
            "Epoch 6/10, Loss: 0.6546200131177902\n",
            "Epoch 6/10, Loss: 0.6553126509189606\n",
            "Epoch 6/10, Loss: 0.6560086277127266\n",
            "Epoch 6/10, Loss: 0.6567166264653206\n",
            "Epoch 6/10, Loss: 0.6574039301872253\n",
            "Epoch 6/10, Loss: 0.6581023977994919\n",
            "Epoch 6/10, Loss: 0.658799543082714\n",
            "Epoch 6/10, Loss: 0.6594932936429977\n",
            "Epoch 6/10, Loss: 0.6601842697858811\n",
            "Epoch 6/10, Loss: 0.6608749811053276\n",
            "Epoch 6/10, Loss: 0.6615652599930764\n",
            "Epoch 6/10, Loss: 0.6622546300292015\n",
            "Epoch 6/10, Loss: 0.662947675049305\n",
            "Epoch 6/10, Loss: 0.6636433371901512\n",
            "Epoch 6/10, Loss: 0.6643260208964348\n",
            "Epoch 6/10, Loss: 0.6650196418166161\n",
            "Epoch 6/10, Loss: 0.665713756263256\n",
            "Epoch 6/10, Loss: 0.666404413163662\n",
            "Epoch 6/10, Loss: 0.6670987924337387\n",
            "Epoch 6/10, Loss: 0.6677962741851806\n",
            "Epoch 6/10, Loss: 0.6684890573620796\n",
            "Epoch 6/10, Loss: 0.6691832503080368\n",
            "Epoch 6/10, Loss: 0.6698803117275238\n",
            "Epoch 6/10, Loss: 0.6705748259425163\n",
            "Epoch 6/10, Loss: 0.6712652235031128\n",
            "Epoch 6/10, Loss: 0.6719522206187248\n",
            "Epoch 6/10, Loss: 0.6726370282769203\n",
            "Epoch 6/10, Loss: 0.6733214686512947\n",
            "Epoch 6/10, Loss: 0.674017158806324\n",
            "Epoch 6/10, Loss: 0.6747146475315094\n",
            "Epoch 6/10, Loss: 0.6754076256752014\n",
            "Epoch 6/10, Loss: 0.6760954934954643\n",
            "Epoch 6/10, Loss: 0.6767857691645622\n",
            "Epoch 6/10, Loss: 0.6774870107173919\n",
            "Epoch 6/10, Loss: 0.678192659854889\n",
            "Epoch 6/10, Loss: 0.6788765788078308\n",
            "Epoch 6/10, Loss: 0.6795767529606819\n",
            "Epoch 6/10, Loss: 0.6802667174339294\n",
            "Epoch 6/10, Loss: 0.6809509828090667\n",
            "Epoch 6/10, Loss: 0.6816560164690018\n",
            "Epoch 6/10, Loss: 0.6823530546426773\n",
            "Epoch 6/10, Loss: 0.6830361998677253\n",
            "Epoch 6/10, Loss: 0.6837304981350899\n",
            "Epoch 6/10, Loss: 0.6844316868185997\n",
            "Epoch 6/10, Loss: 0.6851507845520973\n",
            "Epoch 6/10, Loss: 0.6858328265547753\n",
            "Epoch 6/10, Loss: 0.686527463376522\n",
            "Epoch 6/10, Loss: 0.6872207511067391\n",
            "Epoch 6/10, Loss: 0.6879198225140571\n",
            "Epoch 6/10, Loss: 0.6886095008850097\n",
            "Epoch 6/10, Loss: 0.6892984558343888\n",
            "Epoch 6/10, Loss: 0.689996231675148\n",
            "Epoch 6/10, Loss: 0.690692986369133\n",
            "Epoch 6/10, Loss: 0.6913841961026191\n",
            "Epoch 7/10, Loss: 0.000692725658416748\n",
            "Epoch 7/10, Loss: 0.0013858906030654906\n",
            "Epoch 7/10, Loss: 0.0020791754722595214\n",
            "Epoch 7/10, Loss: 0.0027739248275756834\n",
            "Epoch 7/10, Loss: 0.0034579200744628905\n",
            "Epoch 7/10, Loss: 0.004151018738746643\n",
            "Epoch 7/10, Loss: 0.004834330916404724\n",
            "Epoch 7/10, Loss: 0.005528496205806732\n",
            "Epoch 7/10, Loss: 0.00621170562505722\n",
            "Epoch 7/10, Loss: 0.006892138242721558\n",
            "Epoch 7/10, Loss: 0.007578456342220307\n",
            "Epoch 7/10, Loss: 0.008259862542152404\n",
            "Epoch 7/10, Loss: 0.008942975759506226\n",
            "Epoch 7/10, Loss: 0.009637284874916077\n",
            "Epoch 7/10, Loss: 0.010333567082881927\n",
            "Epoch 7/10, Loss: 0.011033216536045075\n",
            "Epoch 7/10, Loss: 0.011736232697963714\n",
            "Epoch 7/10, Loss: 0.012409973680973053\n",
            "Epoch 7/10, Loss: 0.013109241843223571\n",
            "Epoch 7/10, Loss: 0.01380088758468628\n",
            "Epoch 7/10, Loss: 0.014493924379348756\n",
            "Epoch 7/10, Loss: 0.015185249328613282\n",
            "Epoch 7/10, Loss: 0.01588110876083374\n",
            "Epoch 7/10, Loss: 0.016567960977554322\n",
            "Epoch 7/10, Loss: 0.017246058464050293\n",
            "Epoch 7/10, Loss: 0.017915829956531525\n",
            "Epoch 7/10, Loss: 0.018606364846229552\n",
            "Epoch 7/10, Loss: 0.019298613011837006\n",
            "Epoch 7/10, Loss: 0.0199927179813385\n",
            "Epoch 7/10, Loss: 0.020686540603637695\n",
            "Epoch 7/10, Loss: 0.02137244486808777\n",
            "Epoch 7/10, Loss: 0.022067827820777892\n",
            "Epoch 7/10, Loss: 0.022765244245529174\n",
            "Epoch 7/10, Loss: 0.023461521327495575\n",
            "Epoch 7/10, Loss: 0.02416669636964798\n",
            "Epoch 7/10, Loss: 0.024849307417869566\n",
            "Epoch 7/10, Loss: 0.025543823540210724\n",
            "Epoch 7/10, Loss: 0.026231536149978637\n",
            "Epoch 7/10, Loss: 0.026913340806961058\n",
            "Epoch 7/10, Loss: 0.027603803157806396\n",
            "Epoch 7/10, Loss: 0.028295156240463255\n",
            "Epoch 7/10, Loss: 0.02898171401023865\n",
            "Epoch 7/10, Loss: 0.02968247401714325\n",
            "Epoch 7/10, Loss: 0.03038215959072113\n",
            "Epoch 7/10, Loss: 0.03108122956752777\n",
            "Epoch 7/10, Loss: 0.03176359343528747\n",
            "Epoch 7/10, Loss: 0.03245537096261978\n",
            "Epoch 7/10, Loss: 0.03314594638347626\n",
            "Epoch 7/10, Loss: 0.0338500326871872\n",
            "Epoch 7/10, Loss: 0.03454677325487137\n",
            "Epoch 7/10, Loss: 0.035245923221111294\n",
            "Epoch 7/10, Loss: 0.03592623549699783\n",
            "Epoch 7/10, Loss: 0.036622368693351746\n",
            "Epoch 7/10, Loss: 0.037307967066764834\n",
            "Epoch 7/10, Loss: 0.03800306934118271\n",
            "Epoch 7/10, Loss: 0.038704754531383515\n",
            "Epoch 7/10, Loss: 0.03939899730682373\n",
            "Epoch 7/10, Loss: 0.04008667355775833\n",
            "Epoch 7/10, Loss: 0.04078773576021195\n",
            "Epoch 7/10, Loss: 0.04147473555803299\n",
            "Epoch 7/10, Loss: 0.04216187620162964\n",
            "Epoch 7/10, Loss: 0.04285371631383896\n",
            "Epoch 7/10, Loss: 0.043539651393890384\n",
            "Epoch 7/10, Loss: 0.04424468767642975\n",
            "Epoch 7/10, Loss: 0.044932355284690854\n",
            "Epoch 7/10, Loss: 0.04561928999423981\n",
            "Epoch 7/10, Loss: 0.046312537789344785\n",
            "Epoch 7/10, Loss: 0.04700178515911102\n",
            "Epoch 7/10, Loss: 0.04770666337013245\n",
            "Epoch 7/10, Loss: 0.048408961057662965\n",
            "Epoch 7/10, Loss: 0.0491035361289978\n",
            "Epoch 7/10, Loss: 0.049792986154556275\n",
            "Epoch 7/10, Loss: 0.05048141622543335\n",
            "Epoch 7/10, Loss: 0.051173744678497314\n",
            "Epoch 7/10, Loss: 0.05186709898710251\n",
            "Epoch 7/10, Loss: 0.052554991543292996\n",
            "Epoch 7/10, Loss: 0.05325638020038605\n",
            "Epoch 7/10, Loss: 0.05394976043701172\n",
            "Epoch 7/10, Loss: 0.05463821858167648\n",
            "Epoch 7/10, Loss: 0.05533049750328064\n",
            "Epoch 7/10, Loss: 0.056018196523189547\n",
            "Epoch 7/10, Loss: 0.05669579303264618\n",
            "Epoch 7/10, Loss: 0.05738558900356293\n",
            "Epoch 7/10, Loss: 0.058078209698200225\n",
            "Epoch 7/10, Loss: 0.05875482124090195\n",
            "Epoch 7/10, Loss: 0.059444184303283694\n",
            "Epoch 7/10, Loss: 0.06013655781745911\n",
            "Epoch 7/10, Loss: 0.06083143764734268\n",
            "Epoch 7/10, Loss: 0.061520877838134765\n",
            "Epoch 7/10, Loss: 0.06220231622457504\n",
            "Epoch 7/10, Loss: 0.0628955950140953\n",
            "Epoch 7/10, Loss: 0.06358105134963989\n",
            "Epoch 7/10, Loss: 0.06427124339342118\n",
            "Epoch 7/10, Loss: 0.0649679382443428\n",
            "Epoch 7/10, Loss: 0.06565583407878876\n",
            "Epoch 7/10, Loss: 0.06633784359693527\n",
            "Epoch 7/10, Loss: 0.06702386063337326\n",
            "Epoch 7/10, Loss: 0.06770125597715378\n",
            "Epoch 7/10, Loss: 0.06838688826560974\n",
            "Epoch 7/10, Loss: 0.06908541876077652\n",
            "Epoch 7/10, Loss: 0.0697768377661705\n",
            "Epoch 7/10, Loss: 0.07045885443687439\n",
            "Epoch 7/10, Loss: 0.07114709770679474\n",
            "Epoch 7/10, Loss: 0.07183688163757324\n",
            "Epoch 7/10, Loss: 0.07252448159456253\n",
            "Epoch 7/10, Loss: 0.07320028805732727\n",
            "Epoch 7/10, Loss: 0.07389691805839539\n",
            "Epoch 7/10, Loss: 0.0745894615650177\n",
            "Epoch 7/10, Loss: 0.07527811586856842\n",
            "Epoch 7/10, Loss: 0.07596605855226517\n",
            "Epoch 7/10, Loss: 0.07664951807260513\n",
            "Epoch 7/10, Loss: 0.07734236353635789\n",
            "Epoch 7/10, Loss: 0.07803723073005676\n",
            "Epoch 7/10, Loss: 0.07872361254692077\n",
            "Epoch 7/10, Loss: 0.07941062152385711\n",
            "Epoch 7/10, Loss: 0.08011452943086624\n",
            "Epoch 7/10, Loss: 0.08079914313554763\n",
            "Epoch 7/10, Loss: 0.08149044817686081\n",
            "Epoch 7/10, Loss: 0.0821758828163147\n",
            "Epoch 7/10, Loss: 0.08286595052480697\n",
            "Epoch 7/10, Loss: 0.08354949283599854\n",
            "Epoch 7/10, Loss: 0.08423376661539078\n",
            "Epoch 7/10, Loss: 0.0849212144613266\n",
            "Epoch 7/10, Loss: 0.08562056183815002\n",
            "Epoch 7/10, Loss: 0.0863111228942871\n",
            "Epoch 7/10, Loss: 0.0870039758682251\n",
            "Epoch 7/10, Loss: 0.08770046997070312\n",
            "Epoch 7/10, Loss: 0.08839736819267273\n",
            "Epoch 7/10, Loss: 0.08909626823663712\n",
            "Epoch 7/10, Loss: 0.08978715419769287\n",
            "Epoch 7/10, Loss: 0.09048466289043426\n",
            "Epoch 7/10, Loss: 0.09117073065042496\n",
            "Epoch 7/10, Loss: 0.09186033165454864\n",
            "Epoch 7/10, Loss: 0.09255010008811951\n",
            "Epoch 7/10, Loss: 0.09322438609600067\n",
            "Epoch 7/10, Loss: 0.09390866875648499\n",
            "Epoch 7/10, Loss: 0.09460504794120789\n",
            "Epoch 7/10, Loss: 0.09529165673255921\n",
            "Epoch 7/10, Loss: 0.0959811441898346\n",
            "Epoch 7/10, Loss: 0.09668077123165131\n",
            "Epoch 7/10, Loss: 0.09737456518411636\n",
            "Epoch 7/10, Loss: 0.09806368887424469\n",
            "Epoch 7/10, Loss: 0.09875670862197876\n",
            "Epoch 7/10, Loss: 0.09945940971374512\n",
            "Epoch 7/10, Loss: 0.10014835274219513\n",
            "Epoch 7/10, Loss: 0.10084331023693084\n",
            "Epoch 7/10, Loss: 0.10153625845909119\n",
            "Epoch 7/10, Loss: 0.10223663938045502\n",
            "Epoch 7/10, Loss: 0.10291881167888642\n",
            "Epoch 7/10, Loss: 0.10359653514623642\n",
            "Epoch 7/10, Loss: 0.10428904181718826\n",
            "Epoch 7/10, Loss: 0.10497717070579529\n",
            "Epoch 7/10, Loss: 0.10566785681247712\n",
            "Epoch 7/10, Loss: 0.1063508465886116\n",
            "Epoch 7/10, Loss: 0.10704052132368087\n",
            "Epoch 7/10, Loss: 0.10772205609083176\n",
            "Epoch 7/10, Loss: 0.10840952903032303\n",
            "Epoch 7/10, Loss: 0.10909597128629685\n",
            "Epoch 7/10, Loss: 0.109781583070755\n",
            "Epoch 7/10, Loss: 0.11046752268075943\n",
            "Epoch 7/10, Loss: 0.1111525267958641\n",
            "Epoch 7/10, Loss: 0.11184835654497147\n",
            "Epoch 7/10, Loss: 0.11253744786977768\n",
            "Epoch 7/10, Loss: 0.11323012822866439\n",
            "Epoch 7/10, Loss: 0.11391389286518097\n",
            "Epoch 7/10, Loss: 0.1145999368429184\n",
            "Epoch 7/10, Loss: 0.1152932665348053\n",
            "Epoch 7/10, Loss: 0.1159843145608902\n",
            "Epoch 7/10, Loss: 0.11667859452962875\n",
            "Epoch 7/10, Loss: 0.11737088114023209\n",
            "Epoch 7/10, Loss: 0.11806463384628296\n",
            "Epoch 7/10, Loss: 0.11874824202060699\n",
            "Epoch 7/10, Loss: 0.11943747639656067\n",
            "Epoch 7/10, Loss: 0.12013375055789947\n",
            "Epoch 7/10, Loss: 0.12083939242362976\n",
            "Epoch 7/10, Loss: 0.12153524231910706\n",
            "Epoch 7/10, Loss: 0.12221617066860199\n",
            "Epoch 7/10, Loss: 0.1229022147655487\n",
            "Epoch 7/10, Loss: 0.12359337764978409\n",
            "Epoch 7/10, Loss: 0.12428684508800507\n",
            "Epoch 7/10, Loss: 0.12498533970117569\n",
            "Epoch 7/10, Loss: 0.1256705609560013\n",
            "Epoch 7/10, Loss: 0.12636232715845108\n",
            "Epoch 7/10, Loss: 0.12705725055932998\n",
            "Epoch 7/10, Loss: 0.12774057859182358\n",
            "Epoch 7/10, Loss: 0.12843950408697127\n",
            "Epoch 7/10, Loss: 0.1291269017457962\n",
            "Epoch 7/10, Loss: 0.1298217440843582\n",
            "Epoch 7/10, Loss: 0.13050643503665924\n",
            "Epoch 7/10, Loss: 0.13118785572052002\n",
            "Epoch 7/10, Loss: 0.131876965880394\n",
            "Epoch 7/10, Loss: 0.132573010802269\n",
            "Epoch 7/10, Loss: 0.13325789111852646\n",
            "Epoch 7/10, Loss: 0.13395114558935164\n",
            "Epoch 7/10, Loss: 0.1346293097138405\n",
            "Epoch 7/10, Loss: 0.13531636530160904\n",
            "Epoch 7/10, Loss: 0.13600629651546478\n",
            "Epoch 7/10, Loss: 0.1366937789916992\n",
            "Epoch 7/10, Loss: 0.13737957966327669\n",
            "Epoch 7/10, Loss: 0.13806153386831282\n",
            "Epoch 7/10, Loss: 0.13874297589063644\n",
            "Epoch 7/10, Loss: 0.13943871134519578\n",
            "Epoch 7/10, Loss: 0.14013303363323212\n",
            "Epoch 7/10, Loss: 0.14082304775714874\n",
            "Epoch 7/10, Loss: 0.14151698714494707\n",
            "Epoch 7/10, Loss: 0.14221512204408646\n",
            "Epoch 7/10, Loss: 0.142907997071743\n",
            "Epoch 7/10, Loss: 0.14360014200210572\n",
            "Epoch 7/10, Loss: 0.14428466778993607\n",
            "Epoch 7/10, Loss: 0.14497902601957322\n",
            "Epoch 7/10, Loss: 0.1456833408474922\n",
            "Epoch 7/10, Loss: 0.14637621235847473\n",
            "Epoch 7/10, Loss: 0.1470645076036453\n",
            "Epoch 7/10, Loss: 0.14775984942913056\n",
            "Epoch 7/10, Loss: 0.14844199168682098\n",
            "Epoch 7/10, Loss: 0.14913995695114135\n",
            "Epoch 7/10, Loss: 0.14982765305042267\n",
            "Epoch 7/10, Loss: 0.15051897585392\n",
            "Epoch 7/10, Loss: 0.15120148950815201\n",
            "Epoch 7/10, Loss: 0.15189634197950364\n",
            "Epoch 7/10, Loss: 0.1525949591398239\n",
            "Epoch 7/10, Loss: 0.15329092860221863\n",
            "Epoch 7/10, Loss: 0.15397499334812165\n",
            "Epoch 7/10, Loss: 0.1546723403930664\n",
            "Epoch 7/10, Loss: 0.15535888373851775\n",
            "Epoch 7/10, Loss: 0.15604468327760695\n",
            "Epoch 7/10, Loss: 0.15673566508293152\n",
            "Epoch 7/10, Loss: 0.15742646247148515\n",
            "Epoch 7/10, Loss: 0.15811311990022658\n",
            "Epoch 7/10, Loss: 0.1588022221326828\n",
            "Epoch 7/10, Loss: 0.15948949468135834\n",
            "Epoch 7/10, Loss: 0.16017978662252427\n",
            "Epoch 7/10, Loss: 0.16087994384765625\n",
            "Epoch 7/10, Loss: 0.16157300794124604\n",
            "Epoch 7/10, Loss: 0.16226703667640685\n",
            "Epoch 7/10, Loss: 0.16295848006010055\n",
            "Epoch 7/10, Loss: 0.16364893394708632\n",
            "Epoch 7/10, Loss: 0.1643296554684639\n",
            "Epoch 7/10, Loss: 0.16501315885782242\n",
            "Epoch 7/10, Loss: 0.16570713663101197\n",
            "Epoch 7/10, Loss: 0.16639742743968963\n",
            "Epoch 7/10, Loss: 0.16709996342658998\n",
            "Epoch 7/10, Loss: 0.16779432821273804\n",
            "Epoch 7/10, Loss: 0.16848730278015137\n",
            "Epoch 7/10, Loss: 0.16917880594730378\n",
            "Epoch 7/10, Loss: 0.16986614388227464\n",
            "Epoch 7/10, Loss: 0.17055910909175873\n",
            "Epoch 7/10, Loss: 0.17124094593524933\n",
            "Epoch 7/10, Loss: 0.17193319833278656\n",
            "Epoch 7/10, Loss: 0.17263003206253053\n",
            "Epoch 7/10, Loss: 0.17330465292930602\n",
            "Epoch 7/10, Loss: 0.1739963629245758\n",
            "Epoch 7/10, Loss: 0.17468772649765016\n",
            "Epoch 7/10, Loss: 0.17537820380926133\n",
            "Epoch 7/10, Loss: 0.17607092118263246\n",
            "Epoch 7/10, Loss: 0.17676902478933335\n",
            "Epoch 7/10, Loss: 0.1774553409218788\n",
            "Epoch 7/10, Loss: 0.17814435440301896\n",
            "Epoch 7/10, Loss: 0.1788392534852028\n",
            "Epoch 7/10, Loss: 0.17953494411706925\n",
            "Epoch 7/10, Loss: 0.18023460215330123\n",
            "Epoch 7/10, Loss: 0.18091961908340454\n",
            "Epoch 7/10, Loss: 0.181607257604599\n",
            "Epoch 7/10, Loss: 0.18229176300764083\n",
            "Epoch 7/10, Loss: 0.18297747087478639\n",
            "Epoch 7/10, Loss: 0.1836622953414917\n",
            "Epoch 7/10, Loss: 0.1843679545521736\n",
            "Epoch 7/10, Loss: 0.18507465702295303\n",
            "Epoch 7/10, Loss: 0.18577808743715285\n",
            "Epoch 7/10, Loss: 0.18646819764375686\n",
            "Epoch 7/10, Loss: 0.18717061525583267\n",
            "Epoch 7/10, Loss: 0.18786028558015824\n",
            "Epoch 7/10, Loss: 0.18854468888044357\n",
            "Epoch 7/10, Loss: 0.18923504853248596\n",
            "Epoch 7/10, Loss: 0.18992434769868852\n",
            "Epoch 7/10, Loss: 0.1906303720474243\n",
            "Epoch 7/10, Loss: 0.19132951182126998\n",
            "Epoch 7/10, Loss: 0.1920158406496048\n",
            "Epoch 7/10, Loss: 0.19269690763950348\n",
            "Epoch 7/10, Loss: 0.19340140163898467\n",
            "Epoch 7/10, Loss: 0.19409297984838486\n",
            "Epoch 7/10, Loss: 0.19478123944997788\n",
            "Epoch 7/10, Loss: 0.1954641219973564\n",
            "Epoch 7/10, Loss: 0.19615253937244415\n",
            "Epoch 7/10, Loss: 0.19685204339027404\n",
            "Epoch 7/10, Loss: 0.19754210633039473\n",
            "Epoch 7/10, Loss: 0.19822894632816315\n",
            "Epoch 7/10, Loss: 0.19892136693000795\n",
            "Epoch 7/10, Loss: 0.19960347896814346\n",
            "Epoch 7/10, Loss: 0.20030064481496812\n",
            "Epoch 7/10, Loss: 0.2009940241575241\n",
            "Epoch 7/10, Loss: 0.20168744504451752\n",
            "Epoch 7/10, Loss: 0.20236753237247468\n",
            "Epoch 7/10, Loss: 0.2030736780166626\n",
            "Epoch 7/10, Loss: 0.20376395577192308\n",
            "Epoch 7/10, Loss: 0.20446712452173232\n",
            "Epoch 7/10, Loss: 0.20517965549230577\n",
            "Epoch 7/10, Loss: 0.2058673159480095\n",
            "Epoch 7/10, Loss: 0.2065569878220558\n",
            "Epoch 7/10, Loss: 0.20724885082244873\n",
            "Epoch 7/10, Loss: 0.2079378010034561\n",
            "Epoch 7/10, Loss: 0.2086183472275734\n",
            "Epoch 7/10, Loss: 0.20931665652990342\n",
            "Epoch 7/10, Loss: 0.2100087634921074\n",
            "Epoch 7/10, Loss: 0.21070506447553636\n",
            "Epoch 7/10, Loss: 0.21139992040395736\n",
            "Epoch 7/10, Loss: 0.2120860606431961\n",
            "Epoch 7/10, Loss: 0.2127717937231064\n",
            "Epoch 7/10, Loss: 0.21345491427183153\n",
            "Epoch 7/10, Loss: 0.21414966839551924\n",
            "Epoch 7/10, Loss: 0.21484391915798187\n",
            "Epoch 7/10, Loss: 0.21554009580612182\n",
            "Epoch 7/10, Loss: 0.21623484164476395\n",
            "Epoch 7/10, Loss: 0.2169248052239418\n",
            "Epoch 7/10, Loss: 0.21761021906137468\n",
            "Epoch 7/10, Loss: 0.21830102741718294\n",
            "Epoch 7/10, Loss: 0.21899816459417343\n",
            "Epoch 7/10, Loss: 0.2196794564127922\n",
            "Epoch 7/10, Loss: 0.22037498688697815\n",
            "Epoch 7/10, Loss: 0.2210655623078346\n",
            "Epoch 7/10, Loss: 0.22175435668230056\n",
            "Epoch 7/10, Loss: 0.2224445051550865\n",
            "Epoch 7/10, Loss: 0.22313748878240586\n",
            "Epoch 7/10, Loss: 0.22382628107070923\n",
            "Epoch 7/10, Loss: 0.22451998955011368\n",
            "Epoch 7/10, Loss: 0.22520724201202394\n",
            "Epoch 7/10, Loss: 0.22590491032600402\n",
            "Epoch 7/10, Loss: 0.22659280824661254\n",
            "Epoch 7/10, Loss: 0.22726963472366332\n",
            "Epoch 7/10, Loss: 0.22796825754642486\n",
            "Epoch 7/10, Loss: 0.22864302670955658\n",
            "Epoch 7/10, Loss: 0.22933700197935106\n",
            "Epoch 7/10, Loss: 0.2300335438847542\n",
            "Epoch 7/10, Loss: 0.23071949577331544\n",
            "Epoch 7/10, Loss: 0.23140925306081772\n",
            "Epoch 7/10, Loss: 0.23208587843179704\n",
            "Epoch 7/10, Loss: 0.23277377706766128\n",
            "Epoch 7/10, Loss: 0.233473364174366\n",
            "Epoch 7/10, Loss: 0.23416692304611206\n",
            "Epoch 7/10, Loss: 0.23485102319717407\n",
            "Epoch 7/10, Loss: 0.23553441774845124\n",
            "Epoch 7/10, Loss: 0.236228600025177\n",
            "Epoch 7/10, Loss: 0.23692267549037932\n",
            "Epoch 7/10, Loss: 0.23762498140335084\n",
            "Epoch 7/10, Loss: 0.23832362711429597\n",
            "Epoch 7/10, Loss: 0.23902245581150056\n",
            "Epoch 7/10, Loss: 0.23970839631557464\n",
            "Epoch 7/10, Loss: 0.24039831072092055\n",
            "Epoch 7/10, Loss: 0.24109403020143508\n",
            "Epoch 7/10, Loss: 0.24178687739372254\n",
            "Epoch 7/10, Loss: 0.24248822391033173\n",
            "Epoch 7/10, Loss: 0.24318948519229888\n",
            "Epoch 7/10, Loss: 0.24388360965251923\n",
            "Epoch 7/10, Loss: 0.24458148151636125\n",
            "Epoch 7/10, Loss: 0.24526591151952742\n",
            "Epoch 7/10, Loss: 0.2459619570374489\n",
            "Epoch 7/10, Loss: 0.24664248818159104\n",
            "Epoch 7/10, Loss: 0.24733416134119035\n",
            "Epoch 7/10, Loss: 0.24802020609378814\n",
            "Epoch 7/10, Loss: 0.24870400619506836\n",
            "Epoch 7/10, Loss: 0.24941212141513824\n",
            "Epoch 7/10, Loss: 0.250102143228054\n",
            "Epoch 7/10, Loss: 0.2507976717352867\n",
            "Epoch 7/10, Loss: 0.25149147099256514\n",
            "Epoch 7/10, Loss: 0.2521793492436409\n",
            "Epoch 7/10, Loss: 0.2528580166697502\n",
            "Epoch 7/10, Loss: 0.25354328787326813\n",
            "Epoch 7/10, Loss: 0.2542291234731674\n",
            "Epoch 7/10, Loss: 0.25491929745674136\n",
            "Epoch 7/10, Loss: 0.2556141418814659\n",
            "Epoch 7/10, Loss: 0.25630051785707475\n",
            "Epoch 7/10, Loss: 0.25699013233184814\n",
            "Epoch 7/10, Loss: 0.2576860336661339\n",
            "Epoch 7/10, Loss: 0.2583804139494896\n",
            "Epoch 7/10, Loss: 0.2590825665593147\n",
            "Epoch 7/10, Loss: 0.2597716155052185\n",
            "Epoch 7/10, Loss: 0.26046221858263013\n",
            "Epoch 7/10, Loss: 0.2611569165587425\n",
            "Epoch 7/10, Loss: 0.26185263639688494\n",
            "Epoch 7/10, Loss: 0.2625432353615761\n",
            "Epoch 7/10, Loss: 0.26323630464076997\n",
            "Epoch 7/10, Loss: 0.26392767471075057\n",
            "Epoch 7/10, Loss: 0.26462044018507\n",
            "Epoch 7/10, Loss: 0.2653244473338127\n",
            "Epoch 7/10, Loss: 0.2660114079117775\n",
            "Epoch 7/10, Loss: 0.26671040612459185\n",
            "Epoch 7/10, Loss: 0.2674102998971939\n",
            "Epoch 7/10, Loss: 0.26809173202514647\n",
            "Epoch 7/10, Loss: 0.2687739441394806\n",
            "Epoch 7/10, Loss: 0.26946031081676486\n",
            "Epoch 7/10, Loss: 0.27015638345479964\n",
            "Epoch 7/10, Loss: 0.2708508920073509\n",
            "Epoch 7/10, Loss: 0.27154203617572786\n",
            "Epoch 7/10, Loss: 0.272219567656517\n",
            "Epoch 7/10, Loss: 0.2729100204706192\n",
            "Epoch 7/10, Loss: 0.2735960021615028\n",
            "Epoch 7/10, Loss: 0.27429702049493787\n",
            "Epoch 7/10, Loss: 0.27498387306928634\n",
            "Epoch 7/10, Loss: 0.27567901760339736\n",
            "Epoch 7/10, Loss: 0.2763675268292427\n",
            "Epoch 7/10, Loss: 0.2770681152939796\n",
            "Epoch 7/10, Loss: 0.2777543501853943\n",
            "Epoch 7/10, Loss: 0.27844474494457244\n",
            "Epoch 7/10, Loss: 0.2791299155950546\n",
            "Epoch 7/10, Loss: 0.27982800936698915\n",
            "Epoch 7/10, Loss: 0.2805090310573578\n",
            "Epoch 7/10, Loss: 0.28119940382242203\n",
            "Epoch 7/10, Loss: 0.28189661663770677\n",
            "Epoch 7/10, Loss: 0.28259239047765733\n",
            "Epoch 7/10, Loss: 0.2832654091119766\n",
            "Epoch 7/10, Loss: 0.2839632957577705\n",
            "Epoch 7/10, Loss: 0.28465771973133086\n",
            "Epoch 7/10, Loss: 0.2853377971053124\n",
            "Epoch 7/10, Loss: 0.286025317132473\n",
            "Epoch 7/10, Loss: 0.286719728410244\n",
            "Epoch 7/10, Loss: 0.28741110080480575\n",
            "Epoch 7/10, Loss: 0.28810087823867797\n",
            "Epoch 7/10, Loss: 0.2887861176133156\n",
            "Epoch 7/10, Loss: 0.2894837917089462\n",
            "Epoch 7/10, Loss: 0.2901732565164566\n",
            "Epoch 7/10, Loss: 0.29086148619651797\n",
            "Epoch 7/10, Loss: 0.2915454289317131\n",
            "Epoch 7/10, Loss: 0.29224554979801176\n",
            "Epoch 7/10, Loss: 0.29293048977851865\n",
            "Epoch 7/10, Loss: 0.29362390768527985\n",
            "Epoch 7/10, Loss: 0.294318433880806\n",
            "Epoch 7/10, Loss: 0.2950037596821785\n",
            "Epoch 7/10, Loss: 0.2956915132403374\n",
            "Epoch 7/10, Loss: 0.2963710020184517\n",
            "Epoch 7/10, Loss: 0.29706386721134187\n",
            "Epoch 7/10, Loss: 0.2977490938901901\n",
            "Epoch 7/10, Loss: 0.29843322139978407\n",
            "Epoch 7/10, Loss: 0.2991135736107826\n",
            "Epoch 7/10, Loss: 0.29980747920274736\n",
            "Epoch 7/10, Loss: 0.30049843138456345\n",
            "Epoch 7/10, Loss: 0.30118394261598586\n",
            "Epoch 7/10, Loss: 0.3018712136149406\n",
            "Epoch 7/10, Loss: 0.30256248492002485\n",
            "Epoch 7/10, Loss: 0.30324867671728134\n",
            "Epoch 7/10, Loss: 0.30394065380096436\n",
            "Epoch 7/10, Loss: 0.3046289212703705\n",
            "Epoch 7/10, Loss: 0.30531490409374235\n",
            "Epoch 7/10, Loss: 0.30599730974435807\n",
            "Epoch 7/10, Loss: 0.3066858966946602\n",
            "Epoch 7/10, Loss: 0.3073829011917114\n",
            "Epoch 7/10, Loss: 0.30806295317411425\n",
            "Epoch 7/10, Loss: 0.3087433436512947\n",
            "Epoch 7/10, Loss: 0.30943781727552416\n",
            "Epoch 7/10, Loss: 0.31012195366621015\n",
            "Epoch 7/10, Loss: 0.310804672062397\n",
            "Epoch 7/10, Loss: 0.31149065071344373\n",
            "Epoch 7/10, Loss: 0.3121827432513237\n",
            "Epoch 7/10, Loss: 0.31287872380018233\n",
            "Epoch 7/10, Loss: 0.3135773154497147\n",
            "Epoch 7/10, Loss: 0.3142863310575485\n",
            "Epoch 7/10, Loss: 0.31496708941459656\n",
            "Epoch 7/10, Loss: 0.3156524678468704\n",
            "Epoch 7/10, Loss: 0.31633503836393356\n",
            "Epoch 7/10, Loss: 0.31702071136236193\n",
            "Epoch 7/10, Loss: 0.31771412086486817\n",
            "Epoch 7/10, Loss: 0.3184087983369827\n",
            "Epoch 7/10, Loss: 0.31909074383974073\n",
            "Epoch 7/10, Loss: 0.3197892387509346\n",
            "Epoch 7/10, Loss: 0.3204827435612679\n",
            "Epoch 7/10, Loss: 0.32117947858572005\n",
            "Epoch 7/10, Loss: 0.3218739746212959\n",
            "Epoch 7/10, Loss: 0.32257905340194704\n",
            "Epoch 7/10, Loss: 0.32325682359933855\n",
            "Epoch 7/10, Loss: 0.3239408077597618\n",
            "Epoch 7/10, Loss: 0.32462325364351274\n",
            "Epoch 7/10, Loss: 0.3253012316823006\n",
            "Epoch 7/10, Loss: 0.3260035015940666\n",
            "Epoch 7/10, Loss: 0.3267051696777344\n",
            "Epoch 7/10, Loss: 0.32738473486900327\n",
            "Epoch 7/10, Loss: 0.32808377510309217\n",
            "Epoch 7/10, Loss: 0.32876725471019747\n",
            "Epoch 7/10, Loss: 0.3294576063752174\n",
            "Epoch 7/10, Loss: 0.3301504138112068\n",
            "Epoch 7/10, Loss: 0.33085921585559847\n",
            "Epoch 7/10, Loss: 0.331553440451622\n",
            "Epoch 7/10, Loss: 0.3322380716204643\n",
            "Epoch 7/10, Loss: 0.3329366242289543\n",
            "Epoch 7/10, Loss: 0.33364311677217484\n",
            "Epoch 7/10, Loss: 0.3343282688856125\n",
            "Epoch 7/10, Loss: 0.3350150563120842\n",
            "Epoch 7/10, Loss: 0.33570692253112794\n",
            "Epoch 7/10, Loss: 0.3364069275856018\n",
            "Epoch 7/10, Loss: 0.3370914298892021\n",
            "Epoch 7/10, Loss: 0.3377869723439217\n",
            "Epoch 7/10, Loss: 0.33848123300075533\n",
            "Epoch 7/10, Loss: 0.33917071866989135\n",
            "Epoch 7/10, Loss: 0.33985552203655245\n",
            "Epoch 7/10, Loss: 0.34054677641391756\n",
            "Epoch 7/10, Loss: 0.3412515670657158\n",
            "Epoch 7/10, Loss: 0.3419372506737709\n",
            "Epoch 7/10, Loss: 0.3426259782910347\n",
            "Epoch 7/10, Loss: 0.34333058255910875\n",
            "Epoch 7/10, Loss: 0.34403372740745547\n",
            "Epoch 7/10, Loss: 0.34472366178035735\n",
            "Epoch 7/10, Loss: 0.34540893363952635\n",
            "Epoch 7/10, Loss: 0.3461032034754753\n",
            "Epoch 7/10, Loss: 0.3467919980883598\n",
            "Epoch 7/10, Loss: 0.3474962770342827\n",
            "Epoch 7/10, Loss: 0.3481839073300362\n",
            "Epoch 7/10, Loss: 0.348877126455307\n",
            "Epoch 7/10, Loss: 0.3495659595727921\n",
            "Epoch 7/10, Loss: 0.3502674376964569\n",
            "Epoch 7/10, Loss: 0.3509518867135048\n",
            "Epoch 7/10, Loss: 0.3516411057114601\n",
            "Epoch 7/10, Loss: 0.35233544212579726\n",
            "Epoch 7/10, Loss: 0.35303765386343\n",
            "Epoch 7/10, Loss: 0.3537333742380142\n",
            "Epoch 7/10, Loss: 0.3544208468198776\n",
            "Epoch 7/10, Loss: 0.35510884487628935\n",
            "Epoch 7/10, Loss: 0.35580475240945814\n",
            "Epoch 7/10, Loss: 0.35650082790851595\n",
            "Epoch 7/10, Loss: 0.35719791942834855\n",
            "Epoch 7/10, Loss: 0.3578905863761902\n",
            "Epoch 7/10, Loss: 0.3585884597301483\n",
            "Epoch 7/10, Loss: 0.3592775183916092\n",
            "Epoch 7/10, Loss: 0.3599638766050339\n",
            "Epoch 7/10, Loss: 0.3606545685529709\n",
            "Epoch 7/10, Loss: 0.361337838947773\n",
            "Epoch 7/10, Loss: 0.3620330726504326\n",
            "Epoch 7/10, Loss: 0.3627178377509117\n",
            "Epoch 7/10, Loss: 0.36342369455099105\n",
            "Epoch 7/10, Loss: 0.3641214856505394\n",
            "Epoch 7/10, Loss: 0.36480640691518784\n",
            "Epoch 7/10, Loss: 0.3654851545095444\n",
            "Epoch 7/10, Loss: 0.3661794909834862\n",
            "Epoch 7/10, Loss: 0.3668693678975105\n",
            "Epoch 7/10, Loss: 0.3675625358223915\n",
            "Epoch 7/10, Loss: 0.36826398128271104\n",
            "Epoch 7/10, Loss: 0.36895737320184707\n",
            "Epoch 7/10, Loss: 0.36964777410030364\n",
            "Epoch 7/10, Loss: 0.3703474419116974\n",
            "Epoch 7/10, Loss: 0.371037473320961\n",
            "Epoch 7/10, Loss: 0.3717341602444649\n",
            "Epoch 7/10, Loss: 0.37242690336704254\n",
            "Epoch 7/10, Loss: 0.37311989164352416\n",
            "Epoch 7/10, Loss: 0.37381321585178373\n",
            "Epoch 7/10, Loss: 0.37449079704284666\n",
            "Epoch 7/10, Loss: 0.375173966050148\n",
            "Epoch 7/10, Loss: 0.3758630596399307\n",
            "Epoch 7/10, Loss: 0.3765475544333458\n",
            "Epoch 7/10, Loss: 0.37723283380270006\n",
            "Epoch 7/10, Loss: 0.37792129975557326\n",
            "Epoch 7/10, Loss: 0.3786081099510193\n",
            "Epoch 7/10, Loss: 0.3793020771145821\n",
            "Epoch 7/10, Loss: 0.3799965339899063\n",
            "Epoch 7/10, Loss: 0.3806858928799629\n",
            "Epoch 7/10, Loss: 0.3813778033256531\n",
            "Epoch 7/10, Loss: 0.3820718472599983\n",
            "Epoch 7/10, Loss: 0.3827541986703873\n",
            "Epoch 7/10, Loss: 0.3834433096647263\n",
            "Epoch 7/10, Loss: 0.3841263241767883\n",
            "Epoch 7/10, Loss: 0.384820532977581\n",
            "Epoch 7/10, Loss: 0.385502413213253\n",
            "Epoch 7/10, Loss: 0.38619766402244565\n",
            "Epoch 7/10, Loss: 0.38689032751321795\n",
            "Epoch 7/10, Loss: 0.3875913908481598\n",
            "Epoch 7/10, Loss: 0.38827666211128237\n",
            "Epoch 7/10, Loss: 0.38896233797073365\n",
            "Epoch 7/10, Loss: 0.3896531820297241\n",
            "Epoch 7/10, Loss: 0.39034318512678146\n",
            "Epoch 7/10, Loss: 0.3910317695736885\n",
            "Epoch 7/10, Loss: 0.3917279887199402\n",
            "Epoch 7/10, Loss: 0.3924223756790161\n",
            "Epoch 7/10, Loss: 0.39311399233341215\n",
            "Epoch 7/10, Loss: 0.3938068365454674\n",
            "Epoch 7/10, Loss: 0.3944826246500015\n",
            "Epoch 7/10, Loss: 0.39518487334251406\n",
            "Epoch 7/10, Loss: 0.3958589552640915\n",
            "Epoch 7/10, Loss: 0.39654707384109494\n",
            "Epoch 7/10, Loss: 0.3972326114177704\n",
            "Epoch 7/10, Loss: 0.3979276393651962\n",
            "Epoch 7/10, Loss: 0.3986234081983566\n",
            "Epoch 7/10, Loss: 0.3993252032995224\n",
            "Epoch 7/10, Loss: 0.4000213359594345\n",
            "Epoch 7/10, Loss: 0.40070298564434054\n",
            "Epoch 7/10, Loss: 0.4013871054053307\n",
            "Epoch 7/10, Loss: 0.40207992774248125\n",
            "Epoch 7/10, Loss: 0.4027763115167618\n",
            "Epoch 7/10, Loss: 0.4034568589925766\n",
            "Epoch 7/10, Loss: 0.4041566010713577\n",
            "Epoch 7/10, Loss: 0.4048371284008026\n",
            "Epoch 7/10, Loss: 0.4055250582098961\n",
            "Epoch 7/10, Loss: 0.4062169274687767\n",
            "Epoch 7/10, Loss: 0.40690886133909226\n",
            "Epoch 7/10, Loss: 0.407605672121048\n",
            "Epoch 7/10, Loss: 0.4082958438396454\n",
            "Epoch 7/10, Loss: 0.40898373663425447\n",
            "Epoch 7/10, Loss: 0.4096747313141823\n",
            "Epoch 7/10, Loss: 0.4103733324408531\n",
            "Epoch 7/10, Loss: 0.41107240319252014\n",
            "Epoch 7/10, Loss: 0.4117726740837097\n",
            "Epoch 7/10, Loss: 0.41246413308382035\n",
            "Epoch 7/10, Loss: 0.4131561158299446\n",
            "Epoch 7/10, Loss: 0.4138402553200722\n",
            "Epoch 7/10, Loss: 0.4145225401520729\n",
            "Epoch 7/10, Loss: 0.4152141336798668\n",
            "Epoch 7/10, Loss: 0.41590735322237016\n",
            "Epoch 7/10, Loss: 0.4165934347510338\n",
            "Epoch 7/10, Loss: 0.4172930874824524\n",
            "Epoch 7/10, Loss: 0.4179883990287781\n",
            "Epoch 7/10, Loss: 0.4186878725886345\n",
            "Epoch 7/10, Loss: 0.4193813655972481\n",
            "Epoch 7/10, Loss: 0.42006454199552534\n",
            "Epoch 7/10, Loss: 0.42075249856710434\n",
            "Epoch 7/10, Loss: 0.4214483770132065\n",
            "Epoch 7/10, Loss: 0.4221469878554344\n",
            "Epoch 7/10, Loss: 0.42283207827806474\n",
            "Epoch 7/10, Loss: 0.4235296376943588\n",
            "Epoch 7/10, Loss: 0.4242023186683655\n",
            "Epoch 7/10, Loss: 0.4248985328674316\n",
            "Epoch 7/10, Loss: 0.42559054017066955\n",
            "Epoch 7/10, Loss: 0.4262873342037201\n",
            "Epoch 7/10, Loss: 0.4269778677225113\n",
            "Epoch 7/10, Loss: 0.4276560286283493\n",
            "Epoch 7/10, Loss: 0.42834808242321015\n",
            "Epoch 7/10, Loss: 0.4290363844037056\n",
            "Epoch 7/10, Loss: 0.4297262383699417\n",
            "Epoch 7/10, Loss: 0.43042520916461946\n",
            "Epoch 7/10, Loss: 0.4311137329936027\n",
            "Epoch 7/10, Loss: 0.4317997928261757\n",
            "Epoch 7/10, Loss: 0.43248837488889696\n",
            "Epoch 7/10, Loss: 0.43318398112058637\n",
            "Epoch 7/10, Loss: 0.43388573092222216\n",
            "Epoch 7/10, Loss: 0.4345688135623932\n",
            "Epoch 7/10, Loss: 0.4352696670293808\n",
            "Epoch 7/10, Loss: 0.43595614528656007\n",
            "Epoch 7/10, Loss: 0.4366387193799019\n",
            "Epoch 7/10, Loss: 0.43734428244829177\n",
            "Epoch 7/10, Loss: 0.4380381019115448\n",
            "Epoch 7/10, Loss: 0.4387332992553711\n",
            "Epoch 7/10, Loss: 0.4394192863106728\n",
            "Epoch 7/10, Loss: 0.44011834782361986\n",
            "Epoch 7/10, Loss: 0.4408214229941368\n",
            "Epoch 7/10, Loss: 0.44151251602172853\n",
            "Epoch 7/10, Loss: 0.4422016417980194\n",
            "Epoch 7/10, Loss: 0.4428892773985863\n",
            "Epoch 7/10, Loss: 0.44357865273952485\n",
            "Epoch 7/10, Loss: 0.44426429319381716\n",
            "Epoch 7/10, Loss: 0.44496172839403153\n",
            "Epoch 7/10, Loss: 0.44564979034662244\n",
            "Epoch 7/10, Loss: 0.4463333081007004\n",
            "Epoch 7/10, Loss: 0.44701710844039916\n",
            "Epoch 7/10, Loss: 0.44770569396018983\n",
            "Epoch 7/10, Loss: 0.44839157903194427\n",
            "Epoch 7/10, Loss: 0.44907680082321166\n",
            "Epoch 7/10, Loss: 0.44977242112159727\n",
            "Epoch 7/10, Loss: 0.45048449862003326\n",
            "Epoch 7/10, Loss: 0.45117952221632\n",
            "Epoch 7/10, Loss: 0.4518792353272438\n",
            "Epoch 7/10, Loss: 0.45257664734125136\n",
            "Epoch 7/10, Loss: 0.4532662353515625\n",
            "Epoch 7/10, Loss: 0.45395890629291535\n",
            "Epoch 7/10, Loss: 0.4546511228680611\n",
            "Epoch 7/10, Loss: 0.45534477025270464\n",
            "Epoch 7/10, Loss: 0.45604360991716386\n",
            "Epoch 7/10, Loss: 0.45673137551546095\n",
            "Epoch 7/10, Loss: 0.4574210533499718\n",
            "Epoch 7/10, Loss: 0.45809780514240267\n",
            "Epoch 7/10, Loss: 0.45878609746694565\n",
            "Epoch 7/10, Loss: 0.4594869702458382\n",
            "Epoch 7/10, Loss: 0.46017496156692506\n",
            "Epoch 7/10, Loss: 0.4608653483986855\n",
            "Epoch 7/10, Loss: 0.46156326919794083\n",
            "Epoch 7/10, Loss: 0.4622490348815918\n",
            "Epoch 7/10, Loss: 0.4629279459118843\n",
            "Epoch 7/10, Loss: 0.46360782653093335\n",
            "Epoch 7/10, Loss: 0.4642973285317421\n",
            "Epoch 7/10, Loss: 0.46498537707328796\n",
            "Epoch 7/10, Loss: 0.46567531043291094\n",
            "Epoch 7/10, Loss: 0.46635707169771196\n",
            "Epoch 7/10, Loss: 0.4670559715032577\n",
            "Epoch 7/10, Loss: 0.46774397987127303\n",
            "Epoch 7/10, Loss: 0.468441702246666\n",
            "Epoch 7/10, Loss: 0.4691418208479881\n",
            "Epoch 7/10, Loss: 0.4698352318406105\n",
            "Epoch 7/10, Loss: 0.4705402621626854\n",
            "Epoch 7/10, Loss: 0.47123418730497363\n",
            "Epoch 7/10, Loss: 0.47192263251543043\n",
            "Epoch 7/10, Loss: 0.4726214410662651\n",
            "Epoch 7/10, Loss: 0.47332248610258104\n",
            "Epoch 7/10, Loss: 0.4740259171128273\n",
            "Epoch 7/10, Loss: 0.47471733689308165\n",
            "Epoch 7/10, Loss: 0.47540703529119493\n",
            "Epoch 7/10, Loss: 0.4760942589640617\n",
            "Epoch 7/10, Loss: 0.4767879201769829\n",
            "Epoch 7/10, Loss: 0.4774881876707077\n",
            "Epoch 7/10, Loss: 0.47817951571941375\n",
            "Epoch 7/10, Loss: 0.4788664677143097\n",
            "Epoch 7/10, Loss: 0.47955207574367525\n",
            "Epoch 7/10, Loss: 0.4802422031164169\n",
            "Epoch 7/10, Loss: 0.4809300125837326\n",
            "Epoch 7/10, Loss: 0.4816208165884018\n",
            "Epoch 7/10, Loss: 0.48231378197669983\n",
            "Epoch 7/10, Loss: 0.4830008307099342\n",
            "Epoch 7/10, Loss: 0.4836970645189285\n",
            "Epoch 7/10, Loss: 0.4843928001523018\n",
            "Epoch 7/10, Loss: 0.48508934313058855\n",
            "Epoch 7/10, Loss: 0.48578370064496995\n",
            "Epoch 7/10, Loss: 0.4864733560681343\n",
            "Epoch 7/10, Loss: 0.48716823267936704\n",
            "Epoch 7/10, Loss: 0.4878541715145111\n",
            "Epoch 7/10, Loss: 0.48853872692584993\n",
            "Epoch 7/10, Loss: 0.4892262336611748\n",
            "Epoch 7/10, Loss: 0.48993015789985656\n",
            "Epoch 7/10, Loss: 0.49062182545661925\n",
            "Epoch 7/10, Loss: 0.49130809742212295\n",
            "Epoch 7/10, Loss: 0.4919964767694473\n",
            "Epoch 7/10, Loss: 0.4926896533370018\n",
            "Epoch 7/10, Loss: 0.4933805405497551\n",
            "Epoch 7/10, Loss: 0.49405639559030534\n",
            "Epoch 7/10, Loss: 0.4947520582675934\n",
            "Epoch 7/10, Loss: 0.49545209264755247\n",
            "Epoch 7/10, Loss: 0.49614663565158845\n",
            "Epoch 7/10, Loss: 0.49683745837211607\n",
            "Epoch 7/10, Loss: 0.49752106493711473\n",
            "Epoch 7/10, Loss: 0.49822392052412035\n",
            "Epoch 7/10, Loss: 0.4989125526547432\n",
            "Epoch 7/10, Loss: 0.49960614055395125\n",
            "Epoch 7/10, Loss: 0.5003006293773651\n",
            "Epoch 7/10, Loss: 0.5009986964464188\n",
            "Epoch 7/10, Loss: 0.5016895006895066\n",
            "Epoch 7/10, Loss: 0.5023870750069618\n",
            "Epoch 7/10, Loss: 0.5030753743052483\n",
            "Epoch 7/10, Loss: 0.5037699404954911\n",
            "Epoch 7/10, Loss: 0.5044703578948975\n",
            "Epoch 7/10, Loss: 0.505173582315445\n",
            "Epoch 7/10, Loss: 0.5058718551397323\n",
            "Epoch 7/10, Loss: 0.5065665308237076\n",
            "Epoch 7/10, Loss: 0.507259897172451\n",
            "Epoch 7/10, Loss: 0.5079413421750069\n",
            "Epoch 7/10, Loss: 0.5086219829916954\n",
            "Epoch 7/10, Loss: 0.5093110040426254\n",
            "Epoch 7/10, Loss: 0.5100051199197769\n",
            "Epoch 7/10, Loss: 0.5107055044174195\n",
            "Epoch 7/10, Loss: 0.5113967531919479\n",
            "Epoch 7/10, Loss: 0.5120820476412773\n",
            "Epoch 7/10, Loss: 0.5127598783373832\n",
            "Epoch 7/10, Loss: 0.5134512794613838\n",
            "Epoch 7/10, Loss: 0.514147082209587\n",
            "Epoch 7/10, Loss: 0.5148366862535476\n",
            "Epoch 7/10, Loss: 0.5155279436707496\n",
            "Epoch 7/10, Loss: 0.5162143584489822\n",
            "Epoch 7/10, Loss: 0.5169157539010047\n",
            "Epoch 7/10, Loss: 0.5175983436703682\n",
            "Epoch 7/10, Loss: 0.5182918868064881\n",
            "Epoch 7/10, Loss: 0.5189937871098519\n",
            "Epoch 7/10, Loss: 0.5196773254275322\n",
            "Epoch 7/10, Loss: 0.5203675662875176\n",
            "Epoch 7/10, Loss: 0.5210570634007454\n",
            "Epoch 7/10, Loss: 0.5217498342394828\n",
            "Epoch 7/10, Loss: 0.5224432768821716\n",
            "Epoch 7/10, Loss: 0.5231317938566208\n",
            "Epoch 7/10, Loss: 0.5238325675725937\n",
            "Epoch 7/10, Loss: 0.5245237592458725\n",
            "Epoch 7/10, Loss: 0.5252136183381081\n",
            "Epoch 7/10, Loss: 0.5259105616211891\n",
            "Epoch 7/10, Loss: 0.5266062515377998\n",
            "Epoch 7/10, Loss: 0.5272946827411652\n",
            "Epoch 7/10, Loss: 0.5279839453101158\n",
            "Epoch 7/10, Loss: 0.5286692861318588\n",
            "Epoch 7/10, Loss: 0.5293559064269066\n",
            "Epoch 7/10, Loss: 0.5300556731820106\n",
            "Epoch 7/10, Loss: 0.5307496438026428\n",
            "Epoch 7/10, Loss: 0.5314319340586662\n",
            "Epoch 7/10, Loss: 0.5321220549941063\n",
            "Epoch 7/10, Loss: 0.5328190599679947\n",
            "Epoch 7/10, Loss: 0.533517831504345\n",
            "Epoch 7/10, Loss: 0.5342136718034745\n",
            "Epoch 7/10, Loss: 0.5349162002205848\n",
            "Epoch 7/10, Loss: 0.5356026933789253\n",
            "Epoch 7/10, Loss: 0.536296297609806\n",
            "Epoch 7/10, Loss: 0.5369888498783112\n",
            "Epoch 7/10, Loss: 0.5376927825808525\n",
            "Epoch 7/10, Loss: 0.5383827319741249\n",
            "Epoch 7/10, Loss: 0.539083004295826\n",
            "Epoch 7/10, Loss: 0.5397727062106132\n",
            "Epoch 7/10, Loss: 0.5404525273442269\n",
            "Epoch 7/10, Loss: 0.5411426354646682\n",
            "Epoch 7/10, Loss: 0.5418309324979782\n",
            "Epoch 7/10, Loss: 0.5425110048055649\n",
            "Epoch 7/10, Loss: 0.543198562681675\n",
            "Epoch 7/10, Loss: 0.5438801266551018\n",
            "Epoch 7/10, Loss: 0.5445693565011025\n",
            "Epoch 7/10, Loss: 0.5452531437277794\n",
            "Epoch 7/10, Loss: 0.545937313914299\n",
            "Epoch 7/10, Loss: 0.5466196150779724\n",
            "Epoch 7/10, Loss: 0.5473040361404419\n",
            "Epoch 7/10, Loss: 0.5479937459230423\n",
            "Epoch 7/10, Loss: 0.5486893432736397\n",
            "Epoch 7/10, Loss: 0.5493742620944977\n",
            "Epoch 7/10, Loss: 0.5500556072592735\n",
            "Epoch 7/10, Loss: 0.5507454161047936\n",
            "Epoch 7/10, Loss: 0.5514227070808411\n",
            "Epoch 7/10, Loss: 0.5521230645775795\n",
            "Epoch 7/10, Loss: 0.5528108583092689\n",
            "Epoch 7/10, Loss: 0.5534969639778137\n",
            "Epoch 7/10, Loss: 0.5541963193416596\n",
            "Epoch 7/10, Loss: 0.554876246213913\n",
            "Epoch 7/10, Loss: 0.5555719426274299\n",
            "Epoch 7/10, Loss: 0.5562658655047417\n",
            "Epoch 7/10, Loss: 0.5569537045955658\n",
            "Epoch 7/10, Loss: 0.557644875228405\n",
            "Epoch 7/10, Loss: 0.5583328357338906\n",
            "Epoch 7/10, Loss: 0.5590176876783371\n",
            "Epoch 7/10, Loss: 0.5597238680124282\n",
            "Epoch 7/10, Loss: 0.5604156947731972\n",
            "Epoch 7/10, Loss: 0.561108971297741\n",
            "Epoch 7/10, Loss: 0.5618011897802353\n",
            "Epoch 7/10, Loss: 0.5624959650039673\n",
            "Epoch 7/10, Loss: 0.5631905035376549\n",
            "Epoch 7/10, Loss: 0.563878641307354\n",
            "Epoch 7/10, Loss: 0.5645490154027939\n",
            "Epoch 7/10, Loss: 0.5652540992498398\n",
            "Epoch 7/10, Loss: 0.5659535009860992\n",
            "Epoch 7/10, Loss: 0.5666387619376183\n",
            "Epoch 7/10, Loss: 0.5673308122754097\n",
            "Epoch 7/10, Loss: 0.5680219052433968\n",
            "Epoch 7/10, Loss: 0.5687048891782761\n",
            "Epoch 7/10, Loss: 0.5693888453245163\n",
            "Epoch 7/10, Loss: 0.5700794788599014\n",
            "Epoch 7/10, Loss: 0.5707697789669037\n",
            "Epoch 7/10, Loss: 0.5714594759941101\n",
            "Epoch 7/10, Loss: 0.5721476480960846\n",
            "Epoch 7/10, Loss: 0.5728364717364312\n",
            "Epoch 7/10, Loss: 0.5735313207507133\n",
            "Epoch 7/10, Loss: 0.5742205516695976\n",
            "Epoch 7/10, Loss: 0.5749147182703018\n",
            "Epoch 7/10, Loss: 0.575600690126419\n",
            "Epoch 7/10, Loss: 0.5762946867346763\n",
            "Epoch 7/10, Loss: 0.5769805616140365\n",
            "Epoch 7/10, Loss: 0.5776781686544419\n",
            "Epoch 7/10, Loss: 0.5783647738695145\n",
            "Epoch 7/10, Loss: 0.5790584282279014\n",
            "Epoch 7/10, Loss: 0.5797456862330437\n",
            "Epoch 7/10, Loss: 0.5804446081519127\n",
            "Epoch 7/10, Loss: 0.5811361199617386\n",
            "Epoch 7/10, Loss: 0.5818289961814881\n",
            "Epoch 7/10, Loss: 0.5825184174776077\n",
            "Epoch 7/10, Loss: 0.5831991747617722\n",
            "Epoch 7/10, Loss: 0.5838756254315376\n",
            "Epoch 7/10, Loss: 0.584576594889164\n",
            "Epoch 7/10, Loss: 0.5852713806033134\n",
            "Epoch 7/10, Loss: 0.585973557293415\n",
            "Epoch 7/10, Loss: 0.5866661152243614\n",
            "Epoch 7/10, Loss: 0.5873504586815834\n",
            "Epoch 7/10, Loss: 0.5880448201298714\n",
            "Epoch 7/10, Loss: 0.5887375227808952\n",
            "Epoch 7/10, Loss: 0.5894301891922951\n",
            "Epoch 7/10, Loss: 0.5901205707192421\n",
            "Epoch 7/10, Loss: 0.5907948818802834\n",
            "Epoch 7/10, Loss: 0.5914829205870629\n",
            "Epoch 7/10, Loss: 0.592174272954464\n",
            "Epoch 7/10, Loss: 0.5928537215590477\n",
            "Epoch 7/10, Loss: 0.5935383678078652\n",
            "Epoch 7/10, Loss: 0.594217314183712\n",
            "Epoch 7/10, Loss: 0.5948993005752563\n",
            "Epoch 7/10, Loss: 0.5955894930362702\n",
            "Epoch 7/10, Loss: 0.5962904070615769\n",
            "Epoch 7/10, Loss: 0.5969721809029579\n",
            "Epoch 7/10, Loss: 0.5976619679927826\n",
            "Epoch 7/10, Loss: 0.5983428585529328\n",
            "Epoch 7/10, Loss: 0.59902624386549\n",
            "Epoch 7/10, Loss: 0.5997225285768509\n",
            "Epoch 7/10, Loss: 0.6004214280843735\n",
            "Epoch 7/10, Loss: 0.6011230638623237\n",
            "Epoch 7/10, Loss: 0.6018104905486107\n",
            "Epoch 7/10, Loss: 0.6024940930008889\n",
            "Epoch 7/10, Loss: 0.603190554201603\n",
            "Epoch 7/10, Loss: 0.6038791816830635\n",
            "Epoch 7/10, Loss: 0.604572615981102\n",
            "Epoch 7/10, Loss: 0.6052607308626174\n",
            "Epoch 7/10, Loss: 0.6059419822692871\n",
            "Epoch 7/10, Loss: 0.6066323735713959\n",
            "Epoch 7/10, Loss: 0.6073168077468872\n",
            "Epoch 7/10, Loss: 0.6079994269013405\n",
            "Epoch 7/10, Loss: 0.6086950816512108\n",
            "Epoch 7/10, Loss: 0.6093852421045304\n",
            "Epoch 7/10, Loss: 0.6100781357288361\n",
            "Epoch 7/10, Loss: 0.6107729400992393\n",
            "Epoch 7/10, Loss: 0.6114613788723946\n",
            "Epoch 7/10, Loss: 0.6121488159298897\n",
            "Epoch 7/10, Loss: 0.6128317885994912\n",
            "Epoch 7/10, Loss: 0.6135206565260887\n",
            "Epoch 7/10, Loss: 0.6142126414179802\n",
            "Epoch 7/10, Loss: 0.6149063328504563\n",
            "Epoch 7/10, Loss: 0.6156055216789246\n",
            "Epoch 7/10, Loss: 0.6162859699726104\n",
            "Epoch 7/10, Loss: 0.6169754870533943\n",
            "Epoch 7/10, Loss: 0.6176487373709678\n",
            "Epoch 7/10, Loss: 0.6183319842815399\n",
            "Epoch 7/10, Loss: 0.619020287513733\n",
            "Epoch 7/10, Loss: 0.6197117363810539\n",
            "Epoch 7/10, Loss: 0.6204058873653412\n",
            "Epoch 7/10, Loss: 0.6210985143184662\n",
            "Epoch 7/10, Loss: 0.6217945730686187\n",
            "Epoch 7/10, Loss: 0.6224826558232307\n",
            "Epoch 7/10, Loss: 0.623170463681221\n",
            "Epoch 7/10, Loss: 0.6238619332909584\n",
            "Epoch 7/10, Loss: 0.6245592975020409\n",
            "Epoch 7/10, Loss: 0.6252469704151153\n",
            "Epoch 7/10, Loss: 0.6259291634559632\n",
            "Epoch 7/10, Loss: 0.6266154683232308\n",
            "Epoch 7/10, Loss: 0.6273063129782677\n",
            "Epoch 7/10, Loss: 0.6279911833405495\n",
            "Epoch 7/10, Loss: 0.6286748700141906\n",
            "Epoch 7/10, Loss: 0.6293702105879784\n",
            "Epoch 7/10, Loss: 0.6300603210926056\n",
            "Epoch 7/10, Loss: 0.6307451584339142\n",
            "Epoch 7/10, Loss: 0.631438490152359\n",
            "Epoch 7/10, Loss: 0.6321331197023392\n",
            "Epoch 7/10, Loss: 0.6328274120092392\n",
            "Epoch 7/10, Loss: 0.6335128710865975\n",
            "Epoch 7/10, Loss: 0.6342078630328178\n",
            "Epoch 7/10, Loss: 0.6348979649543762\n",
            "Epoch 7/10, Loss: 0.6355797824263573\n",
            "Epoch 7/10, Loss: 0.6362745867967605\n",
            "Epoch 7/10, Loss: 0.6369778184890748\n",
            "Epoch 7/10, Loss: 0.6376598917841911\n",
            "Epoch 7/10, Loss: 0.6383555673360825\n",
            "Epoch 7/10, Loss: 0.6390371174812317\n",
            "Epoch 7/10, Loss: 0.639729265332222\n",
            "Epoch 7/10, Loss: 0.640407002389431\n",
            "Epoch 7/10, Loss: 0.6410999633669853\n",
            "Epoch 7/10, Loss: 0.6417898005843162\n",
            "Epoch 7/10, Loss: 0.6424889187812806\n",
            "Epoch 7/10, Loss: 0.6431847538948059\n",
            "Epoch 7/10, Loss: 0.6438712838292122\n",
            "Epoch 7/10, Loss: 0.644548470556736\n",
            "Epoch 7/10, Loss: 0.6452371543049812\n",
            "Epoch 7/10, Loss: 0.6459229708909988\n",
            "Epoch 7/10, Loss: 0.6466184446811676\n",
            "Epoch 7/10, Loss: 0.6473090131282806\n",
            "Epoch 7/10, Loss: 0.6479997471570969\n",
            "Epoch 7/10, Loss: 0.6487020408511162\n",
            "Epoch 7/10, Loss: 0.6494021677374839\n",
            "Epoch 7/10, Loss: 0.6500861483812332\n",
            "Epoch 7/10, Loss: 0.6507714425325394\n",
            "Epoch 7/10, Loss: 0.651458083987236\n",
            "Epoch 7/10, Loss: 0.6521493483781815\n",
            "Epoch 7/10, Loss: 0.652841217637062\n",
            "Epoch 7/10, Loss: 0.6535127604007721\n",
            "Epoch 7/10, Loss: 0.6541967889070511\n",
            "Epoch 7/10, Loss: 0.6548879278898239\n",
            "Epoch 7/10, Loss: 0.655583743751049\n",
            "Epoch 7/10, Loss: 0.6562907010912895\n",
            "Epoch 7/10, Loss: 0.6569797244071961\n",
            "Epoch 7/10, Loss: 0.6576794624328614\n",
            "Epoch 7/10, Loss: 0.6583761739730835\n",
            "Epoch 7/10, Loss: 0.6590694521069527\n",
            "Epoch 7/10, Loss: 0.6597597911953926\n",
            "Epoch 7/10, Loss: 0.6604476165175438\n",
            "Epoch 7/10, Loss: 0.6611383848190308\n",
            "Epoch 7/10, Loss: 0.6618272567987442\n",
            "Epoch 7/10, Loss: 0.6625192382335663\n",
            "Epoch 7/10, Loss: 0.6632165699601174\n",
            "Epoch 7/10, Loss: 0.6639009966254235\n",
            "Epoch 7/10, Loss: 0.6645944649577141\n",
            "Epoch 7/10, Loss: 0.665288890004158\n",
            "Epoch 7/10, Loss: 0.6659800440073014\n",
            "Epoch 7/10, Loss: 0.6666739474534988\n",
            "Epoch 7/10, Loss: 0.6673721706867218\n",
            "Epoch 7/10, Loss: 0.6680652546882629\n",
            "Epoch 7/10, Loss: 0.6687590607404709\n",
            "Epoch 7/10, Loss: 0.6694557980298996\n",
            "Epoch 7/10, Loss: 0.6701500212550163\n",
            "Epoch 7/10, Loss: 0.6708399521112443\n",
            "Epoch 7/10, Loss: 0.6715279052257538\n",
            "Epoch 7/10, Loss: 0.672212563097477\n",
            "Epoch 7/10, Loss: 0.6728975692987442\n",
            "Epoch 7/10, Loss: 0.6735929293632508\n",
            "Epoch 7/10, Loss: 0.6742901289463044\n",
            "Epoch 7/10, Loss: 0.6749802206754685\n",
            "Epoch 7/10, Loss: 0.6756680588722229\n",
            "Epoch 7/10, Loss: 0.6763582930564881\n",
            "Epoch 7/10, Loss: 0.6770610294342041\n",
            "Epoch 7/10, Loss: 0.6777658659219742\n",
            "Epoch 7/10, Loss: 0.6784490382671357\n",
            "Epoch 7/10, Loss: 0.6791481465697289\n",
            "Epoch 7/10, Loss: 0.6798377223610877\n",
            "Epoch 7/10, Loss: 0.6805213421583176\n",
            "Epoch 7/10, Loss: 0.681226756453514\n",
            "Epoch 7/10, Loss: 0.6819243495464324\n",
            "Epoch 7/10, Loss: 0.6826061597466468\n",
            "Epoch 7/10, Loss: 0.6832992149591446\n",
            "Epoch 7/10, Loss: 0.6839986732602119\n",
            "Epoch 7/10, Loss: 0.6847184343338013\n",
            "Epoch 7/10, Loss: 0.6853990412950516\n",
            "Epoch 7/10, Loss: 0.6860939375162125\n",
            "Epoch 7/10, Loss: 0.686787757396698\n",
            "Epoch 7/10, Loss: 0.6874874172210693\n",
            "Epoch 7/10, Loss: 0.6881757709980011\n",
            "Epoch 7/10, Loss: 0.6888643149137497\n",
            "Epoch 7/10, Loss: 0.6895638185739518\n",
            "Epoch 7/10, Loss: 0.6902603224515915\n",
            "Epoch 7/10, Loss: 0.6909518849849701\n",
            "Epoch 8/10, Loss: 0.0006929463148117065\n",
            "Epoch 8/10, Loss: 0.001385776162147522\n",
            "Epoch 8/10, Loss: 0.0020784748792648314\n",
            "Epoch 8/10, Loss: 0.002773140549659729\n",
            "Epoch 8/10, Loss: 0.0034588465094566347\n",
            "Epoch 8/10, Loss: 0.004151900351047516\n",
            "Epoch 8/10, Loss: 0.0048336368203163145\n",
            "Epoch 8/10, Loss: 0.005527942955493927\n",
            "Epoch 8/10, Loss: 0.00621154510974884\n",
            "Epoch 8/10, Loss: 0.0068926669359207155\n",
            "Epoch 8/10, Loss: 0.007579685926437378\n",
            "Epoch 8/10, Loss: 0.00826026850938797\n",
            "Epoch 8/10, Loss: 0.00894287544488907\n",
            "Epoch 8/10, Loss: 0.00963712364435196\n",
            "Epoch 8/10, Loss: 0.010330745995044709\n",
            "Epoch 8/10, Loss: 0.011029893279075623\n",
            "Epoch 8/10, Loss: 0.011731561899185181\n",
            "Epoch 8/10, Loss: 0.0124054856300354\n",
            "Epoch 8/10, Loss: 0.013103702068328858\n",
            "Epoch 8/10, Loss: 0.013794444918632508\n",
            "Epoch 8/10, Loss: 0.014487533688545226\n",
            "Epoch 8/10, Loss: 0.015178114116191865\n",
            "Epoch 8/10, Loss: 0.01587272971868515\n",
            "Epoch 8/10, Loss: 0.016560229659080505\n",
            "Epoch 8/10, Loss: 0.017237670958042146\n",
            "Epoch 8/10, Loss: 0.017907197773456573\n",
            "Epoch 8/10, Loss: 0.018597654104232787\n",
            "Epoch 8/10, Loss: 0.019290582835674287\n",
            "Epoch 8/10, Loss: 0.01998496776819229\n",
            "Epoch 8/10, Loss: 0.02067714262008667\n",
            "Epoch 8/10, Loss: 0.02136210209131241\n",
            "Epoch 8/10, Loss: 0.022056143581867218\n",
            "Epoch 8/10, Loss: 0.022754066586494447\n",
            "Epoch 8/10, Loss: 0.023449578166007994\n",
            "Epoch 8/10, Loss: 0.024154568791389466\n",
            "Epoch 8/10, Loss: 0.02483752143383026\n",
            "Epoch 8/10, Loss: 0.025532487869262696\n",
            "Epoch 8/10, Loss: 0.026219247579574584\n",
            "Epoch 8/10, Loss: 0.02689958572387695\n",
            "Epoch 8/10, Loss: 0.027589363396167754\n",
            "Epoch 8/10, Loss: 0.028282248735427857\n",
            "Epoch 8/10, Loss: 0.02896660166978836\n",
            "Epoch 8/10, Loss: 0.02966526919603348\n",
            "Epoch 8/10, Loss: 0.030365537106990814\n",
            "Epoch 8/10, Loss: 0.031062505602836608\n",
            "Epoch 8/10, Loss: 0.03174564754962921\n",
            "Epoch 8/10, Loss: 0.03243775260448456\n",
            "Epoch 8/10, Loss: 0.03312781023979187\n",
            "Epoch 8/10, Loss: 0.033831656336784366\n",
            "Epoch 8/10, Loss: 0.034526245951652525\n",
            "Epoch 8/10, Loss: 0.035225065827369686\n",
            "Epoch 8/10, Loss: 0.035904350757598874\n",
            "Epoch 8/10, Loss: 0.036601029336452484\n",
            "Epoch 8/10, Loss: 0.037287223279476166\n",
            "Epoch 8/10, Loss: 0.037980102717876434\n",
            "Epoch 8/10, Loss: 0.03868031054735184\n",
            "Epoch 8/10, Loss: 0.03937512874603272\n",
            "Epoch 8/10, Loss: 0.04006133669614792\n",
            "Epoch 8/10, Loss: 0.04076121121644974\n",
            "Epoch 8/10, Loss: 0.04144678831100464\n",
            "Epoch 8/10, Loss: 0.042133055210113526\n",
            "Epoch 8/10, Loss: 0.04282393175363541\n",
            "Epoch 8/10, Loss: 0.043509690582752225\n",
            "Epoch 8/10, Loss: 0.04421361547708511\n",
            "Epoch 8/10, Loss: 0.04490148025751114\n",
            "Epoch 8/10, Loss: 0.045589066922664644\n",
            "Epoch 8/10, Loss: 0.04628240245580673\n",
            "Epoch 8/10, Loss: 0.046972573161125186\n",
            "Epoch 8/10, Loss: 0.04767634892463684\n",
            "Epoch 8/10, Loss: 0.04837848234176636\n",
            "Epoch 8/10, Loss: 0.049072587668895724\n",
            "Epoch 8/10, Loss: 0.04976253813505173\n",
            "Epoch 8/10, Loss: 0.050449478685855864\n",
            "Epoch 8/10, Loss: 0.05114119058847427\n",
            "Epoch 8/10, Loss: 0.05183337140083313\n",
            "Epoch 8/10, Loss: 0.052521319448947903\n",
            "Epoch 8/10, Loss: 0.05322225886583328\n",
            "Epoch 8/10, Loss: 0.05391524976491928\n",
            "Epoch 8/10, Loss: 0.05460367411375046\n",
            "Epoch 8/10, Loss: 0.05529453295469284\n",
            "Epoch 8/10, Loss: 0.055981615483760835\n",
            "Epoch 8/10, Loss: 0.056659615576267246\n",
            "Epoch 8/10, Loss: 0.05734824711084366\n",
            "Epoch 8/10, Loss: 0.058042336881160735\n",
            "Epoch 8/10, Loss: 0.058720448076725\n",
            "Epoch 8/10, Loss: 0.05940943443775177\n",
            "Epoch 8/10, Loss: 0.060101762533187865\n",
            "Epoch 8/10, Loss: 0.06079527366161346\n",
            "Epoch 8/10, Loss: 0.0614845262169838\n",
            "Epoch 8/10, Loss: 0.062165757179260255\n",
            "Epoch 8/10, Loss: 0.06285762196779252\n",
            "Epoch 8/10, Loss: 0.06354385435581207\n",
            "Epoch 8/10, Loss: 0.06423572933673859\n",
            "Epoch 8/10, Loss: 0.0649329879283905\n",
            "Epoch 8/10, Loss: 0.06562041574716568\n",
            "Epoch 8/10, Loss: 0.06630319064855575\n",
            "Epoch 8/10, Loss: 0.0669888545870781\n",
            "Epoch 8/10, Loss: 0.06766720074415207\n",
            "Epoch 8/10, Loss: 0.0683532508611679\n",
            "Epoch 8/10, Loss: 0.06905062329769135\n",
            "Epoch 8/10, Loss: 0.06974117839336395\n",
            "Epoch 8/10, Loss: 0.0704237505197525\n",
            "Epoch 8/10, Loss: 0.07111026358604432\n",
            "Epoch 8/10, Loss: 0.07179950565099716\n",
            "Epoch 8/10, Loss: 0.07248834592103959\n",
            "Epoch 8/10, Loss: 0.0731647419333458\n",
            "Epoch 8/10, Loss: 0.07385878735780715\n",
            "Epoch 8/10, Loss: 0.0745503289103508\n",
            "Epoch 8/10, Loss: 0.07523956096172332\n",
            "Epoch 8/10, Loss: 0.07592804884910584\n",
            "Epoch 8/10, Loss: 0.07661036109924316\n",
            "Epoch 8/10, Loss: 0.07730175232887268\n",
            "Epoch 8/10, Loss: 0.07799543023109436\n",
            "Epoch 8/10, Loss: 0.0786815083026886\n",
            "Epoch 8/10, Loss: 0.07936748909950256\n",
            "Epoch 8/10, Loss: 0.08007128095626831\n",
            "Epoch 8/10, Loss: 0.08075446182489396\n",
            "Epoch 8/10, Loss: 0.08144554328918457\n",
            "Epoch 8/10, Loss: 0.08213040000200271\n",
            "Epoch 8/10, Loss: 0.0828189879655838\n",
            "Epoch 8/10, Loss: 0.08350239080190659\n",
            "Epoch 8/10, Loss: 0.08418696415424347\n",
            "Epoch 8/10, Loss: 0.08487250536680221\n",
            "Epoch 8/10, Loss: 0.08557177984714508\n",
            "Epoch 8/10, Loss: 0.08626022720336914\n",
            "Epoch 8/10, Loss: 0.08695290398597717\n",
            "Epoch 8/10, Loss: 0.08765121573209762\n",
            "Epoch 8/10, Loss: 0.08834686613082886\n",
            "Epoch 8/10, Loss: 0.08904435491561889\n",
            "Epoch 8/10, Loss: 0.08973473453521728\n",
            "Epoch 8/10, Loss: 0.09043108999729156\n",
            "Epoch 8/10, Loss: 0.09111588859558105\n",
            "Epoch 8/10, Loss: 0.09180422431230545\n",
            "Epoch 8/10, Loss: 0.09249460929632188\n",
            "Epoch 8/10, Loss: 0.093168781042099\n",
            "Epoch 8/10, Loss: 0.09385244882106782\n",
            "Epoch 8/10, Loss: 0.09454735690355301\n",
            "Epoch 8/10, Loss: 0.09523308575153351\n",
            "Epoch 8/10, Loss: 0.09592132306098938\n",
            "Epoch 8/10, Loss: 0.09662054824829101\n",
            "Epoch 8/10, Loss: 0.09731400293111801\n",
            "Epoch 8/10, Loss: 0.09800383692979812\n",
            "Epoch 8/10, Loss: 0.09869676667451859\n",
            "Epoch 8/10, Loss: 0.09939916759729385\n",
            "Epoch 8/10, Loss: 0.10008743876218795\n",
            "Epoch 8/10, Loss: 0.10078332728147507\n",
            "Epoch 8/10, Loss: 0.10147741413116455\n",
            "Epoch 8/10, Loss: 0.10217834687232971\n",
            "Epoch 8/10, Loss: 0.10286117362976074\n",
            "Epoch 8/10, Loss: 0.10353815287351609\n",
            "Epoch 8/10, Loss: 0.1042291259765625\n",
            "Epoch 8/10, Loss: 0.1049168317914009\n",
            "Epoch 8/10, Loss: 0.10560824871063232\n",
            "Epoch 8/10, Loss: 0.10629164457321166\n",
            "Epoch 8/10, Loss: 0.10697946834564209\n",
            "Epoch 8/10, Loss: 0.10765952467918397\n",
            "Epoch 8/10, Loss: 0.1083463289141655\n",
            "Epoch 8/10, Loss: 0.10903241443634033\n",
            "Epoch 8/10, Loss: 0.10971764761209488\n",
            "Epoch 8/10, Loss: 0.11040173149108887\n",
            "Epoch 8/10, Loss: 0.11108689641952514\n",
            "Epoch 8/10, Loss: 0.11178251028060913\n",
            "Epoch 8/10, Loss: 0.11247100782394409\n",
            "Epoch 8/10, Loss: 0.11316509294509888\n",
            "Epoch 8/10, Loss: 0.1138481256365776\n",
            "Epoch 8/10, Loss: 0.11453303182125092\n",
            "Epoch 8/10, Loss: 0.11522696566581726\n",
            "Epoch 8/10, Loss: 0.11591796326637269\n",
            "Epoch 8/10, Loss: 0.11661113941669464\n",
            "Epoch 8/10, Loss: 0.11730403381586074\n",
            "Epoch 8/10, Loss: 0.11799808245897293\n",
            "Epoch 8/10, Loss: 0.11868172067403793\n",
            "Epoch 8/10, Loss: 0.11937056630849838\n",
            "Epoch 8/10, Loss: 0.12006634706258774\n",
            "Epoch 8/10, Loss: 0.1207724095582962\n",
            "Epoch 8/10, Loss: 0.121467036485672\n",
            "Epoch 8/10, Loss: 0.1221464958190918\n",
            "Epoch 8/10, Loss: 0.12283291792869568\n",
            "Epoch 8/10, Loss: 0.1235236741900444\n",
            "Epoch 8/10, Loss: 0.12421653747558593\n",
            "Epoch 8/10, Loss: 0.12491451424360275\n",
            "Epoch 8/10, Loss: 0.1255982208251953\n",
            "Epoch 8/10, Loss: 0.12628872513771058\n",
            "Epoch 8/10, Loss: 0.1269836170077324\n",
            "Epoch 8/10, Loss: 0.12766705280542373\n",
            "Epoch 8/10, Loss: 0.1283658303618431\n",
            "Epoch 8/10, Loss: 0.12905432218313218\n",
            "Epoch 8/10, Loss: 0.1297469127178192\n",
            "Epoch 8/10, Loss: 0.13043190443515779\n",
            "Epoch 8/10, Loss: 0.13111343193054198\n",
            "Epoch 8/10, Loss: 0.13180250066518784\n",
            "Epoch 8/10, Loss: 0.1324977844953537\n",
            "Epoch 8/10, Loss: 0.13318301111459732\n",
            "Epoch 8/10, Loss: 0.1338763343691826\n",
            "Epoch 8/10, Loss: 0.13455245673656463\n",
            "Epoch 8/10, Loss: 0.13523976641893387\n",
            "Epoch 8/10, Loss: 0.13593030774593354\n",
            "Epoch 8/10, Loss: 0.13661893004179002\n",
            "Epoch 8/10, Loss: 0.13730498254299164\n",
            "Epoch 8/10, Loss: 0.13798554211854935\n",
            "Epoch 8/10, Loss: 0.1386674422621727\n",
            "Epoch 8/10, Loss: 0.1393630136847496\n",
            "Epoch 8/10, Loss: 0.14005808651447296\n",
            "Epoch 8/10, Loss: 0.1407465096116066\n",
            "Epoch 8/10, Loss: 0.14144095677137375\n",
            "Epoch 8/10, Loss: 0.14213886922597885\n",
            "Epoch 8/10, Loss: 0.14283039581775664\n",
            "Epoch 8/10, Loss: 0.14352216827869416\n",
            "Epoch 8/10, Loss: 0.14420574808120729\n",
            "Epoch 8/10, Loss: 0.14489786767959595\n",
            "Epoch 8/10, Loss: 0.14560136151313782\n",
            "Epoch 8/10, Loss: 0.14629308211803435\n",
            "Epoch 8/10, Loss: 0.14698097133636476\n",
            "Epoch 8/10, Loss: 0.14767562460899353\n",
            "Epoch 8/10, Loss: 0.14835880976915358\n",
            "Epoch 8/10, Loss: 0.14905484813451766\n",
            "Epoch 8/10, Loss: 0.14974068397283555\n",
            "Epoch 8/10, Loss: 0.15043107861280441\n",
            "Epoch 8/10, Loss: 0.15111192601919174\n",
            "Epoch 8/10, Loss: 0.15180744671821594\n",
            "Epoch 8/10, Loss: 0.15250584095716477\n",
            "Epoch 8/10, Loss: 0.1532017211318016\n",
            "Epoch 8/10, Loss: 0.15388557052612303\n",
            "Epoch 8/10, Loss: 0.15458087885379793\n",
            "Epoch 8/10, Loss: 0.15526584500074386\n",
            "Epoch 8/10, Loss: 0.1559518161416054\n",
            "Epoch 8/10, Loss: 0.15664208322763443\n",
            "Epoch 8/10, Loss: 0.15733267456293107\n",
            "Epoch 8/10, Loss: 0.15802009981870652\n",
            "Epoch 8/10, Loss: 0.15870774096250534\n",
            "Epoch 8/10, Loss: 0.1593936128616333\n",
            "Epoch 8/10, Loss: 0.160083202958107\n",
            "Epoch 8/10, Loss: 0.16078178399801255\n",
            "Epoch 8/10, Loss: 0.16147523307800293\n",
            "Epoch 8/10, Loss: 0.16216985416412352\n",
            "Epoch 8/10, Loss: 0.16286157989501954\n",
            "Epoch 8/10, Loss: 0.16355154633522034\n",
            "Epoch 8/10, Loss: 0.16423361510038376\n",
            "Epoch 8/10, Loss: 0.16491731530427933\n",
            "Epoch 8/10, Loss: 0.16561256039142608\n",
            "Epoch 8/10, Loss: 0.16630224537849425\n",
            "Epoch 8/10, Loss: 0.16700454187393188\n",
            "Epoch 8/10, Loss: 0.16769854879379273\n",
            "Epoch 8/10, Loss: 0.16839106559753417\n",
            "Epoch 8/10, Loss: 0.16908338284492494\n",
            "Epoch 8/10, Loss: 0.16976941788196565\n",
            "Epoch 8/10, Loss: 0.170461594581604\n",
            "Epoch 8/10, Loss: 0.17114271664619446\n",
            "Epoch 8/10, Loss: 0.17183516561985016\n",
            "Epoch 8/10, Loss: 0.17253198558092117\n",
            "Epoch 8/10, Loss: 0.17320603698492051\n",
            "Epoch 8/10, Loss: 0.17389732545614242\n",
            "Epoch 8/10, Loss: 0.17458811408281327\n",
            "Epoch 8/10, Loss: 0.17527703404426576\n",
            "Epoch 8/10, Loss: 0.17596999895572663\n",
            "Epoch 8/10, Loss: 0.1766685345172882\n",
            "Epoch 8/10, Loss: 0.17735434597730637\n",
            "Epoch 8/10, Loss: 0.17804423809051514\n",
            "Epoch 8/10, Loss: 0.17873842334747314\n",
            "Epoch 8/10, Loss: 0.17943156051635742\n",
            "Epoch 8/10, Loss: 0.18013032323122025\n",
            "Epoch 8/10, Loss: 0.1808143760561943\n",
            "Epoch 8/10, Loss: 0.1815037606358528\n",
            "Epoch 8/10, Loss: 0.18218963366746901\n",
            "Epoch 8/10, Loss: 0.18287598913908004\n",
            "Epoch 8/10, Loss: 0.18356135028600692\n",
            "Epoch 8/10, Loss: 0.1842677835226059\n",
            "Epoch 8/10, Loss: 0.18497537225484847\n",
            "Epoch 8/10, Loss: 0.18567747658491135\n",
            "Epoch 8/10, Loss: 0.18636736434698103\n",
            "Epoch 8/10, Loss: 0.18706854742765427\n",
            "Epoch 8/10, Loss: 0.18775866693258286\n",
            "Epoch 8/10, Loss: 0.18844264847040176\n",
            "Epoch 8/10, Loss: 0.18913284081220627\n",
            "Epoch 8/10, Loss: 0.18982092040777207\n",
            "Epoch 8/10, Loss: 0.19052594208717347\n",
            "Epoch 8/10, Loss: 0.19122544205188752\n",
            "Epoch 8/10, Loss: 0.1919103376865387\n",
            "Epoch 8/10, Loss: 0.19259126728773118\n",
            "Epoch 8/10, Loss: 0.1932941831946373\n",
            "Epoch 8/10, Loss: 0.193985397875309\n",
            "Epoch 8/10, Loss: 0.19467243832349776\n",
            "Epoch 8/10, Loss: 0.1953546149134636\n",
            "Epoch 8/10, Loss: 0.1960427103638649\n",
            "Epoch 8/10, Loss: 0.1967409957051277\n",
            "Epoch 8/10, Loss: 0.1974309538602829\n",
            "Epoch 8/10, Loss: 0.1981182730793953\n",
            "Epoch 8/10, Loss: 0.19880966943502426\n",
            "Epoch 8/10, Loss: 0.19949132645130158\n",
            "Epoch 8/10, Loss: 0.20018831527233125\n",
            "Epoch 8/10, Loss: 0.2008812382221222\n",
            "Epoch 8/10, Loss: 0.20157454150915147\n",
            "Epoch 8/10, Loss: 0.20225435906648637\n",
            "Epoch 8/10, Loss: 0.20295835465192794\n",
            "Epoch 8/10, Loss: 0.2036490357518196\n",
            "Epoch 8/10, Loss: 0.20435198932886123\n",
            "Epoch 8/10, Loss: 0.2050638576745987\n",
            "Epoch 8/10, Loss: 0.20575043153762818\n",
            "Epoch 8/10, Loss: 0.20643907606601716\n",
            "Epoch 8/10, Loss: 0.20713157731294632\n",
            "Epoch 8/10, Loss: 0.20782084703445436\n",
            "Epoch 8/10, Loss: 0.20850151646137238\n",
            "Epoch 8/10, Loss: 0.20920008146762847\n",
            "Epoch 8/10, Loss: 0.2098918460011482\n",
            "Epoch 8/10, Loss: 0.21058727568387986\n",
            "Epoch 8/10, Loss: 0.21128052544593812\n",
            "Epoch 8/10, Loss: 0.21196693670749664\n",
            "Epoch 8/10, Loss: 0.2126531562805176\n",
            "Epoch 8/10, Loss: 0.21333521580696105\n",
            "Epoch 8/10, Loss: 0.21402847695350646\n",
            "Epoch 8/10, Loss: 0.21472182285785674\n",
            "Epoch 8/10, Loss: 0.2154168807864189\n",
            "Epoch 8/10, Loss: 0.21610984683036805\n",
            "Epoch 8/10, Loss: 0.21679925793409346\n",
            "Epoch 8/10, Loss: 0.2174852736592293\n",
            "Epoch 8/10, Loss: 0.2181755902171135\n",
            "Epoch 8/10, Loss: 0.2188714761734009\n",
            "Epoch 8/10, Loss: 0.21955331289768218\n",
            "Epoch 8/10, Loss: 0.22024818843603133\n",
            "Epoch 8/10, Loss: 0.2209376954436302\n",
            "Epoch 8/10, Loss: 0.22162594455480575\n",
            "Epoch 8/10, Loss: 0.22231693124771118\n",
            "Epoch 8/10, Loss: 0.22300952041149139\n",
            "Epoch 8/10, Loss: 0.2236980892419815\n",
            "Epoch 8/10, Loss: 0.22439131569862367\n",
            "Epoch 8/10, Loss: 0.22507732403278352\n",
            "Epoch 8/10, Loss: 0.2257738891839981\n",
            "Epoch 8/10, Loss: 0.22646132469177246\n",
            "Epoch 8/10, Loss: 0.2271385509967804\n",
            "Epoch 8/10, Loss: 0.22783639401197434\n",
            "Epoch 8/10, Loss: 0.2285114021897316\n",
            "Epoch 8/10, Loss: 0.22920294785499573\n",
            "Epoch 8/10, Loss: 0.22989909482002258\n",
            "Epoch 8/10, Loss: 0.23058594965934753\n",
            "Epoch 8/10, Loss: 0.23127533888816834\n",
            "Epoch 8/10, Loss: 0.23195244550704955\n",
            "Epoch 8/10, Loss: 0.2326397248506546\n",
            "Epoch 8/10, Loss: 0.23333795887231826\n",
            "Epoch 8/10, Loss: 0.23403316730260848\n",
            "Epoch 8/10, Loss: 0.23471678560972215\n",
            "Epoch 8/10, Loss: 0.23539916855096818\n",
            "Epoch 8/10, Loss: 0.23609302991628647\n",
            "Epoch 8/10, Loss: 0.2367872204184532\n",
            "Epoch 8/10, Loss: 0.2374872812628746\n",
            "Epoch 8/10, Loss: 0.2381863896250725\n",
            "Epoch 8/10, Loss: 0.23888520616292955\n",
            "Epoch 8/10, Loss: 0.2395696895122528\n",
            "Epoch 8/10, Loss: 0.24026005882024765\n",
            "Epoch 8/10, Loss: 0.24095508033037186\n",
            "Epoch 8/10, Loss: 0.24164755314588546\n",
            "Epoch 8/10, Loss: 0.2423484103679657\n",
            "Epoch 8/10, Loss: 0.24304806196689605\n",
            "Epoch 8/10, Loss: 0.24374111926555633\n",
            "Epoch 8/10, Loss: 0.24443882238864897\n",
            "Epoch 8/10, Loss: 0.245122047662735\n",
            "Epoch 8/10, Loss: 0.2458165409564972\n",
            "Epoch 8/10, Loss: 0.24649697816371918\n",
            "Epoch 8/10, Loss: 0.2471902188062668\n",
            "Epoch 8/10, Loss: 0.24787591010332108\n",
            "Epoch 8/10, Loss: 0.24856030756235123\n",
            "Epoch 8/10, Loss: 0.2492673841714859\n",
            "Epoch 8/10, Loss: 0.24995795679092409\n",
            "Epoch 8/10, Loss: 0.2506533260345459\n",
            "Epoch 8/10, Loss: 0.2513451289534569\n",
            "Epoch 8/10, Loss: 0.2520333150625229\n",
            "Epoch 8/10, Loss: 0.2527123376131058\n",
            "Epoch 8/10, Loss: 0.2533963681459427\n",
            "Epoch 8/10, Loss: 0.25408154910802844\n",
            "Epoch 8/10, Loss: 0.2547701689004898\n",
            "Epoch 8/10, Loss: 0.25546264147758485\n",
            "Epoch 8/10, Loss: 0.25614938569068907\n",
            "Epoch 8/10, Loss: 0.2568402861356735\n",
            "Epoch 8/10, Loss: 0.2575339894890785\n",
            "Epoch 8/10, Loss: 0.25822665137052536\n",
            "Epoch 8/10, Loss: 0.25892910891771315\n",
            "Epoch 8/10, Loss: 0.25961947882175446\n",
            "Epoch 8/10, Loss: 0.2603105506896973\n",
            "Epoch 8/10, Loss: 0.26100488638877867\n",
            "Epoch 8/10, Loss: 0.2617013319730759\n",
            "Epoch 8/10, Loss: 0.26239139688014984\n",
            "Epoch 8/10, Loss: 0.2630839844942093\n",
            "Epoch 8/10, Loss: 0.26377358436584475\n",
            "Epoch 8/10, Loss: 0.26446474993228913\n",
            "Epoch 8/10, Loss: 0.2651696909070015\n",
            "Epoch 8/10, Loss: 0.26585672199726107\n",
            "Epoch 8/10, Loss: 0.2665537610650063\n",
            "Epoch 8/10, Loss: 0.26725172501802447\n",
            "Epoch 8/10, Loss: 0.2679314829111099\n",
            "Epoch 8/10, Loss: 0.2686132608056068\n",
            "Epoch 8/10, Loss: 0.26930009776353836\n",
            "Epoch 8/10, Loss: 0.2699955823421478\n",
            "Epoch 8/10, Loss: 0.27068995463848117\n",
            "Epoch 8/10, Loss: 0.27137994694709777\n",
            "Epoch 8/10, Loss: 0.2720573312044144\n",
            "Epoch 8/10, Loss: 0.27274841940402983\n",
            "Epoch 8/10, Loss: 0.27343391615152357\n",
            "Epoch 8/10, Loss: 0.27413489180803297\n",
            "Epoch 8/10, Loss: 0.27482085996866223\n",
            "Epoch 8/10, Loss: 0.27551423126459124\n",
            "Epoch 8/10, Loss: 0.27620135360956194\n",
            "Epoch 8/10, Loss: 0.2769006588459015\n",
            "Epoch 8/10, Loss: 0.27758472406864165\n",
            "Epoch 8/10, Loss: 0.27827510732412336\n",
            "Epoch 8/10, Loss: 0.2789603397846222\n",
            "Epoch 8/10, Loss: 0.27965870654582975\n",
            "Epoch 8/10, Loss: 0.28033826303482057\n",
            "Epoch 8/10, Loss: 0.28103003865480425\n",
            "Epoch 8/10, Loss: 0.2817260967493057\n",
            "Epoch 8/10, Loss: 0.2824226830601692\n",
            "Epoch 8/10, Loss: 0.2830951427221298\n",
            "Epoch 8/10, Loss: 0.2837917331457138\n",
            "Epoch 8/10, Loss: 0.28448509353399276\n",
            "Epoch 8/10, Loss: 0.2851642380952835\n",
            "Epoch 8/10, Loss: 0.28585201877355576\n",
            "Epoch 8/10, Loss: 0.28654714179039004\n",
            "Epoch 8/10, Loss: 0.2872370774149895\n",
            "Epoch 8/10, Loss: 0.2879273045063019\n",
            "Epoch 8/10, Loss: 0.28861049890518187\n",
            "Epoch 8/10, Loss: 0.2893064652681351\n",
            "Epoch 8/10, Loss: 0.28999577939510346\n",
            "Epoch 8/10, Loss: 0.2906832062005997\n",
            "Epoch 8/10, Loss: 0.2913666099309921\n",
            "Epoch 8/10, Loss: 0.2920654318928719\n",
            "Epoch 8/10, Loss: 0.29275083005428315\n",
            "Epoch 8/10, Loss: 0.2934457139968872\n",
            "Epoch 8/10, Loss: 0.29414032274484636\n",
            "Epoch 8/10, Loss: 0.29482563894987107\n",
            "Epoch 8/10, Loss: 0.29551383101940154\n",
            "Epoch 8/10, Loss: 0.2961932836174965\n",
            "Epoch 8/10, Loss: 0.29688702100515363\n",
            "Epoch 8/10, Loss: 0.29757357233762743\n",
            "Epoch 8/10, Loss: 0.2982570621967316\n",
            "Epoch 8/10, Loss: 0.298938410282135\n",
            "Epoch 8/10, Loss: 0.2996310343146324\n",
            "Epoch 8/10, Loss: 0.30032112276554107\n",
            "Epoch 8/10, Loss: 0.30100713288784026\n",
            "Epoch 8/10, Loss: 0.3016942890882492\n",
            "Epoch 8/10, Loss: 0.30238727658987047\n",
            "Epoch 8/10, Loss: 0.3030736326575279\n",
            "Epoch 8/10, Loss: 0.3037636508345604\n",
            "Epoch 8/10, Loss: 0.3044502905011177\n",
            "Epoch 8/10, Loss: 0.305135643184185\n",
            "Epoch 8/10, Loss: 0.30581557339429855\n",
            "Epoch 8/10, Loss: 0.30650344705581667\n",
            "Epoch 8/10, Loss: 0.30719955027103424\n",
            "Epoch 8/10, Loss: 0.3078792221546173\n",
            "Epoch 8/10, Loss: 0.30855965399742125\n",
            "Epoch 8/10, Loss: 0.30925357443094253\n",
            "Epoch 8/10, Loss: 0.3099384831190109\n",
            "Epoch 8/10, Loss: 0.3106204885840416\n",
            "Epoch 8/10, Loss: 0.31130677205324175\n",
            "Epoch 8/10, Loss: 0.3119986483454704\n",
            "Epoch 8/10, Loss: 0.3126952536702156\n",
            "Epoch 8/10, Loss: 0.3133941738009453\n",
            "Epoch 8/10, Loss: 0.314102060854435\n",
            "Epoch 8/10, Loss: 0.31478121829032896\n",
            "Epoch 8/10, Loss: 0.31546600663661956\n",
            "Epoch 8/10, Loss: 0.31614774858951566\n",
            "Epoch 8/10, Loss: 0.31683337420225144\n",
            "Epoch 8/10, Loss: 0.31752661567926405\n",
            "Epoch 8/10, Loss: 0.3182196288704872\n",
            "Epoch 8/10, Loss: 0.3189033586382866\n",
            "Epoch 8/10, Loss: 0.3196019974946976\n",
            "Epoch 8/10, Loss: 0.3202953289151192\n",
            "Epoch 8/10, Loss: 0.32099017816782\n",
            "Epoch 8/10, Loss: 0.3216842168569565\n",
            "Epoch 8/10, Loss: 0.32238707369565966\n",
            "Epoch 8/10, Loss: 0.3230648036599159\n",
            "Epoch 8/10, Loss: 0.323749803006649\n",
            "Epoch 8/10, Loss: 0.32443173974752426\n",
            "Epoch 8/10, Loss: 0.3251086694598198\n",
            "Epoch 8/10, Loss: 0.32580894511938097\n",
            "Epoch 8/10, Loss: 0.3265102564096451\n",
            "Epoch 8/10, Loss: 0.3271900094151497\n",
            "Epoch 8/10, Loss: 0.3278864921331406\n",
            "Epoch 8/10, Loss: 0.32856930458545686\n",
            "Epoch 8/10, Loss: 0.3292600277662277\n",
            "Epoch 8/10, Loss: 0.3299532356262207\n",
            "Epoch 8/10, Loss: 0.3306616385579109\n",
            "Epoch 8/10, Loss: 0.3313557888865471\n",
            "Epoch 8/10, Loss: 0.33204013562202456\n",
            "Epoch 8/10, Loss: 0.33273914432525636\n",
            "Epoch 8/10, Loss: 0.33344534754753113\n",
            "Epoch 8/10, Loss: 0.33413065046072005\n",
            "Epoch 8/10, Loss: 0.3348167921304703\n",
            "Epoch 8/10, Loss: 0.3355086177587509\n",
            "Epoch 8/10, Loss: 0.3362068213820458\n",
            "Epoch 8/10, Loss: 0.3368915398716927\n",
            "Epoch 8/10, Loss: 0.33758655095100404\n",
            "Epoch 8/10, Loss: 0.33827963465452193\n",
            "Epoch 8/10, Loss: 0.33896988558769225\n",
            "Epoch 8/10, Loss: 0.33965384238958357\n",
            "Epoch 8/10, Loss: 0.3403449156880379\n",
            "Epoch 8/10, Loss: 0.34104921466112137\n",
            "Epoch 8/10, Loss: 0.3417353357672691\n",
            "Epoch 8/10, Loss: 0.342425678730011\n",
            "Epoch 8/10, Loss: 0.34312942922115325\n",
            "Epoch 8/10, Loss: 0.3438319704532623\n",
            "Epoch 8/10, Loss: 0.3445222786068916\n",
            "Epoch 8/10, Loss: 0.34520873308181765\n",
            "Epoch 8/10, Loss: 0.3459021365046501\n",
            "Epoch 8/10, Loss: 0.3465901633501053\n",
            "Epoch 8/10, Loss: 0.34729345196485517\n",
            "Epoch 8/10, Loss: 0.3479803609251976\n",
            "Epoch 8/10, Loss: 0.34867319524288176\n",
            "Epoch 8/10, Loss: 0.34936218667030333\n",
            "Epoch 8/10, Loss: 0.35006227052211764\n",
            "Epoch 8/10, Loss: 0.3507464072704315\n",
            "Epoch 8/10, Loss: 0.3514356292486191\n",
            "Epoch 8/10, Loss: 0.3521293690800667\n",
            "Epoch 8/10, Loss: 0.35283116275072096\n",
            "Epoch 8/10, Loss: 0.35352525413036345\n",
            "Epoch 8/10, Loss: 0.3542139072418213\n",
            "Epoch 8/10, Loss: 0.3549015032052994\n",
            "Epoch 8/10, Loss: 0.35559573519229887\n",
            "Epoch 8/10, Loss: 0.35628957039117815\n",
            "Epoch 8/10, Loss: 0.35698733907938\n",
            "Epoch 8/10, Loss: 0.3576795216202736\n",
            "Epoch 8/10, Loss: 0.3583765818476677\n",
            "Epoch 8/10, Loss: 0.35906651359796526\n",
            "Epoch 8/10, Loss: 0.3597512490153313\n",
            "Epoch 8/10, Loss: 0.36044233268499376\n",
            "Epoch 8/10, Loss: 0.3611269163489342\n",
            "Epoch 8/10, Loss: 0.36182066082954406\n",
            "Epoch 8/10, Loss: 0.3625049624443054\n",
            "Epoch 8/10, Loss: 0.36320913392305376\n",
            "Epoch 8/10, Loss: 0.36390702879428866\n",
            "Epoch 8/10, Loss: 0.364592368721962\n",
            "Epoch 8/10, Loss: 0.3652702666521072\n",
            "Epoch 8/10, Loss: 0.3659646872282028\n",
            "Epoch 8/10, Loss: 0.3666542336344719\n",
            "Epoch 8/10, Loss: 0.36734487068653104\n",
            "Epoch 8/10, Loss: 0.36804532051086425\n",
            "Epoch 8/10, Loss: 0.36873732149600985\n",
            "Epoch 8/10, Loss: 0.3694272823929787\n",
            "Epoch 8/10, Loss: 0.3701270290017128\n",
            "Epoch 8/10, Loss: 0.3708167816996574\n",
            "Epoch 8/10, Loss: 0.37151220148801806\n",
            "Epoch 8/10, Loss: 0.37220468288660047\n",
            "Epoch 8/10, Loss: 0.37289756405353547\n",
            "Epoch 8/10, Loss: 0.3735900440812111\n",
            "Epoch 8/10, Loss: 0.3742683355212212\n",
            "Epoch 8/10, Loss: 0.37495194548368455\n",
            "Epoch 8/10, Loss: 0.3756409695744514\n",
            "Epoch 8/10, Loss: 0.3763238778114319\n",
            "Epoch 8/10, Loss: 0.37700849390029906\n",
            "Epoch 8/10, Loss: 0.3776973136663437\n",
            "Epoch 8/10, Loss: 0.3783836168050766\n",
            "Epoch 8/10, Loss: 0.3790781602859497\n",
            "Epoch 8/10, Loss: 0.37977182018756866\n",
            "Epoch 8/10, Loss: 0.38046004605293277\n",
            "Epoch 8/10, Loss: 0.3811514550447464\n",
            "Epoch 8/10, Loss: 0.38184417897462847\n",
            "Epoch 8/10, Loss: 0.3825276452898979\n",
            "Epoch 8/10, Loss: 0.3832173457741737\n",
            "Epoch 8/10, Loss: 0.3838995037078857\n",
            "Epoch 8/10, Loss: 0.3845941134095192\n",
            "Epoch 8/10, Loss: 0.38527645021677015\n",
            "Epoch 8/10, Loss: 0.3859712124466896\n",
            "Epoch 8/10, Loss: 0.38666415357589723\n",
            "Epoch 8/10, Loss: 0.38736407697200775\n",
            "Epoch 8/10, Loss: 0.388047749042511\n",
            "Epoch 8/10, Loss: 0.3887335988283157\n",
            "Epoch 8/10, Loss: 0.3894242534637451\n",
            "Epoch 8/10, Loss: 0.3901143773794174\n",
            "Epoch 8/10, Loss: 0.39080225211381914\n",
            "Epoch 8/10, Loss: 0.3914981279969215\n",
            "Epoch 8/10, Loss: 0.3921923375725746\n",
            "Epoch 8/10, Loss: 0.39288305133581164\n",
            "Epoch 8/10, Loss: 0.39357422083616256\n",
            "Epoch 8/10, Loss: 0.3942507761120796\n",
            "Epoch 8/10, Loss: 0.39495273023843763\n",
            "Epoch 8/10, Loss: 0.3956262123584747\n",
            "Epoch 8/10, Loss: 0.39631485724449156\n",
            "Epoch 8/10, Loss: 0.39700063186883927\n",
            "Epoch 8/10, Loss: 0.39769506198167803\n",
            "Epoch 8/10, Loss: 0.39839013439416887\n",
            "Epoch 8/10, Loss: 0.39909095668792727\n",
            "Epoch 8/10, Loss: 0.3997849282622337\n",
            "Epoch 8/10, Loss: 0.40046615338325503\n",
            "Epoch 8/10, Loss: 0.40115083026885984\n",
            "Epoch 8/10, Loss: 0.4018443424701691\n",
            "Epoch 8/10, Loss: 0.40254063087701797\n",
            "Epoch 8/10, Loss: 0.4032215117812157\n",
            "Epoch 8/10, Loss: 0.40392019045352934\n",
            "Epoch 8/10, Loss: 0.4045997711420059\n",
            "Epoch 8/10, Loss: 0.40528743743896484\n",
            "Epoch 8/10, Loss: 0.40597866410017014\n",
            "Epoch 8/10, Loss: 0.40666988533735277\n",
            "Epoch 8/10, Loss: 0.4073651630878449\n",
            "Epoch 8/10, Loss: 0.40805525320768354\n",
            "Epoch 8/10, Loss: 0.40874335730075834\n",
            "Epoch 8/10, Loss: 0.4094339562058449\n",
            "Epoch 8/10, Loss: 0.41013018232584\n",
            "Epoch 8/10, Loss: 0.41082803475856783\n",
            "Epoch 8/10, Loss: 0.41152713227272036\n",
            "Epoch 8/10, Loss: 0.41221796721220016\n",
            "Epoch 8/10, Loss: 0.4129090391993523\n",
            "Epoch 8/10, Loss: 0.4135939077734947\n",
            "Epoch 8/10, Loss: 0.41427723586559295\n",
            "Epoch 8/10, Loss: 0.41496899795532227\n",
            "Epoch 8/10, Loss: 0.4156622540950775\n",
            "Epoch 8/10, Loss: 0.4163475923538208\n",
            "Epoch 8/10, Loss: 0.4170466878414154\n",
            "Epoch 8/10, Loss: 0.41774074506759645\n",
            "Epoch 8/10, Loss: 0.4184393781423569\n",
            "Epoch 8/10, Loss: 0.41913099139928817\n",
            "Epoch 8/10, Loss: 0.41981562274694445\n",
            "Epoch 8/10, Loss: 0.420504658639431\n",
            "Epoch 8/10, Loss: 0.4212003858089447\n",
            "Epoch 8/10, Loss: 0.42189977890253066\n",
            "Epoch 8/10, Loss: 0.42258534997701647\n",
            "Epoch 8/10, Loss: 0.42328157740831374\n",
            "Epoch 8/10, Loss: 0.4239545978307724\n",
            "Epoch 8/10, Loss: 0.42464844858646394\n",
            "Epoch 8/10, Loss: 0.42534017997980117\n",
            "Epoch 8/10, Loss: 0.42603737753629684\n",
            "Epoch 8/10, Loss: 0.42672795814275744\n",
            "Epoch 8/10, Loss: 0.4274070267081261\n",
            "Epoch 8/10, Loss: 0.4280972552895546\n",
            "Epoch 8/10, Loss: 0.4287850152850151\n",
            "Epoch 8/10, Loss: 0.42947467267513273\n",
            "Epoch 8/10, Loss: 0.4301739196777344\n",
            "Epoch 8/10, Loss: 0.43086305713653567\n",
            "Epoch 8/10, Loss: 0.431548499584198\n",
            "Epoch 8/10, Loss: 0.43223739516735077\n",
            "Epoch 8/10, Loss: 0.4329325221180916\n",
            "Epoch 8/10, Loss: 0.43363349640369414\n",
            "Epoch 8/10, Loss: 0.4343163189888001\n",
            "Epoch 8/10, Loss: 0.43501721864938736\n",
            "Epoch 8/10, Loss: 0.435704430937767\n",
            "Epoch 8/10, Loss: 0.4363868193626404\n",
            "Epoch 8/10, Loss: 0.4370913525223732\n",
            "Epoch 8/10, Loss: 0.43778580737113953\n",
            "Epoch 8/10, Loss: 0.43847998082637785\n",
            "Epoch 8/10, Loss: 0.4391647231578827\n",
            "Epoch 8/10, Loss: 0.439864262342453\n",
            "Epoch 8/10, Loss: 0.4405667333602905\n",
            "Epoch 8/10, Loss: 0.4412569585442543\n",
            "Epoch 8/10, Loss: 0.4419444757699966\n",
            "Epoch 8/10, Loss: 0.4426319317817688\n",
            "Epoch 8/10, Loss: 0.44332021701335905\n",
            "Epoch 8/10, Loss: 0.44400576722621915\n",
            "Epoch 8/10, Loss: 0.4447023551464081\n",
            "Epoch 8/10, Loss: 0.4453905996084213\n",
            "Epoch 8/10, Loss: 0.44607369393110274\n",
            "Epoch 8/10, Loss: 0.44675857919454576\n",
            "Epoch 8/10, Loss: 0.44744660794734953\n",
            "Epoch 8/10, Loss: 0.4481323844194412\n",
            "Epoch 8/10, Loss: 0.4488185912370682\n",
            "Epoch 8/10, Loss: 0.44951299667358396\n",
            "Epoch 8/10, Loss: 0.450223260641098\n",
            "Epoch 8/10, Loss: 0.450916756272316\n",
            "Epoch 8/10, Loss: 0.4516154163479805\n",
            "Epoch 8/10, Loss: 0.45231215089559557\n",
            "Epoch 8/10, Loss: 0.4530028237104416\n",
            "Epoch 8/10, Loss: 0.45369607090950015\n",
            "Epoch 8/10, Loss: 0.454386808514595\n",
            "Epoch 8/10, Loss: 0.45507947671413423\n",
            "Epoch 8/10, Loss: 0.4557771381735802\n",
            "Epoch 8/10, Loss: 0.45646564370393755\n",
            "Epoch 8/10, Loss: 0.45715433251857757\n",
            "Epoch 8/10, Loss: 0.45783135485649107\n",
            "Epoch 8/10, Loss: 0.45851953434944154\n",
            "Epoch 8/10, Loss: 0.45921933311223984\n",
            "Epoch 8/10, Loss: 0.4599068362116814\n",
            "Epoch 8/10, Loss: 0.4605965449213982\n",
            "Epoch 8/10, Loss: 0.46129371160268784\n",
            "Epoch 8/10, Loss: 0.4619791339635849\n",
            "Epoch 8/10, Loss: 0.4626588550209999\n",
            "Epoch 8/10, Loss: 0.46333887350559233\n",
            "Epoch 8/10, Loss: 0.464028451025486\n",
            "Epoch 8/10, Loss: 0.4647158043980598\n",
            "Epoch 8/10, Loss: 0.46540596294403075\n",
            "Epoch 8/10, Loss: 0.4660872046947479\n",
            "Epoch 8/10, Loss: 0.46678548806905745\n",
            "Epoch 8/10, Loss: 0.4674721204638481\n",
            "Epoch 8/10, Loss: 0.4681702010035515\n",
            "Epoch 8/10, Loss: 0.46887035632133484\n",
            "Epoch 8/10, Loss: 0.46956378263235093\n",
            "Epoch 8/10, Loss: 0.4702686170935631\n",
            "Epoch 8/10, Loss: 0.47096119832992556\n",
            "Epoch 8/10, Loss: 0.47164956796169283\n",
            "Epoch 8/10, Loss: 0.4723472170829773\n",
            "Epoch 8/10, Loss: 0.4730486019849777\n",
            "Epoch 8/10, Loss: 0.4737502552270889\n",
            "Epoch 8/10, Loss: 0.4744403883218765\n",
            "Epoch 8/10, Loss: 0.4751304497718811\n",
            "Epoch 8/10, Loss: 0.475818064391613\n",
            "Epoch 8/10, Loss: 0.4765122702717781\n",
            "Epoch 8/10, Loss: 0.4772114112973213\n",
            "Epoch 8/10, Loss: 0.4779031350016594\n",
            "Epoch 8/10, Loss: 0.4785907566547394\n",
            "Epoch 8/10, Loss: 0.47927682793140414\n",
            "Epoch 8/10, Loss: 0.47996611666679384\n",
            "Epoch 8/10, Loss: 0.4806527243852615\n",
            "Epoch 8/10, Loss: 0.4813434152007103\n",
            "Epoch 8/10, Loss: 0.48203600507974625\n",
            "Epoch 8/10, Loss: 0.4827225291132927\n",
            "Epoch 8/10, Loss: 0.4834170963168144\n",
            "Epoch 8/10, Loss: 0.4841118239760399\n",
            "Epoch 8/10, Loss: 0.48480799978971484\n",
            "Epoch 8/10, Loss: 0.4855008057951927\n",
            "Epoch 8/10, Loss: 0.4861902689933777\n",
            "Epoch 8/10, Loss: 0.4868837317228317\n",
            "Epoch 8/10, Loss: 0.4875689529180527\n",
            "Epoch 8/10, Loss: 0.48825283026695254\n",
            "Epoch 8/10, Loss: 0.4889397747516632\n",
            "Epoch 8/10, Loss: 0.4896434328556061\n",
            "Epoch 8/10, Loss: 0.49033470046520233\n",
            "Epoch 8/10, Loss: 0.4910195097923279\n",
            "Epoch 8/10, Loss: 0.49170775556564333\n",
            "Epoch 8/10, Loss: 0.49239968407154083\n",
            "Epoch 8/10, Loss: 0.49309066784381866\n",
            "Epoch 8/10, Loss: 0.4937647891640663\n",
            "Epoch 8/10, Loss: 0.4944586289525032\n",
            "Epoch 8/10, Loss: 0.49515807563066483\n",
            "Epoch 8/10, Loss: 0.4958516809940338\n",
            "Epoch 8/10, Loss: 0.4965424054861069\n",
            "Epoch 8/10, Loss: 0.49722645825147627\n",
            "Epoch 8/10, Loss: 0.4979276599884033\n",
            "Epoch 8/10, Loss: 0.4986157401800156\n",
            "Epoch 8/10, Loss: 0.4993077174425125\n",
            "Epoch 8/10, Loss: 0.5000032341480255\n",
            "Epoch 8/10, Loss: 0.5007011664509773\n",
            "Epoch 8/10, Loss: 0.5013901320695877\n",
            "Epoch 8/10, Loss: 0.502086985051632\n",
            "Epoch 8/10, Loss: 0.5027738702297211\n",
            "Epoch 8/10, Loss: 0.5034674475193024\n",
            "Epoch 8/10, Loss: 0.504167175590992\n",
            "Epoch 8/10, Loss: 0.5048687523007392\n",
            "Epoch 8/10, Loss: 0.5055669494271279\n",
            "Epoch 8/10, Loss: 0.5062599733471871\n",
            "Epoch 8/10, Loss: 0.5069526019692421\n",
            "Epoch 8/10, Loss: 0.5076336082816124\n",
            "Epoch 8/10, Loss: 0.5083139517307281\n",
            "Epoch 8/10, Loss: 0.5090025782585144\n",
            "Epoch 8/10, Loss: 0.5096954267024993\n",
            "Epoch 8/10, Loss: 0.5103961036205292\n",
            "Epoch 8/10, Loss: 0.5110880144238472\n",
            "Epoch 8/10, Loss: 0.51177264970541\n",
            "Epoch 8/10, Loss: 0.5124504831433296\n",
            "Epoch 8/10, Loss: 0.5131404982209206\n",
            "Epoch 8/10, Loss: 0.5138369863629341\n",
            "Epoch 8/10, Loss: 0.5145267827510833\n",
            "Epoch 8/10, Loss: 0.5152163965702057\n",
            "Epoch 8/10, Loss: 0.5159024649262428\n",
            "Epoch 8/10, Loss: 0.5166027514338494\n",
            "Epoch 8/10, Loss: 0.5172837252020835\n",
            "Epoch 8/10, Loss: 0.5179778916239739\n",
            "Epoch 8/10, Loss: 0.5186804392337799\n",
            "Epoch 8/10, Loss: 0.5193620139360428\n",
            "Epoch 8/10, Loss: 0.5200514342784882\n",
            "Epoch 8/10, Loss: 0.5207390265464783\n",
            "Epoch 8/10, Loss: 0.5214303370118141\n",
            "Epoch 8/10, Loss: 0.522124461889267\n",
            "Epoch 8/10, Loss: 0.5228107461929321\n",
            "Epoch 8/10, Loss: 0.5235114951729775\n",
            "Epoch 8/10, Loss: 0.5242018076777458\n",
            "Epoch 8/10, Loss: 0.5248920899629593\n",
            "Epoch 8/10, Loss: 0.5255883029699325\n",
            "Epoch 8/10, Loss: 0.5262833114266395\n",
            "Epoch 8/10, Loss: 0.5269694300889969\n",
            "Epoch 8/10, Loss: 0.5276588792204857\n",
            "Epoch 8/10, Loss: 0.5283440837264061\n",
            "Epoch 8/10, Loss: 0.5290295031666755\n",
            "Epoch 8/10, Loss: 0.5297284399867058\n",
            "Epoch 8/10, Loss: 0.5304213557243347\n",
            "Epoch 8/10, Loss: 0.5311028745770454\n",
            "Epoch 8/10, Loss: 0.5317932364344596\n",
            "Epoch 8/10, Loss: 0.5324885090589523\n",
            "Epoch 8/10, Loss: 0.533186052262783\n",
            "Epoch 8/10, Loss: 0.5338808939456939\n",
            "Epoch 8/10, Loss: 0.534584725022316\n",
            "Epoch 8/10, Loss: 0.5352718287706375\n",
            "Epoch 8/10, Loss: 0.535964514374733\n",
            "Epoch 8/10, Loss: 0.536655700981617\n",
            "Epoch 8/10, Loss: 0.5373602589964867\n",
            "Epoch 8/10, Loss: 0.5380498808026314\n",
            "Epoch 8/10, Loss: 0.5387496315836906\n",
            "Epoch 8/10, Loss: 0.5394396872520447\n",
            "Epoch 8/10, Loss: 0.5401179827451706\n",
            "Epoch 8/10, Loss: 0.5408078591823577\n",
            "Epoch 8/10, Loss: 0.5414934412240983\n",
            "Epoch 8/10, Loss: 0.5421724479198455\n",
            "Epoch 8/10, Loss: 0.5428590527772903\n",
            "Epoch 8/10, Loss: 0.5435398818254471\n",
            "Epoch 8/10, Loss: 0.5442275820970536\n",
            "Epoch 8/10, Loss: 0.5449107658267022\n",
            "Epoch 8/10, Loss: 0.5455948120951652\n",
            "Epoch 8/10, Loss: 0.5462745987772941\n",
            "Epoch 8/10, Loss: 0.5469584473967553\n",
            "Epoch 8/10, Loss: 0.5476473345756531\n",
            "Epoch 8/10, Loss: 0.5483433582782745\n",
            "Epoch 8/10, Loss: 0.549027726650238\n",
            "Epoch 8/10, Loss: 0.549707859814167\n",
            "Epoch 8/10, Loss: 0.5503970876336097\n",
            "Epoch 8/10, Loss: 0.5510733734369277\n",
            "Epoch 8/10, Loss: 0.5517736991643906\n",
            "Epoch 8/10, Loss: 0.5524619134664536\n",
            "Epoch 8/10, Loss: 0.5531487039327622\n",
            "Epoch 8/10, Loss: 0.5538478251099587\n",
            "Epoch 8/10, Loss: 0.5545271845459938\n",
            "Epoch 8/10, Loss: 0.5552225383520126\n",
            "Epoch 8/10, Loss: 0.5559164914488792\n",
            "Epoch 8/10, Loss: 0.5566037511229515\n",
            "Epoch 8/10, Loss: 0.5572937821745872\n",
            "Epoch 8/10, Loss: 0.5579820597171783\n",
            "Epoch 8/10, Loss: 0.5586658915281296\n",
            "Epoch 8/10, Loss: 0.5593716380000114\n",
            "Epoch 8/10, Loss: 0.5600624923706055\n",
            "Epoch 8/10, Loss: 0.5607552357316017\n",
            "Epoch 8/10, Loss: 0.5614465588331222\n",
            "Epoch 8/10, Loss: 0.5621423032283783\n",
            "Epoch 8/10, Loss: 0.5628365711569786\n",
            "Epoch 8/10, Loss: 0.5635252898335457\n",
            "Epoch 8/10, Loss: 0.564196135699749\n",
            "Epoch 8/10, Loss: 0.5649001260399819\n",
            "Epoch 8/10, Loss: 0.565600043118\n",
            "Epoch 8/10, Loss: 0.5662853184342385\n",
            "Epoch 8/10, Loss: 0.5669777585268021\n",
            "Epoch 8/10, Loss: 0.5676679593324662\n",
            "Epoch 8/10, Loss: 0.5683506719470024\n",
            "Epoch 8/10, Loss: 0.5690320584774017\n",
            "Epoch 8/10, Loss: 0.5697208099961281\n",
            "Epoch 8/10, Loss: 0.5704098141789437\n",
            "Epoch 8/10, Loss: 0.5710998422503472\n",
            "Epoch 8/10, Loss: 0.5717864839434623\n",
            "Epoch 8/10, Loss: 0.5724735165834427\n",
            "Epoch 8/10, Loss: 0.5731688287854194\n",
            "Epoch 8/10, Loss: 0.573857771217823\n",
            "Epoch 8/10, Loss: 0.5745514692664146\n",
            "Epoch 8/10, Loss: 0.575238016963005\n",
            "Epoch 8/10, Loss: 0.5759322410821914\n",
            "Epoch 8/10, Loss: 0.5766187098622322\n",
            "Epoch 8/10, Loss: 0.5773169875741005\n",
            "Epoch 8/10, Loss: 0.5780037783384323\n",
            "Epoch 8/10, Loss: 0.5786965761184693\n",
            "Epoch 8/10, Loss: 0.579382963836193\n",
            "Epoch 8/10, Loss: 0.5800818149447441\n",
            "Epoch 8/10, Loss: 0.5807734205722809\n",
            "Epoch 8/10, Loss: 0.5814652763605118\n",
            "Epoch 8/10, Loss: 0.582153221130371\n",
            "Epoch 8/10, Loss: 0.5828340179920196\n",
            "Epoch 8/10, Loss: 0.5835098761916161\n",
            "Epoch 8/10, Loss: 0.5842120583057404\n",
            "Epoch 8/10, Loss: 0.5849065915346146\n",
            "Epoch 8/10, Loss: 0.5856084549427032\n",
            "Epoch 8/10, Loss: 0.5863013767004013\n",
            "Epoch 8/10, Loss: 0.5869845373034477\n",
            "Epoch 8/10, Loss: 0.5876782995462417\n",
            "Epoch 8/10, Loss: 0.5883695349693299\n",
            "Epoch 8/10, Loss: 0.5890617083907127\n",
            "Epoch 8/10, Loss: 0.5897506024837494\n",
            "Epoch 8/10, Loss: 0.590424598813057\n",
            "Epoch 8/10, Loss: 0.5911104900240898\n",
            "Epoch 8/10, Loss: 0.5918005205988884\n",
            "Epoch 8/10, Loss: 0.5924783989191055\n",
            "Epoch 8/10, Loss: 0.5931636352539063\n",
            "Epoch 8/10, Loss: 0.5938411585092545\n",
            "Epoch 8/10, Loss: 0.5945226508378982\n",
            "Epoch 8/10, Loss: 0.5952132040858269\n",
            "Epoch 8/10, Loss: 0.5959137334227562\n",
            "Epoch 8/10, Loss: 0.5965943502783775\n",
            "Epoch 8/10, Loss: 0.5972849385142326\n",
            "Epoch 8/10, Loss: 0.5979651221632958\n",
            "Epoch 8/10, Loss: 0.5986474214792251\n",
            "Epoch 8/10, Loss: 0.5993426294326782\n",
            "Epoch 8/10, Loss: 0.6000409889221191\n",
            "Epoch 8/10, Loss: 0.6007412995100021\n",
            "Epoch 8/10, Loss: 0.6014287894964219\n",
            "Epoch 8/10, Loss: 0.6021111370325088\n",
            "Epoch 8/10, Loss: 0.6028070989251136\n",
            "Epoch 8/10, Loss: 0.6034970953464508\n",
            "Epoch 8/10, Loss: 0.6041895517110825\n",
            "Epoch 8/10, Loss: 0.6048776572942733\n",
            "Epoch 8/10, Loss: 0.6055596897602081\n",
            "Epoch 8/10, Loss: 0.6062495337128639\n",
            "Epoch 8/10, Loss: 0.6069336097836494\n",
            "Epoch 8/10, Loss: 0.6076149156689644\n",
            "Epoch 8/10, Loss: 0.6083095385432243\n",
            "Epoch 8/10, Loss: 0.6089995861649513\n",
            "Epoch 8/10, Loss: 0.6096913470625878\n",
            "Epoch 8/10, Loss: 0.6103849897384643\n",
            "Epoch 8/10, Loss: 0.6110723161697388\n",
            "Epoch 8/10, Loss: 0.611759173154831\n",
            "Epoch 8/10, Loss: 0.6124407629966736\n",
            "Epoch 8/10, Loss: 0.6131292597055436\n",
            "Epoch 8/10, Loss: 0.613820052742958\n",
            "Epoch 8/10, Loss: 0.6145140274167061\n",
            "Epoch 8/10, Loss: 0.6152128850817681\n",
            "Epoch 8/10, Loss: 0.6158923726677895\n",
            "Epoch 8/10, Loss: 0.616582696378231\n",
            "Epoch 8/10, Loss: 0.6172547117471695\n",
            "Epoch 8/10, Loss: 0.6179371985197067\n",
            "Epoch 8/10, Loss: 0.6186261404752731\n",
            "Epoch 8/10, Loss: 0.619316969871521\n",
            "Epoch 8/10, Loss: 0.6200093914270401\n",
            "Epoch 8/10, Loss: 0.620701868891716\n",
            "Epoch 8/10, Loss: 0.6213962689638138\n",
            "Epoch 8/10, Loss: 0.6220853024721146\n",
            "Epoch 8/10, Loss: 0.6227719315886497\n",
            "Epoch 8/10, Loss: 0.6234629603028298\n",
            "Epoch 8/10, Loss: 0.6241596740484238\n",
            "Epoch 8/10, Loss: 0.62484612429142\n",
            "Epoch 8/10, Loss: 0.6255279408693314\n",
            "Epoch 8/10, Loss: 0.6262141571044922\n",
            "Epoch 8/10, Loss: 0.6269048563241959\n",
            "Epoch 8/10, Loss: 0.6275886453390122\n",
            "Epoch 8/10, Loss: 0.6282718386054039\n",
            "Epoch 8/10, Loss: 0.628966385781765\n",
            "Epoch 8/10, Loss: 0.6296550272107124\n",
            "Epoch 8/10, Loss: 0.6303400495648384\n",
            "Epoch 8/10, Loss: 0.6310324664711953\n",
            "Epoch 8/10, Loss: 0.6317269578576088\n",
            "Epoch 8/10, Loss: 0.6324206032156944\n",
            "Epoch 8/10, Loss: 0.6331062451601028\n",
            "Epoch 8/10, Loss: 0.6337998980283737\n",
            "Epoch 8/10, Loss: 0.6344889326095581\n",
            "Epoch 8/10, Loss: 0.6351701440215111\n",
            "Epoch 8/10, Loss: 0.6358635186553001\n",
            "Epoch 8/10, Loss: 0.6365663506388665\n",
            "Epoch 8/10, Loss: 0.6372466263175011\n",
            "Epoch 8/10, Loss: 0.6379421311020851\n",
            "Epoch 8/10, Loss: 0.6386216710209847\n",
            "Epoch 8/10, Loss: 0.6393137370944023\n",
            "Epoch 8/10, Loss: 0.6399908567070961\n",
            "Epoch 8/10, Loss: 0.6406835686564446\n",
            "Epoch 8/10, Loss: 0.6413731936216355\n",
            "Epoch 8/10, Loss: 0.6420726267695427\n",
            "Epoch 8/10, Loss: 0.6427668751478195\n",
            "Epoch 8/10, Loss: 0.6434529102444648\n",
            "Epoch 8/10, Loss: 0.6441294324994087\n",
            "Epoch 8/10, Loss: 0.6448169907927513\n",
            "Epoch 8/10, Loss: 0.6455030910968781\n",
            "Epoch 8/10, Loss: 0.6461994687318802\n",
            "Epoch 8/10, Loss: 0.6468906150460243\n",
            "Epoch 8/10, Loss: 0.6475801188349724\n",
            "Epoch 8/10, Loss: 0.6482821218967437\n",
            "Epoch 8/10, Loss: 0.6489810316562653\n",
            "Epoch 8/10, Loss: 0.649663702905178\n",
            "Epoch 8/10, Loss: 0.6503481413722039\n",
            "Epoch 8/10, Loss: 0.6510340555906295\n",
            "Epoch 8/10, Loss: 0.6517255079746246\n",
            "Epoch 8/10, Loss: 0.6524171312451362\n",
            "Epoch 8/10, Loss: 0.6530869237184525\n",
            "Epoch 8/10, Loss: 0.6537711173295975\n",
            "Epoch 8/10, Loss: 0.6544610452651978\n",
            "Epoch 8/10, Loss: 0.655156667470932\n",
            "Epoch 8/10, Loss: 0.655862904548645\n",
            "Epoch 8/10, Loss: 0.656553015947342\n",
            "Epoch 8/10, Loss: 0.6572537225484848\n",
            "Epoch 8/10, Loss: 0.6579499878883361\n",
            "Epoch 8/10, Loss: 0.6586427811384201\n",
            "Epoch 8/10, Loss: 0.6593324508666992\n",
            "Epoch 8/10, Loss: 0.660017961025238\n",
            "Epoch 8/10, Loss: 0.660708884716034\n",
            "Epoch 8/10, Loss: 0.6613972430229187\n",
            "Epoch 8/10, Loss: 0.6620881297588348\n",
            "Epoch 8/10, Loss: 0.6627864934206009\n",
            "Epoch 8/10, Loss: 0.6634720349907876\n",
            "Epoch 8/10, Loss: 0.6641653320789337\n",
            "Epoch 8/10, Loss: 0.6648597511053085\n",
            "Epoch 8/10, Loss: 0.665551090478897\n",
            "Epoch 8/10, Loss: 0.6662445226311684\n",
            "Epoch 8/10, Loss: 0.6669431846737862\n",
            "Epoch 8/10, Loss: 0.667636215209961\n",
            "Epoch 8/10, Loss: 0.6683296302556991\n",
            "Epoch 8/10, Loss: 0.669026045203209\n",
            "Epoch 8/10, Loss: 0.6697200070023537\n",
            "Epoch 8/10, Loss: 0.6704094552993775\n",
            "Epoch 8/10, Loss: 0.6710980582237244\n",
            "Epoch 8/10, Loss: 0.6717825455665588\n",
            "Epoch 8/10, Loss: 0.6724677896499633\n",
            "Epoch 8/10, Loss: 0.6731628051400185\n",
            "Epoch 8/10, Loss: 0.6738597260713577\n",
            "Epoch 8/10, Loss: 0.6745475217103958\n",
            "Epoch 8/10, Loss: 0.675235324203968\n",
            "Epoch 8/10, Loss: 0.6759255084991455\n",
            "Epoch 8/10, Loss: 0.676629112303257\n",
            "Epoch 8/10, Loss: 0.6773334708809853\n",
            "Epoch 8/10, Loss: 0.6780158714056015\n",
            "Epoch 8/10, Loss: 0.6787142239809036\n",
            "Epoch 8/10, Loss: 0.6794033969640731\n",
            "Epoch 8/10, Loss: 0.6800863404273987\n",
            "Epoch 8/10, Loss: 0.6807918319106102\n",
            "Epoch 8/10, Loss: 0.6814896771907807\n",
            "Epoch 8/10, Loss: 0.6821704353094101\n",
            "Epoch 8/10, Loss: 0.6828625440597534\n",
            "Epoch 8/10, Loss: 0.6835605691671371\n",
            "Epoch 8/10, Loss: 0.68428071641922\n",
            "Epoch 8/10, Loss: 0.684960152387619\n",
            "Epoch 8/10, Loss: 0.6856549905538559\n",
            "Epoch 8/10, Loss: 0.6863490361571312\n",
            "Epoch 8/10, Loss: 0.6870489853024483\n",
            "Epoch 8/10, Loss: 0.6877362909913063\n",
            "Epoch 8/10, Loss: 0.6884244079589844\n",
            "Epoch 8/10, Loss: 0.6891250206232071\n",
            "Epoch 8/10, Loss: 0.6898212798833847\n",
            "Epoch 8/10, Loss: 0.690512855231762\n",
            "Epoch 9/10, Loss: 0.0006931681036949158\n",
            "Epoch 9/10, Loss: 0.001385645627975464\n",
            "Epoch 9/10, Loss: 0.002077746748924255\n",
            "Epoch 9/10, Loss: 0.00277232563495636\n",
            "Epoch 9/10, Loss: 0.003459125280380249\n",
            "Epoch 9/10, Loss: 0.004152116298675537\n",
            "Epoch 9/10, Loss: 0.004832553207874298\n",
            "Epoch 9/10, Loss: 0.0055266709327697755\n",
            "Epoch 9/10, Loss: 0.006210355937480926\n",
            "Epoch 9/10, Loss: 0.0068918392658233645\n",
            "Epoch 9/10, Loss: 0.007579248070716858\n",
            "Epoch 9/10, Loss: 0.008258981466293334\n",
            "Epoch 9/10, Loss: 0.008941058754920959\n",
            "Epoch 9/10, Loss: 0.009635247230529786\n",
            "Epoch 9/10, Loss: 0.010326788485050201\n",
            "Epoch 9/10, Loss: 0.01102543556690216\n",
            "Epoch 9/10, Loss: 0.011726048350334167\n",
            "Epoch 9/10, Loss: 0.012399820923805236\n",
            "Epoch 9/10, Loss: 0.013097303628921508\n",
            "Epoch 9/10, Loss: 0.013787124156951904\n",
            "Epoch 9/10, Loss: 0.014480271995067597\n",
            "Epoch 9/10, Loss: 0.015170074224472046\n",
            "Epoch 9/10, Loss: 0.01586374855041504\n",
            "Epoch 9/10, Loss: 0.016551578879356384\n",
            "Epoch 9/10, Loss: 0.01722832679748535\n",
            "Epoch 9/10, Loss: 0.017897567749023437\n",
            "Epoch 9/10, Loss: 0.01858792358636856\n",
            "Epoch 9/10, Loss: 0.019281223058700562\n",
            "Epoch 9/10, Loss: 0.01997590458393097\n",
            "Epoch 9/10, Loss: 0.02066671508550644\n",
            "Epoch 9/10, Loss: 0.021351028442382812\n",
            "Epoch 9/10, Loss: 0.022044025897979738\n",
            "Epoch 9/10, Loss: 0.022742141723632814\n",
            "Epoch 9/10, Loss: 0.023437199115753173\n",
            "Epoch 9/10, Loss: 0.02414201033115387\n",
            "Epoch 9/10, Loss: 0.024824987113475798\n",
            "Epoch 9/10, Loss: 0.025520075380802153\n",
            "Epoch 9/10, Loss: 0.026205837965011598\n",
            "Epoch 9/10, Loss: 0.026884978473186494\n",
            "Epoch 9/10, Loss: 0.027574035048484803\n",
            "Epoch 9/10, Loss: 0.028267836928367616\n",
            "Epoch 9/10, Loss: 0.02895053482055664\n",
            "Epoch 9/10, Loss: 0.029647725105285645\n",
            "Epoch 9/10, Loss: 0.030348259210586547\n",
            "Epoch 9/10, Loss: 0.031043729424476623\n",
            "Epoch 9/10, Loss: 0.03172730904817581\n",
            "Epoch 9/10, Loss: 0.03241941565275192\n",
            "Epoch 9/10, Loss: 0.03310893529653549\n",
            "Epoch 9/10, Loss: 0.03381255716085434\n",
            "Epoch 9/10, Loss: 0.03450560802221298\n",
            "Epoch 9/10, Loss: 0.035204072654247284\n",
            "Epoch 9/10, Loss: 0.035882271230220794\n",
            "Epoch 9/10, Loss: 0.03657918959856033\n",
            "Epoch 9/10, Loss: 0.03726565539836883\n",
            "Epoch 9/10, Loss: 0.03795690757036209\n",
            "Epoch 9/10, Loss: 0.03865593165159226\n",
            "Epoch 9/10, Loss: 0.03935102254152298\n",
            "Epoch 9/10, Loss: 0.04003603482246399\n",
            "Epoch 9/10, Loss: 0.04073502558469772\n",
            "Epoch 9/10, Loss: 0.041419445216655734\n",
            "Epoch 9/10, Loss: 0.04210480922460556\n",
            "Epoch 9/10, Loss: 0.04279468619823456\n",
            "Epoch 9/10, Loss: 0.043480249881744384\n",
            "Epoch 9/10, Loss: 0.04418337774276734\n",
            "Epoch 9/10, Loss: 0.044871422052383425\n",
            "Epoch 9/10, Loss: 0.045559347093105315\n",
            "Epoch 9/10, Loss: 0.04625246238708496\n",
            "Epoch 9/10, Loss: 0.04694325459003448\n",
            "Epoch 9/10, Loss: 0.047646226286888124\n",
            "Epoch 9/10, Loss: 0.04834820848703385\n",
            "Epoch 9/10, Loss: 0.049041838407516476\n",
            "Epoch 9/10, Loss: 0.049731981754302976\n",
            "Epoch 9/10, Loss: 0.05041770613193512\n",
            "Epoch 9/10, Loss: 0.05110878121852875\n",
            "Epoch 9/10, Loss: 0.05180007761716843\n",
            "Epoch 9/10, Loss: 0.05248807901144028\n",
            "Epoch 9/10, Loss: 0.05318855929374695\n",
            "Epoch 9/10, Loss: 0.05388116043806076\n",
            "Epoch 9/10, Loss: 0.05456954342126846\n",
            "Epoch 9/10, Loss: 0.05525926011800766\n",
            "Epoch 9/10, Loss: 0.055945702612400054\n",
            "Epoch 9/10, Loss: 0.0566237673163414\n",
            "Epoch 9/10, Loss: 0.05731152552366257\n",
            "Epoch 9/10, Loss: 0.058006492555141446\n",
            "Epoch 9/10, Loss: 0.05868549901247024\n",
            "Epoch 9/10, Loss: 0.05937409889698029\n",
            "Epoch 9/10, Loss: 0.06006637823581695\n",
            "Epoch 9/10, Loss: 0.060758800208568574\n",
            "Epoch 9/10, Loss: 0.06144786477088928\n",
            "Epoch 9/10, Loss: 0.06212885141372681\n",
            "Epoch 9/10, Loss: 0.0628195818066597\n",
            "Epoch 9/10, Loss: 0.06350631153583526\n",
            "Epoch 9/10, Loss: 0.06419926786422729\n",
            "Epoch 9/10, Loss: 0.06489678990840912\n",
            "Epoch 9/10, Loss: 0.0655837379693985\n",
            "Epoch 9/10, Loss: 0.06626667201519013\n",
            "Epoch 9/10, Loss: 0.06695196413993836\n",
            "Epoch 9/10, Loss: 0.06763094568252563\n",
            "Epoch 9/10, Loss: 0.0683170998096466\n",
            "Epoch 9/10, Loss: 0.06901363086700439\n",
            "Epoch 9/10, Loss: 0.06970328938961029\n",
            "Epoch 9/10, Loss: 0.07038611227273942\n",
            "Epoch 9/10, Loss: 0.07107114499807357\n",
            "Epoch 9/10, Loss: 0.07175983250141144\n",
            "Epoch 9/10, Loss: 0.0724496282339096\n",
            "Epoch 9/10, Loss: 0.07312629705667496\n",
            "Epoch 9/10, Loss: 0.07381831753253937\n",
            "Epoch 9/10, Loss: 0.07450915241241456\n",
            "Epoch 9/10, Loss: 0.07519865167140961\n",
            "Epoch 9/10, Loss: 0.075887375831604\n",
            "Epoch 9/10, Loss: 0.07656881868839265\n",
            "Epoch 9/10, Loss: 0.07725902384519577\n",
            "Epoch 9/10, Loss: 0.07795180422067642\n",
            "Epoch 9/10, Loss: 0.07863755476474762\n",
            "Epoch 9/10, Loss: 0.07932278513908386\n",
            "Epoch 9/10, Loss: 0.08002647852897644\n",
            "Epoch 9/10, Loss: 0.08070848667621612\n",
            "Epoch 9/10, Loss: 0.0813993376493454\n",
            "Epoch 9/10, Loss: 0.08208359968662261\n",
            "Epoch 9/10, Loss: 0.08277097380161286\n",
            "Epoch 9/10, Loss: 0.08345420390367508\n",
            "Epoch 9/10, Loss: 0.08413876605033875\n",
            "Epoch 9/10, Loss: 0.08482266175746918\n",
            "Epoch 9/10, Loss: 0.08552188169956207\n",
            "Epoch 9/10, Loss: 0.08620846045017243\n",
            "Epoch 9/10, Loss: 0.086900958776474\n",
            "Epoch 9/10, Loss: 0.08760050976276398\n",
            "Epoch 9/10, Loss: 0.08829520708322525\n",
            "Epoch 9/10, Loss: 0.08899157810211182\n",
            "Epoch 9/10, Loss: 0.089681447327137\n",
            "Epoch 9/10, Loss: 0.09037693828344345\n",
            "Epoch 9/10, Loss: 0.0910607299208641\n",
            "Epoch 9/10, Loss: 0.09174805247783661\n",
            "Epoch 9/10, Loss: 0.09243874663114547\n",
            "Epoch 9/10, Loss: 0.09311247134208679\n",
            "Epoch 9/10, Loss: 0.09379549086093902\n",
            "Epoch 9/10, Loss: 0.09448920929431916\n",
            "Epoch 9/10, Loss: 0.09517433249950409\n",
            "Epoch 9/10, Loss: 0.09586159962415695\n",
            "Epoch 9/10, Loss: 0.0965604145526886\n",
            "Epoch 9/10, Loss: 0.09725353080034256\n",
            "Epoch 9/10, Loss: 0.09794378042221069\n",
            "Epoch 9/10, Loss: 0.09863662612438202\n",
            "Epoch 9/10, Loss: 0.0993387347459793\n",
            "Epoch 9/10, Loss: 0.1000262906551361\n",
            "Epoch 9/10, Loss: 0.10072282344102859\n",
            "Epoch 9/10, Loss: 0.10141775226593018\n",
            "Epoch 9/10, Loss: 0.10211894476413727\n",
            "Epoch 9/10, Loss: 0.1028021204471588\n",
            "Epoch 9/10, Loss: 0.1034783136844635\n",
            "Epoch 9/10, Loss: 0.10416802072525025\n",
            "Epoch 9/10, Loss: 0.10485499787330628\n",
            "Epoch 9/10, Loss: 0.10554684180021286\n",
            "Epoch 9/10, Loss: 0.10623033529520035\n",
            "Epoch 9/10, Loss: 0.10691656970977784\n",
            "Epoch 9/10, Loss: 0.10759538578987121\n",
            "Epoch 9/10, Loss: 0.10828151142597199\n",
            "Epoch 9/10, Loss: 0.10896721839904785\n",
            "Epoch 9/10, Loss: 0.10965205264091492\n",
            "Epoch 9/10, Loss: 0.11033452272415162\n",
            "Epoch 9/10, Loss: 0.11101953721046448\n",
            "Epoch 9/10, Loss: 0.11171493923664093\n",
            "Epoch 9/10, Loss: 0.1124028308391571\n",
            "Epoch 9/10, Loss: 0.11309773230552674\n",
            "Epoch 9/10, Loss: 0.11378000193834305\n",
            "Epoch 9/10, Loss: 0.11446403127908707\n",
            "Epoch 9/10, Loss: 0.11515828567743301\n",
            "Epoch 9/10, Loss: 0.11584923350811005\n",
            "Epoch 9/10, Loss: 0.11654158949851989\n",
            "Epoch 9/10, Loss: 0.11723479974269867\n",
            "Epoch 9/10, Loss: 0.11792884695529937\n",
            "Epoch 9/10, Loss: 0.11861220216751099\n",
            "Epoch 9/10, Loss: 0.11930064439773559\n",
            "Epoch 9/10, Loss: 0.11999591928720474\n",
            "Epoch 9/10, Loss: 0.12070210868120193\n",
            "Epoch 9/10, Loss: 0.12139578992128372\n",
            "Epoch 9/10, Loss: 0.1220740277171135\n",
            "Epoch 9/10, Loss: 0.12276053446531296\n",
            "Epoch 9/10, Loss: 0.12345087057352067\n",
            "Epoch 9/10, Loss: 0.12414312690496444\n",
            "Epoch 9/10, Loss: 0.12484058451652527\n",
            "Epoch 9/10, Loss: 0.1255230848789215\n",
            "Epoch 9/10, Loss: 0.1262126145362854\n",
            "Epoch 9/10, Loss: 0.12690747499465943\n",
            "Epoch 9/10, Loss: 0.12759101802110673\n",
            "Epoch 9/10, Loss: 0.12828964632749557\n",
            "Epoch 9/10, Loss: 0.12897895753383637\n",
            "Epoch 9/10, Loss: 0.12966984748840332\n",
            "Epoch 9/10, Loss: 0.1303547928929329\n",
            "Epoch 9/10, Loss: 0.13103611773252488\n",
            "Epoch 9/10, Loss: 0.13172516012191773\n",
            "Epoch 9/10, Loss: 0.13241966706514358\n",
            "Epoch 9/10, Loss: 0.13310494369268416\n",
            "Epoch 9/10, Loss: 0.13379833513498307\n",
            "Epoch 9/10, Loss: 0.1344726320505142\n",
            "Epoch 9/10, Loss: 0.13515989583730698\n",
            "Epoch 9/10, Loss: 0.1358507418036461\n",
            "Epoch 9/10, Loss: 0.13654021793603896\n",
            "Epoch 9/10, Loss: 0.13722653144598007\n",
            "Epoch 9/10, Loss: 0.13790592867136\n",
            "Epoch 9/10, Loss: 0.13858798998594285\n",
            "Epoch 9/10, Loss: 0.1392833803296089\n",
            "Epoch 9/10, Loss: 0.139978917658329\n",
            "Epoch 9/10, Loss: 0.14066599905490876\n",
            "Epoch 9/10, Loss: 0.14136066102981568\n",
            "Epoch 9/10, Loss: 0.14205835688114166\n",
            "Epoch 9/10, Loss: 0.1427488133907318\n",
            "Epoch 9/10, Loss: 0.14344020694494247\n",
            "Epoch 9/10, Loss: 0.14412278419733046\n",
            "Epoch 9/10, Loss: 0.14481321340799333\n",
            "Epoch 9/10, Loss: 0.14551619231700896\n",
            "Epoch 9/10, Loss: 0.1462070404291153\n",
            "Epoch 9/10, Loss: 0.14689450120925904\n",
            "Epoch 9/10, Loss: 0.1475884558558464\n",
            "Epoch 9/10, Loss: 0.1482720981836319\n",
            "Epoch 9/10, Loss: 0.14896677911281586\n",
            "Epoch 9/10, Loss: 0.14965100914239884\n",
            "Epoch 9/10, Loss: 0.1503404329419136\n",
            "Epoch 9/10, Loss: 0.15101985281705857\n",
            "Epoch 9/10, Loss: 0.15171574527025222\n",
            "Epoch 9/10, Loss: 0.15241391706466675\n",
            "Epoch 9/10, Loss: 0.15310971862077713\n",
            "Epoch 9/10, Loss: 0.15379333192110062\n",
            "Epoch 9/10, Loss: 0.15448714643716813\n",
            "Epoch 9/10, Loss: 0.1551707702279091\n",
            "Epoch 9/10, Loss: 0.15585660976171495\n",
            "Epoch 9/10, Loss: 0.156546136200428\n",
            "Epoch 9/10, Loss: 0.15723650914430617\n",
            "Epoch 9/10, Loss: 0.15792440885305406\n",
            "Epoch 9/10, Loss: 0.1586111558675766\n",
            "Epoch 9/10, Loss: 0.1592958639860153\n",
            "Epoch 9/10, Loss: 0.15998474252223968\n",
            "Epoch 9/10, Loss: 0.16068232369422913\n",
            "Epoch 9/10, Loss: 0.16137587416172028\n",
            "Epoch 9/10, Loss: 0.16207078647613526\n",
            "Epoch 9/10, Loss: 0.16276250338554382\n",
            "Epoch 9/10, Loss: 0.1634519567489624\n",
            "Epoch 9/10, Loss: 0.16413479685783386\n",
            "Epoch 9/10, Loss: 0.16481838876008986\n",
            "Epoch 9/10, Loss: 0.16551432847976685\n",
            "Epoch 9/10, Loss: 0.16620338273048402\n",
            "Epoch 9/10, Loss: 0.16690543961524965\n",
            "Epoch 9/10, Loss: 0.16759907907247543\n",
            "Epoch 9/10, Loss: 0.1682911195755005\n",
            "Epoch 9/10, Loss: 0.16898396956920625\n",
            "Epoch 9/10, Loss: 0.16966894620656967\n",
            "Epoch 9/10, Loss: 0.1703603117465973\n",
            "Epoch 9/10, Loss: 0.17104069244861603\n",
            "Epoch 9/10, Loss: 0.1717330380678177\n",
            "Epoch 9/10, Loss: 0.17242954075336456\n",
            "Epoch 9/10, Loss: 0.17310298192501067\n",
            "Epoch 9/10, Loss: 0.1737938325405121\n",
            "Epoch 9/10, Loss: 0.1744840202331543\n",
            "Epoch 9/10, Loss: 0.1751716267466545\n",
            "Epoch 9/10, Loss: 0.17586454194784165\n",
            "Epoch 9/10, Loss: 0.17656323343515395\n",
            "Epoch 9/10, Loss: 0.1772485136985779\n",
            "Epoch 9/10, Loss: 0.17793900203704835\n",
            "Epoch 9/10, Loss: 0.17863274604082108\n",
            "Epoch 9/10, Loss: 0.17932385498285294\n",
            "Epoch 9/10, Loss: 0.18002201825380326\n",
            "Epoch 9/10, Loss: 0.1807050633430481\n",
            "Epoch 9/10, Loss: 0.1813956401348114\n",
            "Epoch 9/10, Loss: 0.1820823181271553\n",
            "Epoch 9/10, Loss: 0.18276904398202895\n",
            "Epoch 9/10, Loss: 0.18345465636253358\n",
            "Epoch 9/10, Loss: 0.18416159784793854\n",
            "Epoch 9/10, Loss: 0.18486980617046356\n",
            "Epoch 9/10, Loss: 0.18557085752487182\n",
            "Epoch 9/10, Loss: 0.18626051092147827\n",
            "Epoch 9/10, Loss: 0.1869607343673706\n",
            "Epoch 9/10, Loss: 0.18765101432800294\n",
            "Epoch 9/10, Loss: 0.18833455234766006\n",
            "Epoch 9/10, Loss: 0.18902426075935364\n",
            "Epoch 9/10, Loss: 0.18971137088537215\n",
            "Epoch 9/10, Loss: 0.19041566747426986\n",
            "Epoch 9/10, Loss: 0.19111554235219955\n",
            "Epoch 9/10, Loss: 0.19179924875497817\n",
            "Epoch 9/10, Loss: 0.19247972971200944\n",
            "Epoch 9/10, Loss: 0.1931813332438469\n",
            "Epoch 9/10, Loss: 0.1938721716403961\n",
            "Epoch 9/10, Loss: 0.19455825614929198\n",
            "Epoch 9/10, Loss: 0.1952399879693985\n",
            "Epoch 9/10, Loss: 0.19592773139476777\n",
            "Epoch 9/10, Loss: 0.19662507504224777\n",
            "Epoch 9/10, Loss: 0.19731464147567748\n",
            "Epoch 9/10, Loss: 0.19800215327739715\n",
            "Epoch 9/10, Loss: 0.198692787528038\n",
            "Epoch 9/10, Loss: 0.19937396538257598\n",
            "Epoch 9/10, Loss: 0.20007077753543853\n",
            "Epoch 9/10, Loss: 0.2007632316350937\n",
            "Epoch 9/10, Loss: 0.20145612758398057\n",
            "Epoch 9/10, Loss: 0.20213566046953202\n",
            "Epoch 9/10, Loss: 0.2028380562067032\n",
            "Epoch 9/10, Loss: 0.20352885580062866\n",
            "Epoch 9/10, Loss: 0.20423161107301713\n",
            "Epoch 9/10, Loss: 0.20494282764196395\n",
            "Epoch 9/10, Loss: 0.20562827533483505\n",
            "Epoch 9/10, Loss: 0.20631613785028458\n",
            "Epoch 9/10, Loss: 0.2070089711546898\n",
            "Epoch 9/10, Loss: 0.20769827169179916\n",
            "Epoch 9/10, Loss: 0.20837876665592195\n",
            "Epoch 9/10, Loss: 0.2090773068666458\n",
            "Epoch 9/10, Loss: 0.20976872026920318\n",
            "Epoch 9/10, Loss: 0.21046354061365127\n",
            "Epoch 9/10, Loss: 0.21115573173761368\n",
            "Epoch 9/10, Loss: 0.21184212070703506\n",
            "Epoch 9/10, Loss: 0.2125285520553589\n",
            "Epoch 9/10, Loss: 0.21320950984954834\n",
            "Epoch 9/10, Loss: 0.21390153014659882\n",
            "Epoch 9/10, Loss: 0.2145942340493202\n",
            "Epoch 9/10, Loss: 0.21528844338655473\n",
            "Epoch 9/10, Loss: 0.21598016285896302\n",
            "Epoch 9/10, Loss: 0.21666899687051774\n",
            "Epoch 9/10, Loss: 0.21735532504320146\n",
            "Epoch 9/10, Loss: 0.2180451381802559\n",
            "Epoch 9/10, Loss: 0.2187400416135788\n",
            "Epoch 9/10, Loss: 0.21942214572429658\n",
            "Epoch 9/10, Loss: 0.22011633813381196\n",
            "Epoch 9/10, Loss: 0.22080472910404206\n",
            "Epoch 9/10, Loss: 0.2214924112558365\n",
            "Epoch 9/10, Loss: 0.22218396472930907\n",
            "Epoch 9/10, Loss: 0.22287614798545838\n",
            "Epoch 9/10, Loss: 0.22356448394060136\n",
            "Epoch 9/10, Loss: 0.2242572174668312\n",
            "Epoch 9/10, Loss: 0.2249422242641449\n",
            "Epoch 9/10, Loss: 0.22563796174526216\n",
            "Epoch 9/10, Loss: 0.226324886739254\n",
            "Epoch 9/10, Loss: 0.22700221896171568\n",
            "Epoch 9/10, Loss: 0.22769955962896346\n",
            "Epoch 9/10, Loss: 0.22837448984384537\n",
            "Epoch 9/10, Loss: 0.22906411224603654\n",
            "Epoch 9/10, Loss: 0.229759845495224\n",
            "Epoch 9/10, Loss: 0.2304473257660866\n",
            "Epoch 9/10, Loss: 0.2311363268494606\n",
            "Epoch 9/10, Loss: 0.2318136186003685\n",
            "Epoch 9/10, Loss: 0.2325002653002739\n",
            "Epoch 9/10, Loss: 0.23319741970300675\n",
            "Epoch 9/10, Loss: 0.23389374345541\n",
            "Epoch 9/10, Loss: 0.23457685267925263\n",
            "Epoch 9/10, Loss: 0.23525818699598314\n",
            "Epoch 9/10, Loss: 0.23595171636343001\n",
            "Epoch 9/10, Loss: 0.23664604580402374\n",
            "Epoch 9/10, Loss: 0.23734440672397614\n",
            "Epoch 9/10, Loss: 0.23804371082782746\n",
            "Epoch 9/10, Loss: 0.23874251556396484\n",
            "Epoch 9/10, Loss: 0.23942578196525574\n",
            "Epoch 9/10, Loss: 0.24011661118268968\n",
            "Epoch 9/10, Loss: 0.240810910820961\n",
            "Epoch 9/10, Loss: 0.2415030055642128\n",
            "Epoch 9/10, Loss: 0.24220365756750106\n",
            "Epoch 9/10, Loss: 0.242901952624321\n",
            "Epoch 9/10, Loss: 0.24359418725967408\n",
            "Epoch 9/10, Loss: 0.24429202628135682\n",
            "Epoch 9/10, Loss: 0.24497428727149964\n",
            "Epoch 9/10, Loss: 0.24566748034954072\n",
            "Epoch 9/10, Loss: 0.24634752076864241\n",
            "Epoch 9/10, Loss: 0.24704179406166077\n",
            "Epoch 9/10, Loss: 0.24772711503505707\n",
            "Epoch 9/10, Loss: 0.24841183012723922\n",
            "Epoch 9/10, Loss: 0.24911814284324646\n",
            "Epoch 9/10, Loss: 0.2498089800477028\n",
            "Epoch 9/10, Loss: 0.2505041856169701\n",
            "Epoch 9/10, Loss: 0.25119449466466903\n",
            "Epoch 9/10, Loss: 0.2518826938271522\n",
            "Epoch 9/10, Loss: 0.2525617715716362\n",
            "Epoch 9/10, Loss: 0.2532448056936264\n",
            "Epoch 9/10, Loss: 0.25392928087711336\n",
            "Epoch 9/10, Loss: 0.25461657363176343\n",
            "Epoch 9/10, Loss: 0.25530719393491746\n",
            "Epoch 9/10, Loss: 0.2559940095543861\n",
            "Epoch 9/10, Loss: 0.25668564742803573\n",
            "Epoch 9/10, Loss: 0.2573776722550392\n",
            "Epoch 9/10, Loss: 0.2580691023468971\n",
            "Epoch 9/10, Loss: 0.25877159494161606\n",
            "Epoch 9/10, Loss: 0.25946274679899217\n",
            "Epoch 9/10, Loss: 0.26015401113033293\n",
            "Epoch 9/10, Loss: 0.2608479822874069\n",
            "Epoch 9/10, Loss: 0.26154488915205004\n",
            "Epoch 9/10, Loss: 0.2622346891760826\n",
            "Epoch 9/10, Loss: 0.2629267837405205\n",
            "Epoch 9/10, Loss: 0.2636148340702057\n",
            "Epoch 9/10, Loss: 0.26430463886260985\n",
            "Epoch 9/10, Loss: 0.2650102586150169\n",
            "Epoch 9/10, Loss: 0.26569733959436415\n",
            "Epoch 9/10, Loss: 0.26639293175935747\n",
            "Epoch 9/10, Loss: 0.2670895023941994\n",
            "Epoch 9/10, Loss: 0.26776778626441955\n",
            "Epoch 9/10, Loss: 0.26844910061359406\n",
            "Epoch 9/10, Loss: 0.2691361240148544\n",
            "Epoch 9/10, Loss: 0.26983101105690005\n",
            "Epoch 9/10, Loss: 0.2705252404808998\n",
            "Epoch 9/10, Loss: 0.271214330971241\n",
            "Epoch 9/10, Loss: 0.2718915273547173\n",
            "Epoch 9/10, Loss: 0.27258295732736587\n",
            "Epoch 9/10, Loss: 0.2732679527401924\n",
            "Epoch 9/10, Loss: 0.273969182908535\n",
            "Epoch 9/10, Loss: 0.2746542299985886\n",
            "Epoch 9/10, Loss: 0.2753460693359375\n",
            "Epoch 9/10, Loss: 0.27603203785419467\n",
            "Epoch 9/10, Loss: 0.27673033607006076\n",
            "Epoch 9/10, Loss: 0.2774127321243286\n",
            "Epoch 9/10, Loss: 0.27810281550884247\n",
            "Epoch 9/10, Loss: 0.27878782254457474\n",
            "Epoch 9/10, Loss: 0.2794861909747124\n",
            "Epoch 9/10, Loss: 0.2801644915342331\n",
            "Epoch 9/10, Loss: 0.28085712736845014\n",
            "Epoch 9/10, Loss: 0.28155228972435\n",
            "Epoch 9/10, Loss: 0.2822494309544563\n",
            "Epoch 9/10, Loss: 0.2829212888479233\n",
            "Epoch 9/10, Loss: 0.2836168439388275\n",
            "Epoch 9/10, Loss: 0.2843091263771057\n",
            "Epoch 9/10, Loss: 0.2849872772693634\n",
            "Epoch 9/10, Loss: 0.28567504000663757\n",
            "Epoch 9/10, Loss: 0.2863706206083298\n",
            "Epoch 9/10, Loss: 0.28705964946746826\n",
            "Epoch 9/10, Loss: 0.2877500480413437\n",
            "Epoch 9/10, Loss: 0.2884314113855362\n",
            "Epoch 9/10, Loss: 0.28912589186429977\n",
            "Epoch 9/10, Loss: 0.28981476730108263\n",
            "Epoch 9/10, Loss: 0.2905016477704048\n",
            "Epoch 9/10, Loss: 0.2911844841837883\n",
            "Epoch 9/10, Loss: 0.29188227039575576\n",
            "Epoch 9/10, Loss: 0.2925678541064262\n",
            "Epoch 9/10, Loss: 0.2932636743187904\n",
            "Epoch 9/10, Loss: 0.29395836186408997\n",
            "Epoch 9/10, Loss: 0.2946436650156975\n",
            "Epoch 9/10, Loss: 0.2953323033452034\n",
            "Epoch 9/10, Loss: 0.2960114354491234\n",
            "Epoch 9/10, Loss: 0.29670578610897064\n",
            "Epoch 9/10, Loss: 0.29739312529563905\n",
            "Epoch 9/10, Loss: 0.29807596147060395\n",
            "Epoch 9/10, Loss: 0.2987577613592148\n",
            "Epoch 9/10, Loss: 0.29944934403896334\n",
            "Epoch 9/10, Loss: 0.3001385360956192\n",
            "Epoch 9/10, Loss: 0.3008247793316841\n",
            "Epoch 9/10, Loss: 0.30151181799173354\n",
            "Epoch 9/10, Loss: 0.30220599853992464\n",
            "Epoch 9/10, Loss: 0.3028922393321991\n",
            "Epoch 9/10, Loss: 0.30358050829172134\n",
            "Epoch 9/10, Loss: 0.30426575809717177\n",
            "Epoch 9/10, Loss: 0.3049504700303078\n",
            "Epoch 9/10, Loss: 0.30562841564416887\n",
            "Epoch 9/10, Loss: 0.30631553298234937\n",
            "Epoch 9/10, Loss: 0.3070107298493385\n",
            "Epoch 9/10, Loss: 0.3076899919509888\n",
            "Epoch 9/10, Loss: 0.308370166182518\n",
            "Epoch 9/10, Loss: 0.3090635264515877\n",
            "Epoch 9/10, Loss: 0.3097489333152771\n",
            "Epoch 9/10, Loss: 0.31043018954992296\n",
            "Epoch 9/10, Loss: 0.31111677342653277\n",
            "Epoch 9/10, Loss: 0.3118084205389023\n",
            "Epoch 9/10, Loss: 0.3125054016113281\n",
            "Epoch 9/10, Loss: 0.31320438849925997\n",
            "Epoch 9/10, Loss: 0.3139114176034927\n",
            "Epoch 9/10, Loss: 0.3145889195203781\n",
            "Epoch 9/10, Loss: 0.3152731064558029\n",
            "Epoch 9/10, Loss: 0.31595397090911864\n",
            "Epoch 9/10, Loss: 0.3166395295262337\n",
            "Epoch 9/10, Loss: 0.3173326014876366\n",
            "Epoch 9/10, Loss: 0.318024180829525\n",
            "Epoch 9/10, Loss: 0.31870917081832884\n",
            "Epoch 9/10, Loss: 0.31940768349170684\n",
            "Epoch 9/10, Loss: 0.32010083210468293\n",
            "Epoch 9/10, Loss: 0.3207943134307861\n",
            "Epoch 9/10, Loss: 0.3214878853559494\n",
            "Epoch 9/10, Loss: 0.3221890165805817\n",
            "Epoch 9/10, Loss: 0.3228664063215256\n",
            "Epoch 9/10, Loss: 0.32355189275741575\n",
            "Epoch 9/10, Loss: 0.32423330038785936\n",
            "Epoch 9/10, Loss: 0.32490913128852844\n",
            "Epoch 9/10, Loss: 0.3256079212427139\n",
            "Epoch 9/10, Loss: 0.3263088671565056\n",
            "Epoch 9/10, Loss: 0.3269885250926018\n",
            "Epoch 9/10, Loss: 0.32768292915821073\n",
            "Epoch 9/10, Loss: 0.32836504304409025\n",
            "Epoch 9/10, Loss: 0.3290558609366417\n",
            "Epoch 9/10, Loss: 0.3297492129206657\n",
            "Epoch 9/10, Loss: 0.33045721340179446\n",
            "Epoch 9/10, Loss: 0.33115128487348555\n",
            "Epoch 9/10, Loss: 0.3318353306055069\n",
            "Epoch 9/10, Loss: 0.3325345378518105\n",
            "Epoch 9/10, Loss: 0.3332404648661613\n",
            "Epoch 9/10, Loss: 0.33392563891410826\n",
            "Epoch 9/10, Loss: 0.33461111050844194\n",
            "Epoch 9/10, Loss: 0.3353026829957962\n",
            "Epoch 9/10, Loss: 0.3359992944598198\n",
            "Epoch 9/10, Loss: 0.3366839510202408\n",
            "Epoch 9/10, Loss: 0.3373784226179123\n",
            "Epoch 9/10, Loss: 0.33807058829069137\n",
            "Epoch 9/10, Loss: 0.3387613369226456\n",
            "Epoch 9/10, Loss: 0.3394444125890732\n",
            "Epoch 9/10, Loss: 0.3401353040933609\n",
            "Epoch 9/10, Loss: 0.3408393865227699\n",
            "Epoch 9/10, Loss: 0.34152568036317826\n",
            "Epoch 9/10, Loss: 0.34221712964773177\n",
            "Epoch 9/10, Loss: 0.34292028707265854\n",
            "Epoch 9/10, Loss: 0.3436222153902054\n",
            "Epoch 9/10, Loss: 0.3443126266002655\n",
            "Epoch 9/10, Loss: 0.344999734044075\n",
            "Epoch 9/10, Loss: 0.34569250702857973\n",
            "Epoch 9/10, Loss: 0.3463796384334564\n",
            "Epoch 9/10, Loss: 0.3470821796655655\n",
            "Epoch 9/10, Loss: 0.34776860815286637\n",
            "Epoch 9/10, Loss: 0.34846105200052263\n",
            "Epoch 9/10, Loss: 0.34914993280172346\n",
            "Epoch 9/10, Loss: 0.34984914207458495\n",
            "Epoch 9/10, Loss: 0.35053294330835344\n",
            "Epoch 9/10, Loss: 0.35122194093465803\n",
            "Epoch 9/10, Loss: 0.3519150552153587\n",
            "Epoch 9/10, Loss: 0.3526164341568947\n",
            "Epoch 9/10, Loss: 0.35330912482738497\n",
            "Epoch 9/10, Loss: 0.3539984464645386\n",
            "Epoch 9/10, Loss: 0.3546856176257133\n",
            "Epoch 9/10, Loss: 0.35537840431928636\n",
            "Epoch 9/10, Loss: 0.35607046908140183\n",
            "Epoch 9/10, Loss: 0.3567686673998833\n",
            "Epoch 9/10, Loss: 0.35746034932136533\n",
            "Epoch 9/10, Loss: 0.3581568514108658\n",
            "Epoch 9/10, Loss: 0.3588473994135857\n",
            "Epoch 9/10, Loss: 0.3595307390093803\n",
            "Epoch 9/10, Loss: 0.36022195702791215\n",
            "Epoch 9/10, Loss: 0.3609073426127434\n",
            "Epoch 9/10, Loss: 0.36159984475374224\n",
            "Epoch 9/10, Loss: 0.3622836418747902\n",
            "Epoch 9/10, Loss: 0.36298664563894273\n",
            "Epoch 9/10, Loss: 0.36368463045358657\n",
            "Epoch 9/10, Loss: 0.36437012428045273\n",
            "Epoch 9/10, Loss: 0.3650471011996269\n",
            "Epoch 9/10, Loss: 0.3657413563132286\n",
            "Epoch 9/10, Loss: 0.3664305582642555\n",
            "Epoch 9/10, Loss: 0.36711913073062896\n",
            "Epoch 9/10, Loss: 0.3678188464641571\n",
            "Epoch 9/10, Loss: 0.36850967884063723\n",
            "Epoch 9/10, Loss: 0.369199176967144\n",
            "Epoch 9/10, Loss: 0.36989901584386825\n",
            "Epoch 9/10, Loss: 0.3705884858965874\n",
            "Epoch 9/10, Loss: 0.3712828782200813\n",
            "Epoch 9/10, Loss: 0.3719750980734825\n",
            "Epoch 9/10, Loss: 0.37266785019636156\n",
            "Epoch 9/10, Loss: 0.37335946649312973\n",
            "Epoch 9/10, Loss: 0.37403819942474364\n",
            "Epoch 9/10, Loss: 0.37472198212146757\n",
            "Epoch 9/10, Loss: 0.375410933971405\n",
            "Epoch 9/10, Loss: 0.3760924579501152\n",
            "Epoch 9/10, Loss: 0.376776379108429\n",
            "Epoch 9/10, Loss: 0.3774652767181397\n",
            "Epoch 9/10, Loss: 0.37815105271339416\n",
            "Epoch 9/10, Loss: 0.37884591734409334\n",
            "Epoch 9/10, Loss: 0.3795390267372131\n",
            "Epoch 9/10, Loss: 0.3802260912656784\n",
            "Epoch 9/10, Loss: 0.38091698414087294\n",
            "Epoch 9/10, Loss: 0.3816086227297783\n",
            "Epoch 9/10, Loss: 0.3822926899790764\n",
            "Epoch 9/10, Loss: 0.38298269259929657\n",
            "Epoch 9/10, Loss: 0.3836639233827591\n",
            "Epoch 9/10, Loss: 0.38435868847370147\n",
            "Epoch 9/10, Loss: 0.38504122066497803\n",
            "Epoch 9/10, Loss: 0.3857354865074158\n",
            "Epoch 9/10, Loss: 0.386428444981575\n",
            "Epoch 9/10, Loss: 0.38712747079133986\n",
            "Epoch 9/10, Loss: 0.3878097556233406\n",
            "Epoch 9/10, Loss: 0.3884955080151558\n",
            "Epoch 9/10, Loss: 0.3891859692335129\n",
            "Epoch 9/10, Loss: 0.3898762258887291\n",
            "Epoch 9/10, Loss: 0.3905633598566055\n",
            "Epoch 9/10, Loss: 0.3912588795423508\n",
            "Epoch 9/10, Loss: 0.39195290660858156\n",
            "Epoch 9/10, Loss: 0.3926426742076874\n",
            "Epoch 9/10, Loss: 0.39333237379789354\n",
            "Epoch 9/10, Loss: 0.3940091740489006\n",
            "Epoch 9/10, Loss: 0.3947108274698257\n",
            "Epoch 9/10, Loss: 0.39538367074728015\n",
            "Epoch 9/10, Loss: 0.39607257848978045\n",
            "Epoch 9/10, Loss: 0.39675833129882815\n",
            "Epoch 9/10, Loss: 0.3974524208307266\n",
            "Epoch 9/10, Loss: 0.3981467817425728\n",
            "Epoch 9/10, Loss: 0.398846876680851\n",
            "Epoch 9/10, Loss: 0.3995391514897346\n",
            "Epoch 9/10, Loss: 0.40021991640329363\n",
            "Epoch 9/10, Loss: 0.4009048960208893\n",
            "Epoch 9/10, Loss: 0.40159884935617446\n",
            "Epoch 9/10, Loss: 0.4022947787642479\n",
            "Epoch 9/10, Loss: 0.40297572779655455\n",
            "Epoch 9/10, Loss: 0.40367359709739686\n",
            "Epoch 9/10, Loss: 0.40435219824314117\n",
            "Epoch 9/10, Loss: 0.4050395812988281\n",
            "Epoch 9/10, Loss: 0.4057301460504532\n",
            "Epoch 9/10, Loss: 0.40642062640190124\n",
            "Epoch 9/10, Loss: 0.4071146032810211\n",
            "Epoch 9/10, Loss: 0.4078043448328972\n",
            "Epoch 9/10, Loss: 0.4084924103617668\n",
            "Epoch 9/10, Loss: 0.40918260675668716\n",
            "Epoch 9/10, Loss: 0.4098769306540489\n",
            "Epoch 9/10, Loss: 0.41057380121946335\n",
            "Epoch 9/10, Loss: 0.4112719607949257\n",
            "Epoch 9/10, Loss: 0.41196211671829225\n",
            "Epoch 9/10, Loss: 0.4126522423028946\n",
            "Epoch 9/10, Loss: 0.4133375872373581\n",
            "Epoch 9/10, Loss: 0.41402146047353744\n",
            "Epoch 9/10, Loss: 0.41471343678236006\n",
            "Epoch 9/10, Loss: 0.4154067348241806\n",
            "Epoch 9/10, Loss: 0.4160913044214249\n",
            "Epoch 9/10, Loss: 0.4167897992134094\n",
            "Epoch 9/10, Loss: 0.4174828376173973\n",
            "Epoch 9/10, Loss: 0.4181808784008026\n",
            "Epoch 9/10, Loss: 0.4188710880279541\n",
            "Epoch 9/10, Loss: 0.41955666804313657\n",
            "Epoch 9/10, Loss: 0.42024628645181655\n",
            "Epoch 9/10, Loss: 0.4209418656229973\n",
            "Epoch 9/10, Loss: 0.4216417890191078\n",
            "Epoch 9/10, Loss: 0.42232758051157\n",
            "Epoch 9/10, Loss: 0.4230227163434029\n",
            "Epoch 9/10, Loss: 0.42369579952955244\n",
            "Epoch 9/10, Loss: 0.4243877359032631\n",
            "Epoch 9/10, Loss: 0.42507918846607207\n",
            "Epoch 9/10, Loss: 0.4257765427231789\n",
            "Epoch 9/10, Loss: 0.42646690756082534\n",
            "Epoch 9/10, Loss: 0.4271463777422905\n",
            "Epoch 9/10, Loss: 0.4278349772691727\n",
            "Epoch 9/10, Loss: 0.42852217680215837\n",
            "Epoch 9/10, Loss: 0.42921161264181135\n",
            "Epoch 9/10, Loss: 0.429910885155201\n",
            "Epoch 9/10, Loss: 0.4306003879904747\n",
            "Epoch 9/10, Loss: 0.4312851767539978\n",
            "Epoch 9/10, Loss: 0.43197412633895876\n",
            "Epoch 9/10, Loss: 0.4326687518954277\n",
            "Epoch 9/10, Loss: 0.43336919641494753\n",
            "Epoch 9/10, Loss: 0.43405173063278196\n",
            "Epoch 9/10, Loss: 0.4347526790499687\n",
            "Epoch 9/10, Loss: 0.4354401214122772\n",
            "Epoch 9/10, Loss: 0.436122047662735\n",
            "Epoch 9/10, Loss: 0.4368257895708084\n",
            "Epoch 9/10, Loss: 0.43752064764499665\n",
            "Epoch 9/10, Loss: 0.4382137677073479\n",
            "Epoch 9/10, Loss: 0.4388972007632256\n",
            "Epoch 9/10, Loss: 0.4395969782471657\n",
            "Epoch 9/10, Loss: 0.44029910731315614\n",
            "Epoch 9/10, Loss: 0.44098844027519224\n",
            "Epoch 9/10, Loss: 0.4416745554208755\n",
            "Epoch 9/10, Loss: 0.4423618129491806\n",
            "Epoch 9/10, Loss: 0.44304896783828734\n",
            "Epoch 9/10, Loss: 0.443734171807766\n",
            "Epoch 9/10, Loss: 0.44442988032102587\n",
            "Epoch 9/10, Loss: 0.4451182562112808\n",
            "Epoch 9/10, Loss: 0.44580090141296386\n",
            "Epoch 9/10, Loss: 0.4464863699674606\n",
            "Epoch 9/10, Loss: 0.44717382365465164\n",
            "Epoch 9/10, Loss: 0.44785947328805925\n",
            "Epoch 9/10, Loss: 0.44854617780447004\n",
            "Epoch 9/10, Loss: 0.4492396092414856\n",
            "Epoch 9/10, Loss: 0.44994854921102523\n",
            "Epoch 9/10, Loss: 0.4506407328248024\n",
            "Epoch 9/10, Loss: 0.4513385862708092\n",
            "Epoch 9/10, Loss: 0.4520348905920982\n",
            "Epoch 9/10, Loss: 0.45272616082429884\n",
            "Epoch 9/10, Loss: 0.45341974300146104\n",
            "Epoch 9/10, Loss: 0.4541092172861099\n",
            "Epoch 9/10, Loss: 0.45480112981796267\n",
            "Epoch 9/10, Loss: 0.4554978473186493\n",
            "Epoch 9/10, Loss: 0.45618684446811675\n",
            "Epoch 9/10, Loss: 0.45687475061416627\n",
            "Epoch 9/10, Loss: 0.45755177080631254\n",
            "Epoch 9/10, Loss: 0.4582398297190666\n",
            "Epoch 9/10, Loss: 0.4589387992024422\n",
            "Epoch 9/10, Loss: 0.4596257899403572\n",
            "Epoch 9/10, Loss: 0.4603148058652878\n",
            "Epoch 9/10, Loss: 0.4610114579200745\n",
            "Epoch 9/10, Loss: 0.46169650882482527\n",
            "Epoch 9/10, Loss: 0.4623765496015549\n",
            "Epoch 9/10, Loss: 0.4630564396381378\n",
            "Epoch 9/10, Loss: 0.46374584728479384\n",
            "Epoch 9/10, Loss: 0.4644324828982353\n",
            "Epoch 9/10, Loss: 0.46512262207269667\n",
            "Epoch 9/10, Loss: 0.4658033103346825\n",
            "Epoch 9/10, Loss: 0.4665012223124504\n",
            "Epoch 9/10, Loss: 0.46718668657541274\n",
            "Epoch 9/10, Loss: 0.4678848533034325\n",
            "Epoch 9/10, Loss: 0.46858505392074584\n",
            "Epoch 9/10, Loss: 0.469278490126133\n",
            "Epoch 9/10, Loss: 0.4699831367135048\n",
            "Epoch 9/10, Loss: 0.4706748564839363\n",
            "Epoch 9/10, Loss: 0.4713631448149681\n",
            "Epoch 9/10, Loss: 0.4720598710179329\n",
            "Epoch 9/10, Loss: 0.4727613602280617\n",
            "Epoch 9/10, Loss: 0.47346170169115065\n",
            "Epoch 9/10, Loss: 0.4741507673859596\n",
            "Epoch 9/10, Loss: 0.4748409477472305\n",
            "Epoch 9/10, Loss: 0.4755287024974823\n",
            "Epoch 9/10, Loss: 0.47622321665287015\n",
            "Epoch 9/10, Loss: 0.47692146331071855\n",
            "Epoch 9/10, Loss: 0.47761333709955217\n",
            "Epoch 9/10, Loss: 0.47830139952898026\n",
            "Epoch 9/10, Loss: 0.47898768419027327\n",
            "Epoch 9/10, Loss: 0.4796761121749878\n",
            "Epoch 9/10, Loss: 0.48036173325777054\n",
            "Epoch 9/10, Loss: 0.4810523064136505\n",
            "Epoch 9/10, Loss: 0.4817445095181465\n",
            "Epoch 9/10, Loss: 0.48243047934770583\n",
            "Epoch 9/10, Loss: 0.48312357676029205\n",
            "Epoch 9/10, Loss: 0.4838175164461136\n",
            "Epoch 9/10, Loss: 0.48451331341266635\n",
            "Epoch 9/10, Loss: 0.4852047605514526\n",
            "Epoch 9/10, Loss: 0.4858940260410309\n",
            "Epoch 9/10, Loss: 0.48658628296852113\n",
            "Epoch 9/10, Loss: 0.4872707469463348\n",
            "Epoch 9/10, Loss: 0.4879539099931717\n",
            "Epoch 9/10, Loss: 0.48864026153087614\n",
            "Epoch 9/10, Loss: 0.48934364938735964\n",
            "Epoch 9/10, Loss: 0.49003450870513915\n",
            "Epoch 9/10, Loss: 0.49071805536746976\n",
            "Epoch 9/10, Loss: 0.4914064066410065\n",
            "Epoch 9/10, Loss: 0.4920972979664803\n",
            "Epoch 9/10, Loss: 0.492788376390934\n",
            "Epoch 9/10, Loss: 0.4934608941674232\n",
            "Epoch 9/10, Loss: 0.4941530985236168\n",
            "Epoch 9/10, Loss: 0.49485192614793777\n",
            "Epoch 9/10, Loss: 0.49554480707645415\n",
            "Epoch 9/10, Loss: 0.49623517227172853\n",
            "Epoch 9/10, Loss: 0.49691941708326337\n",
            "Epoch 9/10, Loss: 0.4976191565990448\n",
            "Epoch 9/10, Loss: 0.4983066837787628\n",
            "Epoch 9/10, Loss: 0.49899751102924345\n",
            "Epoch 9/10, Loss: 0.49969359242916106\n",
            "Epoch 9/10, Loss: 0.5003913857936859\n",
            "Epoch 9/10, Loss: 0.5010789530873299\n",
            "Epoch 9/10, Loss: 0.5017753249406814\n",
            "Epoch 9/10, Loss: 0.5024609951972961\n",
            "Epoch 9/10, Loss: 0.5031538119316101\n",
            "Epoch 9/10, Loss: 0.5038530353307724\n",
            "Epoch 9/10, Loss: 0.5045531865954399\n",
            "Epoch 9/10, Loss: 0.5052513200640678\n",
            "Epoch 9/10, Loss: 0.5059429098367692\n",
            "Epoch 9/10, Loss: 0.5066347953081131\n",
            "Epoch 9/10, Loss: 0.5073153241872788\n",
            "Epoch 9/10, Loss: 0.5079953528046608\n",
            "Epoch 9/10, Loss: 0.5086835708618164\n",
            "Epoch 9/10, Loss: 0.5093753762245178\n",
            "Epoch 9/10, Loss: 0.510076121032238\n",
            "Epoch 9/10, Loss: 0.5107684590220452\n",
            "Epoch 9/10, Loss: 0.5114523832201958\n",
            "Epoch 9/10, Loss: 0.5121299508213997\n",
            "Epoch 9/10, Loss: 0.5128187888264656\n",
            "Epoch 9/10, Loss: 0.5135157599449157\n",
            "Epoch 9/10, Loss: 0.5142055017948151\n",
            "Epoch 9/10, Loss: 0.514893918454647\n",
            "Epoch 9/10, Loss: 0.5155796191692352\n",
            "Epoch 9/10, Loss: 0.5162790231704711\n",
            "Epoch 9/10, Loss: 0.5169585630893707\n",
            "Epoch 9/10, Loss: 0.5176531147956848\n",
            "Epoch 9/10, Loss: 0.5183560864329338\n",
            "Epoch 9/10, Loss: 0.519036117374897\n",
            "Epoch 9/10, Loss: 0.5197249320745468\n",
            "Epoch 9/10, Loss: 0.5204110498428345\n",
            "Epoch 9/10, Loss: 0.5211010853052139\n",
            "Epoch 9/10, Loss: 0.5217954357862472\n",
            "Epoch 9/10, Loss: 0.5224799213409423\n",
            "Epoch 9/10, Loss: 0.5231803941130638\n",
            "Epoch 9/10, Loss: 0.5238698006272317\n",
            "Epoch 9/10, Loss: 0.5245602595806121\n",
            "Epoch 9/10, Loss: 0.5252559876441956\n",
            "Epoch 9/10, Loss: 0.5259502853751182\n",
            "Epoch 9/10, Loss: 0.5266344981789589\n",
            "Epoch 9/10, Loss: 0.527323892056942\n",
            "Epoch 9/10, Loss: 0.5280086944699287\n",
            "Epoch 9/10, Loss: 0.5286931218504906\n",
            "Epoch 9/10, Loss: 0.5293912115693092\n",
            "Epoch 9/10, Loss: 0.5300832973718643\n",
            "Epoch 9/10, Loss: 0.5307642641067505\n",
            "Epoch 9/10, Loss: 0.5314546229839325\n",
            "Epoch 9/10, Loss: 0.5321486036777496\n",
            "Epoch 9/10, Loss: 0.532845143198967\n",
            "Epoch 9/10, Loss: 0.5335389480590821\n",
            "Epoch 9/10, Loss: 0.5342436367273331\n",
            "Epoch 9/10, Loss: 0.5349311080574989\n",
            "Epoch 9/10, Loss: 0.5356228493452072\n",
            "Epoch 9/10, Loss: 0.536312866449356\n",
            "Epoch 9/10, Loss: 0.5370178281664848\n",
            "Epoch 9/10, Loss: 0.5377070998549461\n",
            "Epoch 9/10, Loss: 0.5384063192009926\n",
            "Epoch 9/10, Loss: 0.5390964915156364\n",
            "Epoch 9/10, Loss: 0.5397734588980675\n",
            "Epoch 9/10, Loss: 0.54046284365654\n",
            "Epoch 9/10, Loss: 0.5411461094021797\n",
            "Epoch 9/10, Loss: 0.5418242513537407\n",
            "Epoch 9/10, Loss: 0.5425098637342453\n",
            "Epoch 9/10, Loss: 0.5431899169683456\n",
            "Epoch 9/10, Loss: 0.5438762690424919\n",
            "Epoch 9/10, Loss: 0.544558812379837\n",
            "Epoch 9/10, Loss: 0.5452427160739899\n",
            "Epoch 9/10, Loss: 0.5459203721284867\n",
            "Epoch 9/10, Loss: 0.5466036194562912\n",
            "Epoch 9/10, Loss: 0.5472916610836983\n",
            "Epoch 9/10, Loss: 0.5479878916740417\n",
            "Epoch 9/10, Loss: 0.5486716955900193\n",
            "Epoch 9/10, Loss: 0.5493507888317108\n",
            "Epoch 9/10, Loss: 0.5500393878221512\n",
            "Epoch 9/10, Loss: 0.5507146300673484\n",
            "Epoch 9/10, Loss: 0.5514149349331856\n",
            "Epoch 9/10, Loss: 0.5521033328175545\n",
            "Epoch 9/10, Loss: 0.5527905679345131\n",
            "Epoch 9/10, Loss: 0.5534894645810128\n",
            "Epoch 9/10, Loss: 0.5541682244539261\n",
            "Epoch 9/10, Loss: 0.5548632335066795\n",
            "Epoch 9/10, Loss: 0.5555569682717323\n",
            "Epoch 9/10, Loss: 0.5562436299920082\n",
            "Epoch 9/10, Loss: 0.5569327271580696\n",
            "Epoch 9/10, Loss: 0.5576210822463036\n",
            "Epoch 9/10, Loss: 0.5583038334846496\n",
            "Epoch 9/10, Loss: 0.5590091397762299\n",
            "Epoch 9/10, Loss: 0.5596989843845367\n",
            "Epoch 9/10, Loss: 0.5603911828994751\n",
            "Epoch 9/10, Loss: 0.5610815723538398\n",
            "Epoch 9/10, Loss: 0.5617780629992485\n",
            "Epoch 9/10, Loss: 0.5624722911715507\n",
            "Epoch 9/10, Loss: 0.5631613488793373\n",
            "Epoch 9/10, Loss: 0.5638324157595634\n",
            "Epoch 9/10, Loss: 0.5645355223417282\n",
            "Epoch 9/10, Loss: 0.5652357355356217\n",
            "Epoch 9/10, Loss: 0.5659207884073257\n",
            "Epoch 9/10, Loss: 0.5666133862733841\n",
            "Epoch 9/10, Loss: 0.5673029222488404\n",
            "Epoch 9/10, Loss: 0.5679853420257568\n",
            "Epoch 9/10, Loss: 0.5686645441651345\n",
            "Epoch 9/10, Loss: 0.569351839363575\n",
            "Epoch 9/10, Loss: 0.5700397413969039\n",
            "Epoch 9/10, Loss: 0.5707298557758331\n",
            "Epoch 9/10, Loss: 0.5714151542782784\n",
            "Epoch 9/10, Loss: 0.5721005758643151\n",
            "Epoch 9/10, Loss: 0.5727961230874061\n",
            "Epoch 9/10, Loss: 0.573484768629074\n",
            "Epoch 9/10, Loss: 0.574177985906601\n",
            "Epoch 9/10, Loss: 0.5748646379709244\n",
            "Epoch 9/10, Loss: 0.575558837890625\n",
            "Epoch 9/10, Loss: 0.5762456753849983\n",
            "Epoch 9/10, Loss: 0.5769444043040276\n",
            "Epoch 9/10, Loss: 0.5776311348080635\n",
            "Epoch 9/10, Loss: 0.5783230500817299\n",
            "Epoch 9/10, Loss: 0.5790087773799896\n",
            "Epoch 9/10, Loss: 0.5797078084349633\n",
            "Epoch 9/10, Loss: 0.5803992587327957\n",
            "Epoch 9/10, Loss: 0.5810903116464615\n",
            "Epoch 9/10, Loss: 0.5817769792079925\n",
            "Epoch 9/10, Loss: 0.5824575535655022\n",
            "Epoch 9/10, Loss: 0.5831327642798424\n",
            "Epoch 9/10, Loss: 0.5838357090950013\n",
            "Epoch 9/10, Loss: 0.5845299846529961\n",
            "Epoch 9/10, Loss: 0.5852315337657928\n",
            "Epoch 9/10, Loss: 0.5859243474006652\n",
            "Epoch 9/10, Loss: 0.5866062693595886\n",
            "Epoch 9/10, Loss: 0.5872996727228165\n",
            "Epoch 9/10, Loss: 0.58798963201046\n",
            "Epoch 9/10, Loss: 0.5886813027858734\n",
            "Epoch 9/10, Loss: 0.5893688985109329\n",
            "Epoch 9/10, Loss: 0.5900425530672073\n",
            "Epoch 9/10, Loss: 0.5907266982793808\n",
            "Epoch 9/10, Loss: 0.5914156118035316\n",
            "Epoch 9/10, Loss: 0.592092090845108\n",
            "Epoch 9/10, Loss: 0.592777686715126\n",
            "Epoch 9/10, Loss: 0.593453957080841\n",
            "Epoch 9/10, Loss: 0.5941349192857742\n",
            "Epoch 9/10, Loss: 0.5948256040811539\n",
            "Epoch 9/10, Loss: 0.5955257440805435\n",
            "Epoch 9/10, Loss: 0.5962051680088043\n",
            "Epoch 9/10, Loss: 0.5968963251113891\n",
            "Epoch 9/10, Loss: 0.5975757663846016\n",
            "Epoch 9/10, Loss: 0.5982571725845337\n",
            "Epoch 9/10, Loss: 0.5989515060186386\n",
            "Epoch 9/10, Loss: 0.5996493124365807\n",
            "Epoch 9/10, Loss: 0.6003487510085106\n",
            "Epoch 9/10, Loss: 0.6010360540747642\n",
            "Epoch 9/10, Loss: 0.6017173429131508\n",
            "Epoch 9/10, Loss: 0.6024127873778343\n",
            "Epoch 9/10, Loss: 0.6031037116646767\n",
            "Epoch 9/10, Loss: 0.6037951384782791\n",
            "Epoch 9/10, Loss: 0.6044829921722412\n",
            "Epoch 9/10, Loss: 0.6051655745506287\n",
            "Epoch 9/10, Loss: 0.6058548487424851\n",
            "Epoch 9/10, Loss: 0.6065385470986366\n",
            "Epoch 9/10, Loss: 0.6072187339663505\n",
            "Epoch 9/10, Loss: 0.6079125519990921\n",
            "Epoch 9/10, Loss: 0.608602483510971\n",
            "Epoch 9/10, Loss: 0.6092933216094971\n",
            "Epoch 9/10, Loss: 0.6099860075116158\n",
            "Epoch 9/10, Loss: 0.6106721774339676\n",
            "Epoch 9/10, Loss: 0.6113586819171906\n",
            "Epoch 9/10, Loss: 0.6120388312935829\n",
            "Epoch 9/10, Loss: 0.6127269363999367\n",
            "Epoch 9/10, Loss: 0.6134167773127556\n",
            "Epoch 9/10, Loss: 0.6141108132004738\n",
            "Epoch 9/10, Loss: 0.6148090969920158\n",
            "Epoch 9/10, Loss: 0.6154875927567482\n",
            "Epoch 9/10, Loss: 0.6161782537698746\n",
            "Epoch 9/10, Loss: 0.616849204659462\n",
            "Epoch 9/10, Loss: 0.6175308941602707\n",
            "Epoch 9/10, Loss: 0.6182202432751656\n",
            "Epoch 9/10, Loss: 0.6189104183912277\n",
            "Epoch 9/10, Loss: 0.6196012995243072\n",
            "Epoch 9/10, Loss: 0.6202935712337494\n",
            "Epoch 9/10, Loss: 0.6209864798784256\n",
            "Epoch 9/10, Loss: 0.6216760271787644\n",
            "Epoch 9/10, Loss: 0.6223616725206376\n",
            "Epoch 9/10, Loss: 0.6230522436499596\n",
            "Epoch 9/10, Loss: 0.6237483021616935\n",
            "Epoch 9/10, Loss: 0.624433703482151\n",
            "Epoch 9/10, Loss: 0.6251151262521744\n",
            "Epoch 9/10, Loss: 0.6258012298345565\n",
            "Epoch 9/10, Loss: 0.6264917727708816\n",
            "Epoch 9/10, Loss: 0.6271746791601182\n",
            "Epoch 9/10, Loss: 0.6278573473095894\n",
            "Epoch 9/10, Loss: 0.6285510727763176\n",
            "Epoch 9/10, Loss: 0.6292386735081673\n",
            "Epoch 9/10, Loss: 0.6299236269593239\n",
            "Epoch 9/10, Loss: 0.6306153408288956\n",
            "Epoch 9/10, Loss: 0.6313094493746757\n",
            "Epoch 9/10, Loss: 0.6320024829506874\n",
            "Epoch 9/10, Loss: 0.6326880630850792\n",
            "Epoch 9/10, Loss: 0.6333805810213089\n",
            "Epoch 9/10, Loss: 0.634068747997284\n",
            "Epoch 9/10, Loss: 0.6347493237257004\n",
            "Epoch 9/10, Loss: 0.6354416155815125\n",
            "Epoch 9/10, Loss: 0.6361440420746803\n",
            "Epoch 9/10, Loss: 0.6368226820230484\n",
            "Epoch 9/10, Loss: 0.637518003821373\n",
            "Epoch 9/10, Loss: 0.6381959252357483\n",
            "Epoch 9/10, Loss: 0.6388876761198043\n",
            "Epoch 9/10, Loss: 0.6395641223192216\n",
            "Epoch 9/10, Loss: 0.6402565942406654\n",
            "Epoch 9/10, Loss: 0.6409459801316262\n",
            "Epoch 9/10, Loss: 0.6416457368731499\n",
            "Epoch 9/10, Loss: 0.642338573038578\n",
            "Epoch 9/10, Loss: 0.6430240827202797\n",
            "Epoch 9/10, Loss: 0.6436998980045319\n",
            "Epoch 9/10, Loss: 0.6443865265846253\n",
            "Epoch 9/10, Loss: 0.6450726758241654\n",
            "Epoch 9/10, Loss: 0.6457697530388832\n",
            "Epoch 9/10, Loss: 0.6464612599611282\n",
            "Epoch 9/10, Loss: 0.6471497309803963\n",
            "Epoch 9/10, Loss: 0.6478514411449432\n",
            "Epoch 9/10, Loss: 0.6485493337512016\n",
            "Epoch 9/10, Loss: 0.6492308917641639\n",
            "Epoch 9/10, Loss: 0.649914424777031\n",
            "Epoch 9/10, Loss: 0.6505998212099076\n",
            "Epoch 9/10, Loss: 0.6512912204265594\n",
            "Epoch 9/10, Loss: 0.6519823675155639\n",
            "Epoch 9/10, Loss: 0.6526505632996559\n",
            "Epoch 9/10, Loss: 0.6533346801400185\n",
            "Epoch 9/10, Loss: 0.6540235833525657\n",
            "Epoch 9/10, Loss: 0.6547189849615097\n",
            "Epoch 9/10, Loss: 0.6554246785640716\n",
            "Epoch 9/10, Loss: 0.6561154340505599\n",
            "Epoch 9/10, Loss: 0.6568169072270393\n",
            "Epoch 9/10, Loss: 0.6575127124786377\n",
            "Epoch 9/10, Loss: 0.6582049996852875\n",
            "Epoch 9/10, Loss: 0.6588939643502235\n",
            "Epoch 9/10, Loss: 0.6595775296092034\n",
            "Epoch 9/10, Loss: 0.6602683660984039\n",
            "Epoch 9/10, Loss: 0.660956186234951\n",
            "Epoch 9/10, Loss: 0.6616459415555\n",
            "Epoch 9/10, Loss: 0.6623448917865753\n",
            "Epoch 9/10, Loss: 0.6630311066508293\n",
            "Epoch 9/10, Loss: 0.6637242158055305\n",
            "Epoch 9/10, Loss: 0.6644184023737908\n",
            "Epoch 9/10, Loss: 0.6651097058653831\n",
            "Epoch 9/10, Loss: 0.6658026654124259\n",
            "Epoch 9/10, Loss: 0.6665015563368797\n",
            "Epoch 9/10, Loss: 0.6671942726373673\n",
            "Epoch 9/10, Loss: 0.6678872878551483\n",
            "Epoch 9/10, Loss: 0.6685833758115769\n",
            "Epoch 9/10, Loss: 0.6692770686745644\n",
            "Epoch 9/10, Loss: 0.6699660153985023\n",
            "Epoch 9/10, Loss: 0.6706550522446633\n",
            "Epoch 9/10, Loss: 0.6713393453955651\n",
            "Epoch 9/10, Loss: 0.6720245891213417\n",
            "Epoch 9/10, Loss: 0.6727192452549935\n",
            "Epoch 9/10, Loss: 0.673415890455246\n",
            "Epoch 9/10, Loss: 0.6741017816066742\n",
            "Epoch 9/10, Loss: 0.6747895374298095\n",
            "Epoch 9/10, Loss: 0.675479659974575\n",
            "Epoch 9/10, Loss: 0.676183698117733\n",
            "Epoch 9/10, Loss: 0.6768878158926964\n",
            "Epoch 9/10, Loss: 0.6775694324374198\n",
            "Epoch 9/10, Loss: 0.6782672410011291\n",
            "Epoch 9/10, Loss: 0.6789559947252274\n",
            "Epoch 9/10, Loss: 0.6796382250785827\n",
            "Epoch 9/10, Loss: 0.6803435832262039\n",
            "Epoch 9/10, Loss: 0.6810414632558822\n",
            "Epoch 9/10, Loss: 0.6817213507294655\n",
            "Epoch 9/10, Loss: 0.682412708580494\n",
            "Epoch 9/10, Loss: 0.6831094952225685\n",
            "Epoch 9/10, Loss: 0.6838298437595367\n",
            "Epoch 9/10, Loss: 0.6845082861185073\n",
            "Epoch 9/10, Loss: 0.6852028369903564\n",
            "Epoch 9/10, Loss: 0.6858968950510025\n",
            "Epoch 9/10, Loss: 0.6865969254970551\n",
            "Epoch 9/10, Loss: 0.6872833666801452\n",
            "Epoch 9/10, Loss: 0.6879710381031037\n",
            "Epoch 9/10, Loss: 0.6886723289489746\n",
            "Epoch 9/10, Loss: 0.6893683439493179\n",
            "Epoch 9/10, Loss: 0.6900596840977669\n",
            "Epoch 10/10, Loss: 0.0006933904886245728\n",
            "Epoch 10/10, Loss: 0.0013854921460151673\n",
            "Epoch 10/10, Loss: 0.0020769737362861633\n",
            "Epoch 10/10, Loss: 0.002771458089351654\n",
            "Epoch 10/10, Loss: 0.0034589183330535887\n",
            "Epoch 10/10, Loss: 0.004151829779148102\n",
            "Epoch 10/10, Loss: 0.004831142485141754\n",
            "Epoch 10/10, Loss: 0.0055248354077339175\n",
            "Epoch 10/10, Loss: 0.006208377003669739\n",
            "Epoch 10/10, Loss: 0.0068899840712547305\n",
            "Epoch 10/10, Loss: 0.007577561199665069\n",
            "Epoch 10/10, Loss: 0.008256412208080292\n",
            "Epoch 10/10, Loss: 0.008937930047512055\n",
            "Epoch 10/10, Loss: 0.009632054030895234\n",
            "Epoch 10/10, Loss: 0.010321901679039002\n",
            "Epoch 10/10, Loss: 0.011020039021968842\n",
            "Epoch 10/10, Loss: 0.011719793260097503\n",
            "Epoch 10/10, Loss: 0.012393169820308685\n",
            "Epoch 10/10, Loss: 0.013090137660503388\n",
            "Epoch 10/10, Loss: 0.01377900665998459\n",
            "Epoch 10/10, Loss: 0.014472216188907623\n",
            "Epoch 10/10, Loss: 0.01516120195388794\n",
            "Epoch 10/10, Loss: 0.015854133665561675\n",
            "Epoch 10/10, Loss: 0.016542068421840667\n",
            "Epoch 10/10, Loss: 0.01721807712316513\n",
            "Epoch 10/10, Loss: 0.01788698625564575\n",
            "Epoch 10/10, Loss: 0.018577218413352966\n",
            "Epoch 10/10, Loss: 0.019270667910575866\n",
            "Epoch 10/10, Loss: 0.01996566069126129\n",
            "Epoch 10/10, Loss: 0.020655288815498354\n",
            "Epoch 10/10, Loss: 0.021339155673980714\n",
            "Epoch 10/10, Loss: 0.02203130751848221\n",
            "Epoch 10/10, Loss: 0.022729392230510712\n",
            "Epoch 10/10, Loss: 0.023424212157726287\n",
            "Epoch 10/10, Loss: 0.024128844559192657\n",
            "Epoch 10/10, Loss: 0.024811616957187654\n",
            "Epoch 10/10, Loss: 0.025506597280502318\n",
            "Epoch 10/10, Loss: 0.026191311717033386\n",
            "Epoch 10/10, Loss: 0.026869426786899568\n",
            "Epoch 10/10, Loss: 0.02755772227048874\n",
            "Epoch 10/10, Loss: 0.02825201064348221\n",
            "Epoch 10/10, Loss: 0.02893343061208725\n",
            "Epoch 10/10, Loss: 0.02962957090139389\n",
            "Epoch 10/10, Loss: 0.030330152571201325\n",
            "Epoch 10/10, Loss: 0.031024534046649933\n",
            "Epoch 10/10, Loss: 0.031708304941654206\n",
            "Epoch 10/10, Loss: 0.0324001767039299\n",
            "Epoch 10/10, Loss: 0.03308913463354111\n",
            "Epoch 10/10, Loss: 0.03379254370927811\n",
            "Epoch 10/10, Loss: 0.03448447424173355\n",
            "Epoch 10/10, Loss: 0.035182558238506315\n",
            "Epoch 10/10, Loss: 0.03585960465669632\n",
            "Epoch 10/10, Loss: 0.036556545913219454\n",
            "Epoch 10/10, Loss: 0.03724304962158203\n",
            "Epoch 10/10, Loss: 0.037933077931404116\n",
            "Epoch 10/10, Loss: 0.038631112813949584\n",
            "Epoch 10/10, Loss: 0.039326261401176454\n",
            "Epoch 10/10, Loss: 0.040010249614715575\n",
            "Epoch 10/10, Loss: 0.04070855420827866\n",
            "Epoch 10/10, Loss: 0.04139198237657547\n",
            "Epoch 10/10, Loss: 0.04207640355825424\n",
            "Epoch 10/10, Loss: 0.042765236854553225\n",
            "Epoch 10/10, Loss: 0.04345058572292328\n",
            "Epoch 10/10, Loss: 0.04415313798189163\n",
            "Epoch 10/10, Loss: 0.04484134912490845\n",
            "Epoch 10/10, Loss: 0.04552939003705978\n",
            "Epoch 10/10, Loss: 0.046222059190273286\n",
            "Epoch 10/10, Loss: 0.0469132609963417\n",
            "Epoch 10/10, Loss: 0.047615631759166714\n",
            "Epoch 10/10, Loss: 0.04831747078895569\n",
            "Epoch 10/10, Loss: 0.04901061457395554\n",
            "Epoch 10/10, Loss: 0.04970073038339615\n",
            "Epoch 10/10, Loss: 0.050385414719581606\n",
            "Epoch 10/10, Loss: 0.05107582664489746\n",
            "Epoch 10/10, Loss: 0.0517664298415184\n",
            "Epoch 10/10, Loss: 0.05245448249578476\n",
            "Epoch 10/10, Loss: 0.053154489815235136\n",
            "Epoch 10/10, Loss: 0.05384669351577759\n",
            "Epoch 10/10, Loss: 0.05453502482175827\n",
            "Epoch 10/10, Loss: 0.0552237805724144\n",
            "Epoch 10/10, Loss: 0.05590955239534378\n",
            "Epoch 10/10, Loss: 0.05658742928504944\n",
            "Epoch 10/10, Loss: 0.05727450740337372\n",
            "Epoch 10/10, Loss: 0.05796993464231491\n",
            "Epoch 10/10, Loss: 0.05864940696954727\n",
            "Epoch 10/10, Loss: 0.059337604522705076\n",
            "Epoch 10/10, Loss: 0.06002982884645462\n",
            "Epoch 10/10, Loss: 0.060721346735954286\n",
            "Epoch 10/10, Loss: 0.061410216331481936\n",
            "Epoch 10/10, Loss: 0.062090921878814695\n",
            "Epoch 10/10, Loss: 0.0627807000875473\n",
            "Epoch 10/10, Loss: 0.06346771860122681\n",
            "Epoch 10/10, Loss: 0.06416133749485016\n",
            "Epoch 10/10, Loss: 0.06485890758037567\n",
            "Epoch 10/10, Loss: 0.06554535722732543\n",
            "Epoch 10/10, Loss: 0.06622801876068116\n",
            "Epoch 10/10, Loss: 0.06691291522979737\n",
            "Epoch 10/10, Loss: 0.06759230613708496\n",
            "Epoch 10/10, Loss: 0.06827833473682404\n",
            "Epoch 10/10, Loss: 0.06897423195838928\n",
            "Epoch 10/10, Loss: 0.06966295504570007\n",
            "Epoch 10/10, Loss: 0.0703458098769188\n",
            "Epoch 10/10, Loss: 0.07102951580286027\n",
            "Epoch 10/10, Loss: 0.07171762675046921\n",
            "Epoch 10/10, Loss: 0.07240818107128143\n",
            "Epoch 10/10, Loss: 0.07308489054441453\n",
            "Epoch 10/10, Loss: 0.07377525639533997\n",
            "Epoch 10/10, Loss: 0.0744655836224556\n",
            "Epoch 10/10, Loss: 0.075155129134655\n",
            "Epoch 10/10, Loss: 0.0758438658118248\n",
            "Epoch 10/10, Loss: 0.07652462190389633\n",
            "Epoch 10/10, Loss: 0.07721381223201752\n",
            "Epoch 10/10, Loss: 0.07790588885545731\n",
            "Epoch 10/10, Loss: 0.07859128391742706\n",
            "Epoch 10/10, Loss: 0.07927594554424286\n",
            "Epoch 10/10, Loss: 0.07997955530881881\n",
            "Epoch 10/10, Loss: 0.08066055470705033\n",
            "Epoch 10/10, Loss: 0.08135116326808929\n",
            "Epoch 10/10, Loss: 0.08203480470180512\n",
            "Epoch 10/10, Loss: 0.08272113382816315\n",
            "Epoch 10/10, Loss: 0.08340415799617767\n",
            "Epoch 10/10, Loss: 0.0840884788632393\n",
            "Epoch 10/10, Loss: 0.08477088892459869\n",
            "Epoch 10/10, Loss: 0.08547006857395172\n",
            "Epoch 10/10, Loss: 0.0861549242734909\n",
            "Epoch 10/10, Loss: 0.08684724223613739\n",
            "Epoch 10/10, Loss: 0.08754763233661651\n",
            "Epoch 10/10, Loss: 0.08824157154560089\n",
            "Epoch 10/10, Loss: 0.08893702137470245\n",
            "Epoch 10/10, Loss: 0.08962636876106263\n",
            "Epoch 10/10, Loss: 0.09032118874788285\n",
            "Epoch 10/10, Loss: 0.09100414365530014\n",
            "Epoch 10/10, Loss: 0.09169061303138733\n",
            "Epoch 10/10, Loss: 0.0923813950419426\n",
            "Epoch 10/10, Loss: 0.09305442637205123\n",
            "Epoch 10/10, Loss: 0.09373676139116287\n",
            "Epoch 10/10, Loss: 0.09442947453260422\n",
            "Epoch 10/10, Loss: 0.09511417585611344\n",
            "Epoch 10/10, Loss: 0.09580067670345306\n",
            "Epoch 10/10, Loss: 0.09649906349182129\n",
            "Epoch 10/10, Loss: 0.09719183659553528\n",
            "Epoch 10/10, Loss: 0.09788229286670685\n",
            "Epoch 10/10, Loss: 0.09857505702972412\n",
            "Epoch 10/10, Loss: 0.09927687835693359\n",
            "Epoch 10/10, Loss: 0.09996367955207824\n",
            "Epoch 10/10, Loss: 0.10066065895557404\n",
            "Epoch 10/10, Loss: 0.10135622632503509\n",
            "Epoch 10/10, Loss: 0.10205747151374817\n",
            "Epoch 10/10, Loss: 0.10274077880382537\n",
            "Epoch 10/10, Loss: 0.10341613638401032\n",
            "Epoch 10/10, Loss: 0.10410474914312362\n",
            "Epoch 10/10, Loss: 0.10479075878858567\n",
            "Epoch 10/10, Loss: 0.10548281437158584\n",
            "Epoch 10/10, Loss: 0.10616618114709854\n",
            "Epoch 10/10, Loss: 0.10685098934173584\n",
            "Epoch 10/10, Loss: 0.10752871209383011\n",
            "Epoch 10/10, Loss: 0.10821413958072662\n",
            "Epoch 10/10, Loss: 0.10889943957328796\n",
            "Epoch 10/10, Loss: 0.10958384954929352\n",
            "Epoch 10/10, Loss: 0.11026485216617585\n",
            "Epoch 10/10, Loss: 0.11094948798418044\n",
            "Epoch 10/10, Loss: 0.11164467829465866\n",
            "Epoch 10/10, Loss: 0.11233194291591644\n",
            "Epoch 10/10, Loss: 0.11302724808454513\n",
            "Epoch 10/10, Loss: 0.11370871675014496\n",
            "Epoch 10/10, Loss: 0.1143920361995697\n",
            "Epoch 10/10, Loss: 0.11508641213178634\n",
            "Epoch 10/10, Loss: 0.11577730649709701\n",
            "Epoch 10/10, Loss: 0.1164690346121788\n",
            "Epoch 10/10, Loss: 0.11716235417127609\n",
            "Epoch 10/10, Loss: 0.1178561881184578\n",
            "Epoch 10/10, Loss: 0.11853902512788772\n",
            "Epoch 10/10, Loss: 0.11922704666852951\n",
            "Epoch 10/10, Loss: 0.11992179542779922\n",
            "Epoch 10/10, Loss: 0.12062791162729264\n",
            "Epoch 10/10, Loss: 0.1213208321928978\n",
            "Epoch 10/10, Loss: 0.12199800145626068\n",
            "Epoch 10/10, Loss: 0.12268438160419465\n",
            "Epoch 10/10, Loss: 0.12337428045272827\n",
            "Epoch 10/10, Loss: 0.12406592106819153\n",
            "Epoch 10/10, Loss: 0.12476284968852996\n",
            "Epoch 10/10, Loss: 0.12544431096315384\n",
            "Epoch 10/10, Loss: 0.12613305687904358\n",
            "Epoch 10/10, Loss: 0.12682788306474685\n",
            "Epoch 10/10, Loss: 0.12751152616739272\n",
            "Epoch 10/10, Loss: 0.12821000343561173\n",
            "Epoch 10/10, Loss: 0.128899942278862\n",
            "Epoch 10/10, Loss: 0.12958950209617615\n",
            "Epoch 10/10, Loss: 0.13027416563034058\n",
            "Epoch 10/10, Loss: 0.13095505905151367\n",
            "Epoch 10/10, Loss: 0.1316440839767456\n",
            "Epoch 10/10, Loss: 0.13233779388666153\n",
            "Epoch 10/10, Loss: 0.13302290219068527\n",
            "Epoch 10/10, Loss: 0.1337163591980934\n",
            "Epoch 10/10, Loss: 0.13438895338773726\n",
            "Epoch 10/10, Loss: 0.13507595056295396\n",
            "Epoch 10/10, Loss: 0.13576688343286514\n",
            "Epoch 10/10, Loss: 0.1364570151567459\n",
            "Epoch 10/10, Loss: 0.1371435930132866\n",
            "Epoch 10/10, Loss: 0.13782195085287094\n",
            "Epoch 10/10, Loss: 0.13850396543741225\n",
            "Epoch 10/10, Loss: 0.13919915598630905\n",
            "Epoch 10/10, Loss: 0.13989499139785766\n",
            "Epoch 10/10, Loss: 0.14058088648319245\n",
            "Epoch 10/10, Loss: 0.14127555745840073\n",
            "Epoch 10/10, Loss: 0.141973027408123\n",
            "Epoch 10/10, Loss: 0.14266259640455245\n",
            "Epoch 10/10, Loss: 0.14335359805822373\n",
            "Epoch 10/10, Loss: 0.1440351140499115\n",
            "Epoch 10/10, Loss: 0.1447242213487625\n",
            "Epoch 10/10, Loss: 0.14542690229415894\n",
            "Epoch 10/10, Loss: 0.14611706203222274\n",
            "Epoch 10/10, Loss: 0.14680406653881073\n",
            "Epoch 10/10, Loss: 0.14749730253219603\n",
            "Epoch 10/10, Loss: 0.14818098425865173\n",
            "Epoch 10/10, Loss: 0.1488746408224106\n",
            "Epoch 10/10, Loss: 0.14955742084980012\n",
            "Epoch 10/10, Loss: 0.1502458271384239\n",
            "Epoch 10/10, Loss: 0.1509239644408226\n",
            "Epoch 10/10, Loss: 0.15162002152204512\n",
            "Epoch 10/10, Loss: 0.15231796890497207\n",
            "Epoch 10/10, Loss: 0.15301369887590408\n",
            "Epoch 10/10, Loss: 0.15369705003499984\n",
            "Epoch 10/10, Loss: 0.15438974112272263\n",
            "Epoch 10/10, Loss: 0.15507216757535935\n",
            "Epoch 10/10, Loss: 0.15575764662027358\n",
            "Epoch 10/10, Loss: 0.1564464015364647\n",
            "Epoch 10/10, Loss: 0.15713654232025145\n",
            "Epoch 10/10, Loss: 0.15782470846176147\n",
            "Epoch 10/10, Loss: 0.1585109537243843\n",
            "Epoch 10/10, Loss: 0.15919464695453645\n",
            "Epoch 10/10, Loss: 0.15988279801607133\n",
            "Epoch 10/10, Loss: 0.16057977855205535\n",
            "Epoch 10/10, Loss: 0.16127322375774383\n",
            "Epoch 10/10, Loss: 0.16196821433305741\n",
            "Epoch 10/10, Loss: 0.1626597101688385\n",
            "Epoch 10/10, Loss: 0.16334861987829208\n",
            "Epoch 10/10, Loss: 0.1640318210721016\n",
            "Epoch 10/10, Loss: 0.1647150669693947\n",
            "Epoch 10/10, Loss: 0.1654113366007805\n",
            "Epoch 10/10, Loss: 0.16609972780942917\n",
            "Epoch 10/10, Loss: 0.16680154317617416\n",
            "Epoch 10/10, Loss: 0.16749480217695237\n",
            "Epoch 10/10, Loss: 0.16818634331226348\n",
            "Epoch 10/10, Loss: 0.168879527926445\n",
            "Epoch 10/10, Loss: 0.16956360131502152\n",
            "Epoch 10/10, Loss: 0.17025412541627885\n",
            "Epoch 10/10, Loss: 0.17093372815847396\n",
            "Epoch 10/10, Loss: 0.17162575000524521\n",
            "Epoch 10/10, Loss: 0.17232171285152437\n",
            "Epoch 10/10, Loss: 0.17299449610710144\n",
            "Epoch 10/10, Loss: 0.1736848874092102\n",
            "Epoch 10/10, Loss: 0.17437444406747818\n",
            "Epoch 10/10, Loss: 0.1750608707666397\n",
            "Epoch 10/10, Loss: 0.17575352054834364\n",
            "Epoch 10/10, Loss: 0.1764521750807762\n",
            "Epoch 10/10, Loss: 0.17713689237833022\n",
            "Epoch 10/10, Loss: 0.1778277811408043\n",
            "Epoch 10/10, Loss: 0.1785212716460228\n",
            "Epoch 10/10, Loss: 0.17921069926023483\n",
            "Epoch 10/10, Loss: 0.1799084692597389\n",
            "Epoch 10/10, Loss: 0.1805904524922371\n",
            "Epoch 10/10, Loss: 0.18128183728456498\n",
            "Epoch 10/10, Loss: 0.1819689237475395\n",
            "Epoch 10/10, Loss: 0.1826558240056038\n",
            "Epoch 10/10, Loss: 0.18334147995710373\n",
            "Epoch 10/10, Loss: 0.18404875022172928\n",
            "Epoch 10/10, Loss: 0.18475739812850953\n",
            "Epoch 10/10, Loss: 0.18545757800340654\n",
            "Epoch 10/10, Loss: 0.1861469802260399\n",
            "Epoch 10/10, Loss: 0.18684643131494522\n",
            "Epoch 10/10, Loss: 0.1875366606116295\n",
            "Epoch 10/10, Loss: 0.18821972984075547\n",
            "Epoch 10/10, Loss: 0.18890871852636337\n",
            "Epoch 10/10, Loss: 0.18959502190351485\n",
            "Epoch 10/10, Loss: 0.19029878664016725\n",
            "Epoch 10/10, Loss: 0.19099905180931093\n",
            "Epoch 10/10, Loss: 0.1916817239522934\n",
            "Epoch 10/10, Loss: 0.19236151647567748\n",
            "Epoch 10/10, Loss: 0.19306198048591613\n",
            "Epoch 10/10, Loss: 0.19375242340564727\n",
            "Epoch 10/10, Loss: 0.19443772685527802\n",
            "Epoch 10/10, Loss: 0.1951191908121109\n",
            "Epoch 10/10, Loss: 0.19580655169487\n",
            "Epoch 10/10, Loss: 0.19650314080715178\n",
            "Epoch 10/10, Loss: 0.19719210183620453\n",
            "Epoch 10/10, Loss: 0.19787960028648377\n",
            "Epoch 10/10, Loss: 0.19856964635849\n",
            "Epoch 10/10, Loss: 0.19925031381845473\n",
            "Epoch 10/10, Loss: 0.19994694954156875\n",
            "Epoch 10/10, Loss: 0.2006389188170433\n",
            "Epoch 10/10, Loss: 0.20133119583129883\n",
            "Epoch 10/10, Loss: 0.20201041996479036\n",
            "Epoch 10/10, Loss: 0.20271159321069718\n",
            "Epoch 10/10, Loss: 0.2034023079276085\n",
            "Epoch 10/10, Loss: 0.20410487008094788\n",
            "Epoch 10/10, Loss: 0.20481543922424317\n",
            "Epoch 10/10, Loss: 0.20549971264600753\n",
            "Epoch 10/10, Loss: 0.20618695420026778\n",
            "Epoch 10/10, Loss: 0.20687990242242812\n",
            "Epoch 10/10, Loss: 0.20756902462244034\n",
            "Epoch 10/10, Loss: 0.2082491256594658\n",
            "Epoch 10/10, Loss: 0.20894743764400484\n",
            "Epoch 10/10, Loss: 0.2096384853720665\n",
            "Epoch 10/10, Loss: 0.21033287197351455\n",
            "Epoch 10/10, Loss: 0.21102438259124756\n",
            "Epoch 10/10, Loss: 0.21171053087711333\n",
            "Epoch 10/10, Loss: 0.21239697682857514\n",
            "Epoch 10/10, Loss: 0.21307678318023682\n",
            "Epoch 10/10, Loss: 0.21376772552728654\n",
            "Epoch 10/10, Loss: 0.2144599546790123\n",
            "Epoch 10/10, Loss: 0.21515349453687668\n",
            "Epoch 10/10, Loss: 0.2158443303704262\n",
            "Epoch 10/10, Loss: 0.21653255742788316\n",
            "Epoch 10/10, Loss: 0.21721898931264877\n",
            "Epoch 10/10, Loss: 0.21790828549861907\n",
            "Epoch 10/10, Loss: 0.21860238581895827\n",
            "Epoch 10/10, Loss: 0.21928458040952684\n",
            "Epoch 10/10, Loss: 0.2199780604839325\n",
            "Epoch 10/10, Loss: 0.2206652809381485\n",
            "Epoch 10/10, Loss: 0.22135236656665802\n",
            "Epoch 10/10, Loss: 0.22204429852962493\n",
            "Epoch 10/10, Loss: 0.2227360575199127\n",
            "Epoch 10/10, Loss: 0.22342414569854735\n",
            "Epoch 10/10, Loss: 0.22411637049913408\n",
            "Epoch 10/10, Loss: 0.224800534427166\n",
            "Epoch 10/10, Loss: 0.2254956311583519\n",
            "Epoch 10/10, Loss: 0.2261819723844528\n",
            "Epoch 10/10, Loss: 0.2268591924905777\n",
            "Epoch 10/10, Loss: 0.22755622351169585\n",
            "Epoch 10/10, Loss: 0.22823083579540251\n",
            "Epoch 10/10, Loss: 0.22891886687278748\n",
            "Epoch 10/10, Loss: 0.22961416590213776\n",
            "Epoch 10/10, Loss: 0.23030207479000092\n",
            "Epoch 10/10, Loss: 0.2309906632900238\n",
            "Epoch 10/10, Loss: 0.23166792196035385\n",
            "Epoch 10/10, Loss: 0.2323539150953293\n",
            "Epoch 10/10, Loss: 0.23305017268657685\n",
            "Epoch 10/10, Loss: 0.23374724036455155\n",
            "Epoch 10/10, Loss: 0.23442980808019637\n",
            "Epoch 10/10, Loss: 0.23511004745960234\n",
            "Epoch 10/10, Loss: 0.23580322909355164\n",
            "Epoch 10/10, Loss: 0.236497716486454\n",
            "Epoch 10/10, Loss: 0.23719475013017655\n",
            "Epoch 10/10, Loss: 0.23789406150579454\n",
            "Epoch 10/10, Loss: 0.2385928573012352\n",
            "Epoch 10/10, Loss: 0.23927505695819853\n",
            "Epoch 10/10, Loss: 0.23996635288000107\n",
            "Epoch 10/10, Loss: 0.24065990179777144\n",
            "Epoch 10/10, Loss: 0.24135160881280898\n",
            "Epoch 10/10, Loss: 0.24205225825309754\n",
            "Epoch 10/10, Loss: 0.2427493626475334\n",
            "Epoch 10/10, Loss: 0.24344093972444533\n",
            "Epoch 10/10, Loss: 0.2441391363143921\n",
            "Epoch 10/10, Loss: 0.2448205863237381\n",
            "Epoch 10/10, Loss: 0.24551263576745988\n",
            "Epoch 10/10, Loss: 0.24619205021858215\n",
            "Epoch 10/10, Loss: 0.2468869852423668\n",
            "Epoch 10/10, Loss: 0.2475719151496887\n",
            "Epoch 10/10, Loss: 0.24825674653053284\n",
            "Epoch 10/10, Loss: 0.24896248388290404\n",
            "Epoch 10/10, Loss: 0.24965337771177293\n",
            "Epoch 10/10, Loss: 0.2503484123945236\n",
            "Epoch 10/10, Loss: 0.2510375608801842\n",
            "Epoch 10/10, Loss: 0.2517255591750145\n",
            "Epoch 10/10, Loss: 0.2524044709801674\n",
            "Epoch 10/10, Loss: 0.253086664378643\n",
            "Epoch 10/10, Loss: 0.25377038997411727\n",
            "Epoch 10/10, Loss: 0.25445649605989457\n",
            "Epoch 10/10, Loss: 0.25514561170339584\n",
            "Epoch 10/10, Loss: 0.25583228439092637\n",
            "Epoch 10/10, Loss: 0.25652427583932874\n",
            "Epoch 10/10, Loss: 0.2572149704098701\n",
            "Epoch 10/10, Loss: 0.2579055259823799\n",
            "Epoch 10/10, Loss: 0.25860786497592925\n",
            "Epoch 10/10, Loss: 0.25929941684007646\n",
            "Epoch 10/10, Loss: 0.2599906738400459\n",
            "Epoch 10/10, Loss: 0.26068427443504333\n",
            "Epoch 10/10, Loss: 0.26138145607709884\n",
            "Epoch 10/10, Loss: 0.26207117694616316\n",
            "Epoch 10/10, Loss: 0.2627627621889114\n",
            "Epoch 10/10, Loss: 0.26344939905405046\n",
            "Epoch 10/10, Loss: 0.26413799077272415\n",
            "Epoch 10/10, Loss: 0.26484411722421647\n",
            "Epoch 10/10, Loss: 0.26553122425079345\n",
            "Epoch 10/10, Loss: 0.26622571581602095\n",
            "Epoch 10/10, Loss: 0.2669212621450424\n",
            "Epoch 10/10, Loss: 0.26759818667173385\n",
            "Epoch 10/10, Loss: 0.2682790074944496\n",
            "Epoch 10/10, Loss: 0.26896601349115373\n",
            "Epoch 10/10, Loss: 0.26966028851270674\n",
            "Epoch 10/10, Loss: 0.27035436886548997\n",
            "Epoch 10/10, Loss: 0.2710427218079567\n",
            "Epoch 10/10, Loss: 0.2717196903824806\n",
            "Epoch 10/10, Loss: 0.2724112560749054\n",
            "Epoch 10/10, Loss: 0.27309572327136994\n",
            "Epoch 10/10, Loss: 0.2737974156141281\n",
            "Epoch 10/10, Loss: 0.2744815004467964\n",
            "Epoch 10/10, Loss: 0.2751719580292702\n",
            "Epoch 10/10, Loss: 0.2758568990826607\n",
            "Epoch 10/10, Loss: 0.2765543787479401\n",
            "Epoch 10/10, Loss: 0.2772354348897934\n",
            "Epoch 10/10, Loss: 0.27792500418424604\n",
            "Epoch 10/10, Loss: 0.278609572827816\n",
            "Epoch 10/10, Loss: 0.27930775088071824\n",
            "Epoch 10/10, Loss: 0.2799849247336388\n",
            "Epoch 10/10, Loss: 0.28067804223299025\n",
            "Epoch 10/10, Loss: 0.28137248343229293\n",
            "Epoch 10/10, Loss: 0.2820700032114983\n",
            "Epoch 10/10, Loss: 0.2827412113547325\n",
            "Epoch 10/10, Loss: 0.28343590557575227\n",
            "Epoch 10/10, Loss: 0.28412708735466\n",
            "Epoch 10/10, Loss: 0.2848041790723801\n",
            "Epoch 10/10, Loss: 0.285491720020771\n",
            "Epoch 10/10, Loss: 0.28618758046627046\n",
            "Epoch 10/10, Loss: 0.2868760703802109\n",
            "Epoch 10/10, Loss: 0.28756643748283384\n",
            "Epoch 10/10, Loss: 0.28824609363079073\n",
            "Epoch 10/10, Loss: 0.2889392243027687\n",
            "Epoch 10/10, Loss: 0.289627443253994\n",
            "Epoch 10/10, Loss: 0.2903139513731003\n",
            "Epoch 10/10, Loss: 0.29099618780612946\n",
            "Epoch 10/10, Loss: 0.29169311583042146\n",
            "Epoch 10/10, Loss: 0.292378686606884\n",
            "Epoch 10/10, Loss: 0.29307507491111756\n",
            "Epoch 10/10, Loss: 0.2937698411345482\n",
            "Epoch 10/10, Loss: 0.29445511442422867\n",
            "Epoch 10/10, Loss: 0.29514420622587206\n",
            "Epoch 10/10, Loss: 0.29582280343770984\n",
            "Epoch 10/10, Loss: 0.2965175881385803\n",
            "Epoch 10/10, Loss: 0.2972053366303444\n",
            "Epoch 10/10, Loss: 0.2978874948620796\n",
            "Epoch 10/10, Loss: 0.29856935757398606\n",
            "Epoch 10/10, Loss: 0.2992600551843643\n",
            "Epoch 10/10, Loss: 0.29994830828905106\n",
            "Epoch 10/10, Loss: 0.30063459277153015\n",
            "Epoch 10/10, Loss: 0.30132150667905805\n",
            "Epoch 10/10, Loss: 0.3020165368914604\n",
            "Epoch 10/10, Loss: 0.3027025229334831\n",
            "Epoch 10/10, Loss: 0.30338916343450545\n",
            "Epoch 10/10, Loss: 0.30407317250967025\n",
            "Epoch 10/10, Loss: 0.3047572100162506\n",
            "Epoch 10/10, Loss: 0.30543349528312685\n",
            "Epoch 10/10, Loss: 0.30611982083320616\n",
            "Epoch 10/10, Loss: 0.3068140976428986\n",
            "Epoch 10/10, Loss: 0.30749289762973786\n",
            "Epoch 10/10, Loss: 0.30817259281873705\n",
            "Epoch 10/10, Loss: 0.3088653789162636\n",
            "Epoch 10/10, Loss: 0.30955110567808153\n",
            "Epoch 10/10, Loss: 0.3102315727472305\n",
            "Epoch 10/10, Loss: 0.31091845059394835\n",
            "Epoch 10/10, Loss: 0.3116098536849022\n",
            "Epoch 10/10, Loss: 0.31230703586339953\n",
            "Epoch 10/10, Loss: 0.31300590324401856\n",
            "Epoch 10/10, Loss: 0.3137122581005096\n",
            "Epoch 10/10, Loss: 0.31438803750276567\n",
            "Epoch 10/10, Loss: 0.3150716056227684\n",
            "Epoch 10/10, Loss: 0.31575153410434725\n",
            "Epoch 10/10, Loss: 0.31643700486421583\n",
            "Epoch 10/10, Loss: 0.3171299014687538\n",
            "Epoch 10/10, Loss: 0.31782018929719924\n",
            "Epoch 10/10, Loss: 0.318506073653698\n",
            "Epoch 10/10, Loss: 0.31920426338911057\n",
            "Epoch 10/10, Loss: 0.31989721697568896\n",
            "Epoch 10/10, Loss: 0.3205896842479706\n",
            "Epoch 10/10, Loss: 0.3212827746272087\n",
            "Epoch 10/10, Loss: 0.3219825168251991\n",
            "Epoch 10/10, Loss: 0.32265933787822726\n",
            "Epoch 10/10, Loss: 0.32334493362903594\n",
            "Epoch 10/10, Loss: 0.32402578312158586\n",
            "Epoch 10/10, Loss: 0.3247004755139351\n",
            "Epoch 10/10, Loss: 0.32539812606573104\n",
            "Epoch 10/10, Loss: 0.3260986952781677\n",
            "Epoch 10/10, Loss: 0.3267780468463898\n",
            "Epoch 10/10, Loss: 0.32747068828344345\n",
            "Epoch 10/10, Loss: 0.3281520640850067\n",
            "Epoch 10/10, Loss: 0.3288427727818489\n",
            "Epoch 10/10, Loss: 0.3295360849499702\n",
            "Epoch 10/10, Loss: 0.3302436774969101\n",
            "Epoch 10/10, Loss: 0.3309376650452614\n",
            "Epoch 10/10, Loss: 0.33162138855457307\n",
            "Epoch 10/10, Loss: 0.33232061010599134\n",
            "Epoch 10/10, Loss: 0.3330262713432312\n",
            "Epoch 10/10, Loss: 0.3337111085057259\n",
            "Epoch 10/10, Loss: 0.3343958794474602\n",
            "Epoch 10/10, Loss: 0.33508700555562976\n",
            "Epoch 10/10, Loss: 0.3357821510434151\n",
            "Epoch 10/10, Loss: 0.3364665400981903\n",
            "Epoch 10/10, Loss: 0.3371604608297348\n",
            "Epoch 10/10, Loss: 0.3378518834114075\n",
            "Epoch 10/10, Loss: 0.3385429410338402\n",
            "Epoch 10/10, Loss: 0.3392250939011574\n",
            "Epoch 10/10, Loss: 0.33991580027341844\n",
            "Epoch 10/10, Loss: 0.34061986297369\n",
            "Epoch 10/10, Loss: 0.34130617743730546\n",
            "Epoch 10/10, Loss: 0.341998381793499\n",
            "Epoch 10/10, Loss: 0.34270111727714536\n",
            "Epoch 10/10, Loss: 0.34340241968631746\n",
            "Epoch 10/10, Loss: 0.3440927367210388\n",
            "Epoch 10/10, Loss: 0.34478012013435366\n",
            "Epoch 10/10, Loss: 0.3454724197983742\n",
            "Epoch 10/10, Loss: 0.346158615231514\n",
            "Epoch 10/10, Loss: 0.3468605928421021\n",
            "Epoch 10/10, Loss: 0.34754669803380966\n",
            "Epoch 10/10, Loss: 0.34823874324560167\n",
            "Epoch 10/10, Loss: 0.3489273160099983\n",
            "Epoch 10/10, Loss: 0.34962600976228714\n",
            "Epoch 10/10, Loss: 0.3503094500303268\n",
            "Epoch 10/10, Loss: 0.3509980375766754\n",
            "Epoch 10/10, Loss: 0.3516904947757721\n",
            "Epoch 10/10, Loss: 0.35239145773649216\n",
            "Epoch 10/10, Loss: 0.3530828931927681\n",
            "Epoch 10/10, Loss: 0.3537725231051445\n",
            "Epoch 10/10, Loss: 0.3544592416882515\n",
            "Epoch 10/10, Loss: 0.35515073138475417\n",
            "Epoch 10/10, Loss: 0.35584133499860765\n",
            "Epoch 10/10, Loss: 0.35653979367017746\n",
            "Epoch 10/10, Loss: 0.35723095703125\n",
            "Epoch 10/10, Loss: 0.3579270763397217\n",
            "Epoch 10/10, Loss: 0.35861806046962735\n",
            "Epoch 10/10, Loss: 0.35930014789104464\n",
            "Epoch 10/10, Loss: 0.35999131518602373\n",
            "Epoch 10/10, Loss: 0.3606771404743195\n",
            "Epoch 10/10, Loss: 0.36136856162548064\n",
            "Epoch 10/10, Loss: 0.36205180805921555\n",
            "Epoch 10/10, Loss: 0.36275400322675705\n",
            "Epoch 10/10, Loss: 0.36345209765434267\n",
            "Epoch 10/10, Loss: 0.3641375503540039\n",
            "Epoch 10/10, Loss: 0.364813539147377\n",
            "Epoch 10/10, Loss: 0.36550743246078493\n",
            "Epoch 10/10, Loss: 0.3661962809562683\n",
            "Epoch 10/10, Loss: 0.36688309019804\n",
            "Epoch 10/10, Loss: 0.3675822542309761\n",
            "Epoch 10/10, Loss: 0.368272057056427\n",
            "Epoch 10/10, Loss: 0.368961067199707\n",
            "Epoch 10/10, Loss: 0.36966100871562957\n",
            "Epoch 10/10, Loss: 0.37035018986463547\n",
            "Epoch 10/10, Loss: 0.3710437110066414\n",
            "Epoch 10/10, Loss: 0.3717356898784637\n",
            "Epoch 10/10, Loss: 0.3724282954931259\n",
            "Epoch 10/10, Loss: 0.37311906522512434\n",
            "Epoch 10/10, Loss: 0.37379804557561874\n",
            "Epoch 10/10, Loss: 0.37448180609941484\n",
            "Epoch 10/10, Loss: 0.37517068070173265\n",
            "Epoch 10/10, Loss: 0.3758509412407875\n",
            "Epoch 10/10, Loss: 0.376534129858017\n",
            "Epoch 10/10, Loss: 0.3772229050397873\n",
            "Epoch 10/10, Loss: 0.37790812903642657\n",
            "Epoch 10/10, Loss: 0.3786031333208084\n",
            "Epoch 10/10, Loss: 0.3792958629131317\n",
            "Epoch 10/10, Loss: 0.3799817255139351\n",
            "Epoch 10/10, Loss: 0.3806720834970474\n",
            "Epoch 10/10, Loss: 0.3813627905845642\n",
            "Epoch 10/10, Loss: 0.38204709815979004\n",
            "Epoch 10/10, Loss: 0.38273720943927764\n",
            "Epoch 10/10, Loss: 0.3834174530506134\n",
            "Epoch 10/10, Loss: 0.3841122002005577\n",
            "Epoch 10/10, Loss: 0.3847947378754616\n",
            "Epoch 10/10, Loss: 0.3854884940385819\n",
            "Epoch 10/10, Loss: 0.3861812814474106\n",
            "Epoch 10/10, Loss: 0.38687956911325455\n",
            "Epoch 10/10, Loss: 0.3875605962276459\n",
            "Epoch 10/10, Loss: 0.3882460520863533\n",
            "Epoch 10/10, Loss: 0.388936311006546\n",
            "Epoch 10/10, Loss: 0.3896267075538635\n",
            "Epoch 10/10, Loss: 0.39031306374073027\n",
            "Epoch 10/10, Loss: 0.3910082131624222\n",
            "Epoch 10/10, Loss: 0.3917020495533943\n",
            "Epoch 10/10, Loss: 0.3923908214569092\n",
            "Epoch 10/10, Loss: 0.3930791746377945\n",
            "Epoch 10/10, Loss: 0.39375584268569946\n",
            "Epoch 10/10, Loss: 0.3944571858048439\n",
            "Epoch 10/10, Loss: 0.39512934523820875\n",
            "Epoch 10/10, Loss: 0.3958183260560036\n",
            "Epoch 10/10, Loss: 0.3965038677453995\n",
            "Epoch 10/10, Loss: 0.3971977975964546\n",
            "Epoch 10/10, Loss: 0.3978914243578911\n",
            "Epoch 10/10, Loss: 0.39859095907211306\n",
            "Epoch 10/10, Loss: 0.3992818437218666\n",
            "Epoch 10/10, Loss: 0.39996211099624634\n",
            "Epoch 10/10, Loss: 0.4006472121477127\n",
            "Epoch 10/10, Loss: 0.4013414304256439\n",
            "Epoch 10/10, Loss: 0.40203680300712585\n",
            "Epoch 10/10, Loss: 0.4027176249623299\n",
            "Epoch 10/10, Loss: 0.4034148574471474\n",
            "Epoch 10/10, Loss: 0.4040924370884895\n",
            "Epoch 10/10, Loss: 0.40477951711416243\n",
            "Epoch 10/10, Loss: 0.4054693958759308\n",
            "Epoch 10/10, Loss: 0.4061591014266014\n",
            "Epoch 10/10, Loss: 0.40685192638635637\n",
            "Epoch 10/10, Loss: 0.4075411194562912\n",
            "Epoch 10/10, Loss: 0.40822896552085874\n",
            "Epoch 10/10, Loss: 0.4089187470078468\n",
            "Epoch 10/10, Loss: 0.4096114827990532\n",
            "Epoch 10/10, Loss: 0.41030752724409103\n",
            "Epoch 10/10, Loss: 0.4110049069523811\n",
            "Epoch 10/10, Loss: 0.41169436222314837\n",
            "Epoch 10/10, Loss: 0.41238350063562396\n",
            "Epoch 10/10, Loss: 0.41306914228200914\n",
            "Epoch 10/10, Loss: 0.41375320583581926\n",
            "Epoch 10/10, Loss: 0.4144454057812691\n",
            "Epoch 10/10, Loss: 0.41513874745368956\n",
            "Epoch 10/10, Loss: 0.41582251399755477\n",
            "Epoch 10/10, Loss: 0.41652038842439654\n",
            "Epoch 10/10, Loss: 0.4172125606536865\n",
            "Epoch 10/10, Loss: 0.4179101784825325\n",
            "Epoch 10/10, Loss: 0.41859930515289306\n",
            "Epoch 10/10, Loss: 0.4192854770421982\n",
            "Epoch 10/10, Loss: 0.4199753288626671\n",
            "Epoch 10/10, Loss: 0.420670762181282\n",
            "Epoch 10/10, Loss: 0.4213710407614708\n",
            "Epoch 10/10, Loss: 0.422056864798069\n",
            "Epoch 10/10, Loss: 0.42275106769800186\n",
            "Epoch 10/10, Loss: 0.42342400723695756\n",
            "Epoch 10/10, Loss: 0.42411432272195815\n",
            "Epoch 10/10, Loss: 0.42480548918247224\n",
            "Epoch 10/10, Loss: 0.4255028253793716\n",
            "Epoch 10/10, Loss: 0.4261927778720856\n",
            "Epoch 10/10, Loss: 0.4268722855448723\n",
            "Epoch 10/10, Loss: 0.4275593690276146\n",
            "Epoch 10/10, Loss: 0.42824598437547684\n",
            "Epoch 10/10, Loss: 0.4289351774454117\n",
            "Epoch 10/10, Loss: 0.42963429522514346\n",
            "Epoch 10/10, Loss: 0.4303239888548851\n",
            "Epoch 10/10, Loss: 0.4310080823302269\n",
            "Epoch 10/10, Loss: 0.43169689589738847\n",
            "Epoch 10/10, Loss: 0.43239099377393725\n",
            "Epoch 10/10, Loss: 0.43309107911586764\n",
            "Epoch 10/10, Loss: 0.433773296713829\n",
            "Epoch 10/10, Loss: 0.43447429859638215\n",
            "Epoch 10/10, Loss: 0.4351616097092629\n",
            "Epoch 10/10, Loss: 0.43584286320209503\n",
            "Epoch 10/10, Loss: 0.4365459758043289\n",
            "Epoch 10/10, Loss: 0.43724107605218887\n",
            "Epoch 10/10, Loss: 0.43793310737609864\n",
            "Epoch 10/10, Loss: 0.438615151822567\n",
            "Epoch 10/10, Loss: 0.439315000474453\n",
            "Epoch 10/10, Loss: 0.4400169729590416\n",
            "Epoch 10/10, Loss: 0.440705383181572\n",
            "Epoch 10/10, Loss: 0.4413902221918106\n",
            "Epoch 10/10, Loss: 0.44207725989818575\n",
            "Epoch 10/10, Loss: 0.44276323705911635\n",
            "Epoch 10/10, Loss: 0.4434478915929794\n",
            "Epoch 10/10, Loss: 0.44414268487691877\n",
            "Epoch 10/10, Loss: 0.44483117973804476\n",
            "Epoch 10/10, Loss: 0.44551334536075593\n",
            "Epoch 10/10, Loss: 0.4461990410685539\n",
            "Epoch 10/10, Loss: 0.44688589560985564\n",
            "Epoch 10/10, Loss: 0.4475714012980461\n",
            "Epoch 10/10, Loss: 0.4482582560777664\n",
            "Epoch 10/10, Loss: 0.44895087206363676\n",
            "Epoch 10/10, Loss: 0.4496588261127472\n",
            "Epoch 10/10, Loss: 0.45034983396530154\n",
            "Epoch 10/10, Loss: 0.4510470475554466\n",
            "Epoch 10/10, Loss: 0.45174309360980985\n",
            "Epoch 10/10, Loss: 0.4524346153140068\n",
            "Epoch 10/10, Loss: 0.4531283581852913\n",
            "Epoch 10/10, Loss: 0.4538167045712471\n",
            "Epoch 10/10, Loss: 0.454508008480072\n",
            "Epoch 10/10, Loss: 0.4552039395570755\n",
            "Epoch 10/10, Loss: 0.45589325433969496\n",
            "Epoch 10/10, Loss: 0.45658050721883775\n",
            "Epoch 10/10, Loss: 0.45725732254981993\n",
            "Epoch 10/10, Loss: 0.4579452514052391\n",
            "Epoch 10/10, Loss: 0.4586435577273369\n",
            "Epoch 10/10, Loss: 0.4593300071358681\n",
            "Epoch 10/10, Loss: 0.4600183094739914\n",
            "Epoch 10/10, Loss: 0.4607146116495132\n",
            "Epoch 10/10, Loss: 0.4613992612361908\n",
            "Epoch 10/10, Loss: 0.46207926934957505\n",
            "Epoch 10/10, Loss: 0.4627588336467743\n",
            "Epoch 10/10, Loss: 0.4634478908777237\n",
            "Epoch 10/10, Loss: 0.46413378190994264\n",
            "Epoch 10/10, Loss: 0.4648237246870995\n",
            "Epoch 10/10, Loss: 0.46550382059812545\n",
            "Epoch 10/10, Loss: 0.4662015322446823\n",
            "Epoch 10/10, Loss: 0.46688595616817474\n",
            "Epoch 10/10, Loss: 0.46758403432369233\n",
            "Epoch 10/10, Loss: 0.4682842898368835\n",
            "Epoch 10/10, Loss: 0.4689777290225029\n",
            "Epoch 10/10, Loss: 0.4696821936964989\n",
            "Epoch 10/10, Loss: 0.4703733877539635\n",
            "Epoch 10/10, Loss: 0.4710615846514702\n",
            "Epoch 10/10, Loss: 0.4717575470805168\n",
            "Epoch 10/10, Loss: 0.4724589750170708\n",
            "Epoch 10/10, Loss: 0.4731583203673363\n",
            "Epoch 10/10, Loss: 0.4738464542627335\n",
            "Epoch 10/10, Loss: 0.47453657805919647\n",
            "Epoch 10/10, Loss: 0.4752242915630341\n",
            "Epoch 10/10, Loss: 0.475918948829174\n",
            "Epoch 10/10, Loss: 0.4766164579987526\n",
            "Epoch 10/10, Loss: 0.4773083055615425\n",
            "Epoch 10/10, Loss: 0.47799664801359176\n",
            "Epoch 10/10, Loss: 0.47868296545743944\n",
            "Epoch 10/10, Loss: 0.47937050235271456\n",
            "Epoch 10/10, Loss: 0.48005527424812316\n",
            "Epoch 10/10, Loss: 0.48074572187662123\n",
            "Epoch 10/10, Loss: 0.48143752008676527\n",
            "Epoch 10/10, Loss: 0.4821229021549225\n",
            "Epoch 10/10, Loss: 0.4828146492242813\n",
            "Epoch 10/10, Loss: 0.4835079470872879\n",
            "Epoch 10/10, Loss: 0.48420335119962693\n",
            "Epoch 10/10, Loss: 0.48489355379343035\n",
            "Epoch 10/10, Loss: 0.4855826149582863\n",
            "Epoch 10/10, Loss: 0.48627379566431045\n",
            "Epoch 10/10, Loss: 0.4869574565887451\n",
            "Epoch 10/10, Loss: 0.4876398639678955\n",
            "Epoch 10/10, Loss: 0.4883255923986435\n",
            "Epoch 10/10, Loss: 0.48902870577573776\n",
            "Epoch 10/10, Loss: 0.48971914291381835\n",
            "Epoch 10/10, Loss: 0.4904015496969223\n",
            "Epoch 10/10, Loss: 0.4910901551246643\n",
            "Epoch 10/10, Loss: 0.491780100107193\n",
            "Epoch 10/10, Loss: 0.49247126930952073\n",
            "Epoch 10/10, Loss: 0.49314228945970534\n",
            "Epoch 10/10, Loss: 0.4938329675793648\n",
            "Epoch 10/10, Loss: 0.49453115952014925\n",
            "Epoch 10/10, Loss: 0.495223455786705\n",
            "Epoch 10/10, Loss: 0.49591326487064363\n",
            "Epoch 10/10, Loss: 0.4965975139141083\n",
            "Epoch 10/10, Loss: 0.4972959136366844\n",
            "Epoch 10/10, Loss: 0.49798287904262545\n",
            "Epoch 10/10, Loss: 0.4986728686094284\n",
            "Epoch 10/10, Loss: 0.49936919075250624\n",
            "Epoch 10/10, Loss: 0.5000668383836746\n",
            "Epoch 10/10, Loss: 0.5007533009052276\n",
            "Epoch 10/10, Loss: 0.5014493577480316\n",
            "Epoch 10/10, Loss: 0.5021339379549027\n",
            "Epoch 10/10, Loss: 0.5028261458873748\n",
            "Epoch 10/10, Loss: 0.5035250273346901\n",
            "Epoch 10/10, Loss: 0.5042238991260528\n",
            "Epoch 10/10, Loss: 0.5049219779968261\n",
            "Epoch 10/10, Loss: 0.5056122536659241\n",
            "Epoch 10/10, Loss: 0.5063033831119538\n",
            "Epoch 10/10, Loss: 0.5069833926558495\n",
            "Epoch 10/10, Loss: 0.5076630837917327\n",
            "Epoch 10/10, Loss: 0.5083508751392365\n",
            "Epoch 10/10, Loss: 0.5090417846441269\n",
            "Epoch 10/10, Loss: 0.5097424399852752\n",
            "Epoch 10/10, Loss: 0.5104350396990776\n",
            "Epoch 10/10, Loss: 0.5111182057857513\n",
            "Epoch 10/10, Loss: 0.5117953051328659\n",
            "Epoch 10/10, Loss: 0.5124830973148345\n",
            "Epoch 10/10, Loss: 0.5131804030537606\n",
            "Epoch 10/10, Loss: 0.5138699108362198\n",
            "Epoch 10/10, Loss: 0.5145574337244034\n",
            "Epoch 10/10, Loss: 0.5152427436113357\n",
            "Epoch 10/10, Loss: 0.5159414202570916\n",
            "Epoch 10/10, Loss: 0.5166196318864822\n",
            "Epoch 10/10, Loss: 0.5173144028186798\n",
            "Epoch 10/10, Loss: 0.518017646074295\n",
            "Epoch 10/10, Loss: 0.5186964081525802\n",
            "Epoch 10/10, Loss: 0.519384761929512\n",
            "Epoch 10/10, Loss: 0.5200696914792061\n",
            "Epoch 10/10, Loss: 0.5207585620284081\n",
            "Epoch 10/10, Loss: 0.521452831864357\n",
            "Epoch 10/10, Loss: 0.5221358026862144\n",
            "Epoch 10/10, Loss: 0.5228358190655709\n",
            "Epoch 10/10, Loss: 0.5235242876410484\n",
            "Epoch 10/10, Loss: 0.5242147462964057\n",
            "Epoch 10/10, Loss: 0.524910093486309\n",
            "Epoch 10/10, Loss: 0.5256036518812179\n",
            "Epoch 10/10, Loss: 0.5262862209677697\n",
            "Epoch 10/10, Loss: 0.526975384414196\n",
            "Epoch 10/10, Loss: 0.5276595792174339\n",
            "Epoch 10/10, Loss: 0.5283431495428086\n",
            "Epoch 10/10, Loss: 0.5290403687357903\n",
            "Epoch 10/10, Loss: 0.5297317747473717\n",
            "Epoch 10/10, Loss: 0.5304123353362084\n",
            "Epoch 10/10, Loss: 0.5311025149226188\n",
            "Epoch 10/10, Loss: 0.5317954999208451\n",
            "Epoch 10/10, Loss: 0.5324911835193634\n",
            "Epoch 10/10, Loss: 0.5331839002370834\n",
            "Epoch 10/10, Loss: 0.5338891404867172\n",
            "Epoch 10/10, Loss: 0.5345768065452575\n",
            "Epoch 10/10, Loss: 0.535267571747303\n",
            "Epoch 10/10, Loss: 0.5359565389156341\n",
            "Epoch 10/10, Loss: 0.5366617529392242\n",
            "Epoch 10/10, Loss: 0.5373506524562836\n",
            "Epoch 10/10, Loss: 0.5380493270158768\n",
            "Epoch 10/10, Loss: 0.5387394433617592\n",
            "Epoch 10/10, Loss: 0.5394152017235756\n",
            "Epoch 10/10, Loss: 0.5401038984060288\n",
            "Epoch 10/10, Loss: 0.5407850986123085\n",
            "Epoch 10/10, Loss: 0.5414625040888786\n",
            "Epoch 10/10, Loss: 0.5421470819115639\n",
            "Epoch 10/10, Loss: 0.5428263115286827\n",
            "Epoch 10/10, Loss: 0.5435114232301712\n",
            "Epoch 10/10, Loss: 0.5441932854056358\n",
            "Epoch 10/10, Loss: 0.5448770270943641\n",
            "Epoch 10/10, Loss: 0.5455527898669242\n",
            "Epoch 10/10, Loss: 0.5462354019284248\n",
            "Epoch 10/10, Loss: 0.546922568321228\n",
            "Epoch 10/10, Loss: 0.547618850171566\n",
            "Epoch 10/10, Loss: 0.5483020688891411\n",
            "Epoch 10/10, Loss: 0.548980229139328\n",
            "Epoch 10/10, Loss: 0.5496681698560715\n",
            "Epoch 10/10, Loss: 0.5503423209190369\n",
            "Epoch 10/10, Loss: 0.5510426143407822\n",
            "Epoch 10/10, Loss: 0.5517310262322426\n",
            "Epoch 10/10, Loss: 0.5524185354113579\n",
            "Epoch 10/10, Loss: 0.5531172136664391\n",
            "Epoch 10/10, Loss: 0.5537953353524208\n",
            "Epoch 10/10, Loss: 0.5544899872541428\n",
            "Epoch 10/10, Loss: 0.5551833184957504\n",
            "Epoch 10/10, Loss: 0.5558693534135819\n",
            "Epoch 10/10, Loss: 0.5565576483011245\n",
            "Epoch 10/10, Loss: 0.5572459082007408\n",
            "Epoch 10/10, Loss: 0.5579275173544884\n",
            "Epoch 10/10, Loss: 0.558632377564907\n",
            "Epoch 10/10, Loss: 0.5593211684823036\n",
            "Epoch 10/10, Loss: 0.5600128057003021\n",
            "Epoch 10/10, Loss: 0.5607022197246552\n",
            "Epoch 10/10, Loss: 0.5613993036150933\n",
            "Epoch 10/10, Loss: 0.5620936558246613\n",
            "Epoch 10/10, Loss: 0.5627828782200813\n",
            "Epoch 10/10, Loss: 0.5634539768099784\n",
            "Epoch 10/10, Loss: 0.564156339764595\n",
            "Epoch 10/10, Loss: 0.5648566952347756\n",
            "Epoch 10/10, Loss: 0.5655413516759873\n",
            "Epoch 10/10, Loss: 0.5662339396476745\n",
            "Epoch 10/10, Loss: 0.5669229652881622\n",
            "Epoch 10/10, Loss: 0.5676050666570663\n",
            "Epoch 10/10, Loss: 0.5682823261022568\n",
            "Epoch 10/10, Loss: 0.5689684495925903\n",
            "Epoch 10/10, Loss: 0.5696554036140442\n",
            "Epoch 10/10, Loss: 0.5703454249501229\n",
            "Epoch 10/10, Loss: 0.5710294937491417\n",
            "Epoch 10/10, Loss: 0.5717134088873863\n",
            "Epoch 10/10, Loss: 0.5724090283513069\n",
            "Epoch 10/10, Loss: 0.5730973637700081\n",
            "Epoch 10/10, Loss: 0.5737900869250298\n",
            "Epoch 10/10, Loss: 0.5744765036702156\n",
            "Epoch 10/10, Loss: 0.5751704971194267\n",
            "Epoch 10/10, Loss: 0.5758575478196144\n",
            "Epoch 10/10, Loss: 0.576556576371193\n",
            "Epoch 10/10, Loss: 0.57724306422472\n",
            "Epoch 10/10, Loss: 0.5779340668320656\n",
            "Epoch 10/10, Loss: 0.5786192718744277\n",
            "Epoch 10/10, Loss: 0.5793186662793159\n",
            "Epoch 10/10, Loss: 0.5800097771286964\n",
            "Epoch 10/10, Loss: 0.5807001707553864\n",
            "Epoch 10/10, Loss: 0.5813856858015061\n",
            "Epoch 10/10, Loss: 0.5820658397674561\n",
            "Epoch 10/10, Loss: 0.5827403454780579\n",
            "Epoch 10/10, Loss: 0.5834437409639358\n",
            "Epoch 10/10, Loss: 0.5841377573609352\n",
            "Epoch 10/10, Loss: 0.5848389878869057\n",
            "Epoch 10/10, Loss: 0.5855313503146171\n",
            "Epoch 10/10, Loss: 0.5862119701504708\n",
            "Epoch 10/10, Loss: 0.5869051823616028\n",
            "Epoch 10/10, Loss: 0.5875939835309982\n",
            "Epoch 10/10, Loss: 0.5882851370573043\n",
            "Epoch 10/10, Loss: 0.5889715471863747\n",
            "Epoch 10/10, Loss: 0.5896448283195496\n",
            "Epoch 10/10, Loss: 0.5903274857997894\n",
            "Epoch 10/10, Loss: 0.5910154117345809\n",
            "Epoch 10/10, Loss: 0.5916905907988548\n",
            "Epoch 10/10, Loss: 0.5923763819336891\n",
            "Epoch 10/10, Loss: 0.5930514380931854\n",
            "Epoch 10/10, Loss: 0.5937318340539932\n",
            "Epoch 10/10, Loss: 0.5944224861860276\n",
            "Epoch 10/10, Loss: 0.5951222297549248\n",
            "Epoch 10/10, Loss: 0.5958004164695739\n",
            "Epoch 10/10, Loss: 0.5964919782876968\n",
            "Epoch 10/10, Loss: 0.5971706367135048\n",
            "Epoch 10/10, Loss: 0.5978512724041939\n",
            "Epoch 10/10, Loss: 0.5985448704957962\n",
            "Epoch 10/10, Loss: 0.59924210947752\n",
            "Epoch 10/10, Loss: 0.5999409927725792\n",
            "Epoch 10/10, Loss: 0.6006279218792915\n",
            "Epoch 10/10, Loss: 0.6013082758784294\n",
            "Epoch 10/10, Loss: 0.6020031815767288\n",
            "Epoch 10/10, Loss: 0.6026947261095047\n",
            "Epoch 10/10, Loss: 0.6033850728273392\n",
            "Epoch 10/10, Loss: 0.6040724979639054\n",
            "Epoch 10/10, Loss: 0.6047554656267166\n",
            "Epoch 10/10, Loss: 0.6054441448450089\n",
            "Epoch 10/10, Loss: 0.6061274427771568\n",
            "Epoch 10/10, Loss: 0.6068066311478615\n",
            "Epoch 10/10, Loss: 0.607499796807766\n",
            "Epoch 10/10, Loss: 0.608189604818821\n",
            "Epoch 10/10, Loss: 0.6088796555399895\n",
            "Epoch 10/10, Loss: 0.6095715209841728\n",
            "Epoch 10/10, Loss: 0.6102564871907235\n",
            "Epoch 10/10, Loss: 0.61094279307127\n",
            "Epoch 10/10, Loss: 0.6116214392185211\n",
            "Epoch 10/10, Loss: 0.6123091295957566\n",
            "Epoch 10/10, Loss: 0.6129981552362442\n",
            "Epoch 10/10, Loss: 0.6136920943856239\n",
            "Epoch 10/10, Loss: 0.6143896242380142\n",
            "Epoch 10/10, Loss: 0.6150670887231827\n",
            "Epoch 10/10, Loss: 0.6157577486634255\n",
            "Epoch 10/10, Loss: 0.6164277360439301\n",
            "Epoch 10/10, Loss: 0.6171085887551307\n",
            "Epoch 10/10, Loss: 0.6177981807589531\n",
            "Epoch 10/10, Loss: 0.6184876633286476\n",
            "Epoch 10/10, Loss: 0.6191771186590195\n",
            "Epoch 10/10, Loss: 0.6198691412210464\n",
            "Epoch 10/10, Loss: 0.6205606612563134\n",
            "Epoch 10/10, Loss: 0.6212504133582115\n",
            "Epoch 10/10, Loss: 0.6219351995587349\n",
            "Epoch 10/10, Loss: 0.6226252938508987\n",
            "Epoch 10/10, Loss: 0.6233206870555877\n",
            "Epoch 10/10, Loss: 0.6240051449537277\n",
            "Epoch 10/10, Loss: 0.6246861523389816\n",
            "Epoch 10/10, Loss: 0.6253721101284027\n",
            "Epoch 10/10, Loss: 0.6260624848604203\n",
            "Epoch 10/10, Loss: 0.626744635283947\n",
            "Epoch 10/10, Loss: 0.6274267436265946\n",
            "Epoch 10/10, Loss: 0.6281196128726005\n",
            "Epoch 10/10, Loss: 0.6288064650893211\n",
            "Epoch 10/10, Loss: 0.629491162121296\n",
            "Epoch 10/10, Loss: 0.6301823145747185\n",
            "Epoch 10/10, Loss: 0.6308758605122566\n",
            "Epoch 10/10, Loss: 0.6315682642459869\n",
            "Epoch 10/10, Loss: 0.6322536014914513\n",
            "Epoch 10/10, Loss: 0.6329451171755791\n",
            "Epoch 10/10, Loss: 0.6336325458884239\n",
            "Epoch 10/10, Loss: 0.6343124507665634\n",
            "Epoch 10/10, Loss: 0.635003947854042\n",
            "Epoch 10/10, Loss: 0.6357059606909752\n",
            "Epoch 10/10, Loss: 0.6363830532431602\n",
            "Epoch 10/10, Loss: 0.6370781783461571\n",
            "Epoch 10/10, Loss: 0.6377547351717949\n",
            "Epoch 10/10, Loss: 0.6384459919929505\n",
            "Epoch 10/10, Loss: 0.6391217163801193\n",
            "Epoch 10/10, Loss: 0.6398139352798462\n",
            "Epoch 10/10, Loss: 0.6405030556917191\n",
            "Epoch 10/10, Loss: 0.6412031157612801\n",
            "Epoch 10/10, Loss: 0.6418946435451508\n",
            "Epoch 10/10, Loss: 0.6425796005129815\n",
            "Epoch 10/10, Loss: 0.6432546632885933\n",
            "Epoch 10/10, Loss: 0.6439404868483544\n",
            "Epoch 10/10, Loss: 0.6446265154480935\n",
            "Epoch 10/10, Loss: 0.6453241552114487\n",
            "Epoch 10/10, Loss: 0.6460158696174622\n",
            "Epoch 10/10, Loss: 0.6467034332752227\n",
            "Epoch 10/10, Loss: 0.6474048496484757\n",
            "Epoch 10/10, Loss: 0.6481018462181092\n",
            "Epoch 10/10, Loss: 0.6487823964953423\n",
            "Epoch 10/10, Loss: 0.6494649738669396\n",
            "Epoch 10/10, Loss: 0.6501499934792518\n",
            "Epoch 10/10, Loss: 0.6508411629796028\n",
            "Epoch 10/10, Loss: 0.6515316367149353\n",
            "Epoch 10/10, Loss: 0.6521983197927474\n",
            "Epoch 10/10, Loss: 0.6528821792602539\n",
            "Epoch 10/10, Loss: 0.6535701633095742\n",
            "Epoch 10/10, Loss: 0.6542653191685677\n",
            "Epoch 10/10, Loss: 0.6549706210494042\n",
            "Epoch 10/10, Loss: 0.655661705493927\n",
            "Epoch 10/10, Loss: 0.6563638105988503\n",
            "Epoch 10/10, Loss: 0.6570591398477554\n",
            "Epoch 10/10, Loss: 0.6577508941292762\n",
            "Epoch 10/10, Loss: 0.6584391168951989\n",
            "Epoch 10/10, Loss: 0.659120971262455\n",
            "Epoch 10/10, Loss: 0.659811538875103\n",
            "Epoch 10/10, Loss: 0.660498796403408\n",
            "Epoch 10/10, Loss: 0.6611873787045479\n",
            "Epoch 10/10, Loss: 0.6618866022229195\n",
            "Epoch 10/10, Loss: 0.6625731771588326\n",
            "Epoch 10/10, Loss: 0.6632660859227181\n",
            "Epoch 10/10, Loss: 0.6639598737359047\n",
            "Epoch 10/10, Loss: 0.6646509807705879\n",
            "Epoch 10/10, Loss: 0.6653435209393501\n",
            "Epoch 10/10, Loss: 0.6660424945950508\n",
            "Epoch 10/10, Loss: 0.6667347104549408\n",
            "Epoch 10/10, Loss: 0.6674273151159287\n",
            "Epoch 10/10, Loss: 0.6681230691671372\n",
            "Epoch 10/10, Loss: 0.6688164830207824\n",
            "Epoch 10/10, Loss: 0.6695049052238464\n",
            "Epoch 10/10, Loss: 0.6701942231059075\n",
            "Epoch 10/10, Loss: 0.6708782953619957\n",
            "Epoch 10/10, Loss: 0.6715633613467217\n",
            "Epoch 10/10, Loss: 0.6722576454281807\n",
            "Epoch 10/10, Loss: 0.6729540717601776\n",
            "Epoch 10/10, Loss: 0.6736382814645767\n",
            "Epoch 10/10, Loss: 0.6743259707689285\n",
            "Epoch 10/10, Loss: 0.6750160185098648\n",
            "Epoch 10/10, Loss: 0.6757201879620552\n",
            "Epoch 10/10, Loss: 0.676424236536026\n",
            "Epoch 10/10, Loss: 0.6771050246953965\n",
            "Epoch 10/10, Loss: 0.6778024342060089\n",
            "Epoch 10/10, Loss: 0.6784907494187356\n",
            "Epoch 10/10, Loss: 0.6791722255945206\n",
            "Epoch 10/10, Loss: 0.6798773031234742\n",
            "Epoch 10/10, Loss: 0.6805750628709794\n",
            "Epoch 10/10, Loss: 0.6812541917562485\n",
            "Epoch 10/10, Loss: 0.681944925904274\n",
            "Epoch 10/10, Loss: 0.6826406016349792\n",
            "Epoch 10/10, Loss: 0.6833610306978226\n",
            "Epoch 10/10, Loss: 0.6840385855436325\n",
            "Epoch 10/10, Loss: 0.684732676744461\n",
            "Epoch 10/10, Loss: 0.6854265948534012\n",
            "Epoch 10/10, Loss: 0.6861265608072281\n",
            "Epoch 10/10, Loss: 0.6868122565746307\n",
            "Epoch 10/10, Loss: 0.6874994617104531\n",
            "Epoch 10/10, Loss: 0.6882011295557022\n",
            "Epoch 10/10, Loss: 0.6888968966007233\n",
            "Epoch 10/10, Loss: 0.6895878186225891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model:\n",
        "\n",
        "Here we will test the performance of the model on the test data. First, lets save the model parameters in a `.PTH` file. We will load the saved model by opening the file, then load the test data using testloader (just like trainloader) then we will be conducting the inference.\n",
        "\n",
        "* `torch.save(model.state_dict(), path)` to save the model\n",
        "\n",
        "* `model.load_state_dict(torch.load(path))` to load the model"
      ],
      "metadata": {
        "id": "nsiot4aFTM58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save the trained model\n",
        "PATH = './mymodel.pth'\n",
        "torch.save(model3.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "_ALawap1R-OV"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the saved model\n",
        "model3 = Network()\n",
        "model3.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aMD2Ay8TsQR",
        "outputId": "ad352da7-c917-49fb-af58-db5c54e9b221"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdata = CustomDataset(X_test, y_test)\n",
        "\n",
        "testloader = DataLoader(testdata, batch_size=4, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "mEH_oyUHUVLr"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(testdata[5])\n",
        "print(testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQT6xx_gUlgT",
        "outputId": "ddaf4074-536a-4421-9e13-5815d8fbebb2"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([ 0.5007, -0.8821, -0.5948, -2.0559, -1.2178, -0.1364,  1.5397,  0.2697,\n",
            "         0.6762, -0.2466]), tensor(0))\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x79ab9960f550>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform inference\n",
        "def test_model(model, testloader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        for batch_X, batch_y in testloader:\n",
        "            outputs = model(batch_X)  # Perform forward pass\n",
        "            _, predicted = torch.max(outputs, 1)  # Max probability value discarded, index obtained in predicted. [since output = (probability, class), here \"class\" is the index]\n",
        "            total += batch_y.size(0)              # total no of samples so far\n",
        "            correct += (predicted == batch_y).sum().item()     # total correct prediction so far. [(predicted==batch_y) is a boolean tensor, .sums true value in tensor, .item() converts the sum to scalar to give total true values.\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "3Tpw_YemU34k"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "test_model(model3, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8vGZXBEV1AV",
        "outputId": "21098db2-f4b4-426b-fa9e-87134a2979bf"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 62.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference:\n",
        "\n",
        "Classification: [https://medium.com/analytics-vidhya/a-simple-neural-network-classifier-using-pytorch-from-scratch-7ebb477422d2]\n",
        "\n",
        "Autograd: [https://pytorch.org/tutorials/beginner/introyt/autogradyt_tutorial.html]\n",
        "\n",
        "Profiler: [https://pytorch.org/docs/stable/autograd.html#profiler]\n",
        "\n"
      ],
      "metadata": {
        "id": "DGaxhYOPYIvD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UnbfnizZYa5R"
      },
      "execution_count": 49,
      "outputs": []
    }
  ]
}